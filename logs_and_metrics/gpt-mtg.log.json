{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 412.573673870334,
  "global_step": 210000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "learning_rate": 4.998772102161101e-05,
      "loss": 6.6318,
      "step": 100
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.9975442043222e-05,
      "loss": 5.554,
      "step": 200
    },
    {
      "epoch": 0.59,
      "learning_rate": 4.996316306483301e-05,
      "loss": 4.7336,
      "step": 300
    },
    {
      "epoch": 0.79,
      "learning_rate": 4.995088408644401e-05,
      "loss": 4.0564,
      "step": 400
    },
    {
      "epoch": 0.98,
      "learning_rate": 4.9938605108055014e-05,
      "loss": 3.5742,
      "step": 500
    },
    {
      "epoch": 1.18,
      "learning_rate": 4.9926326129666014e-05,
      "loss": 3.1921,
      "step": 600
    },
    {
      "epoch": 1.38,
      "learning_rate": 4.9914047151277013e-05,
      "loss": 2.9255,
      "step": 700
    },
    {
      "epoch": 1.57,
      "learning_rate": 4.990176817288802e-05,
      "loss": 2.7567,
      "step": 800
    },
    {
      "epoch": 1.77,
      "learning_rate": 4.988948919449902e-05,
      "loss": 2.6652,
      "step": 900
    },
    {
      "epoch": 1.96,
      "learning_rate": 4.987721021611002e-05,
      "loss": 2.5718,
      "step": 1000
    },
    {
      "epoch": 2.16,
      "learning_rate": 4.9864931237721026e-05,
      "loss": 2.5098,
      "step": 1100
    },
    {
      "epoch": 2.36,
      "learning_rate": 4.9852652259332025e-05,
      "loss": 2.4721,
      "step": 1200
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.9840373280943025e-05,
      "loss": 2.4266,
      "step": 1300
    },
    {
      "epoch": 2.75,
      "learning_rate": 4.982809430255403e-05,
      "loss": 2.406,
      "step": 1400
    },
    {
      "epoch": 2.95,
      "learning_rate": 4.981581532416503e-05,
      "loss": 2.3799,
      "step": 1500
    },
    {
      "epoch": 3.14,
      "learning_rate": 4.980353634577604e-05,
      "loss": 2.3563,
      "step": 1600
    },
    {
      "epoch": 3.34,
      "learning_rate": 4.979125736738704e-05,
      "loss": 2.3609,
      "step": 1700
    },
    {
      "epoch": 3.54,
      "learning_rate": 4.977897838899804e-05,
      "loss": 2.3214,
      "step": 1800
    },
    {
      "epoch": 3.73,
      "learning_rate": 4.976669941060904e-05,
      "loss": 2.3087,
      "step": 1900
    },
    {
      "epoch": 3.93,
      "learning_rate": 4.9754420432220036e-05,
      "loss": 2.2575,
      "step": 2000
    },
    {
      "epoch": 4.13,
      "learning_rate": 4.974214145383104e-05,
      "loss": 2.2613,
      "step": 2100
    },
    {
      "epoch": 4.32,
      "learning_rate": 4.972986247544205e-05,
      "loss": 2.2427,
      "step": 2200
    },
    {
      "epoch": 4.52,
      "learning_rate": 4.971758349705305e-05,
      "loss": 2.2216,
      "step": 2300
    },
    {
      "epoch": 4.72,
      "learning_rate": 4.970530451866405e-05,
      "loss": 2.2141,
      "step": 2400
    },
    {
      "epoch": 4.91,
      "learning_rate": 4.9693025540275054e-05,
      "loss": 2.214,
      "step": 2500
    },
    {
      "epoch": 5.11,
      "learning_rate": 4.9680746561886054e-05,
      "loss": 2.1849,
      "step": 2600
    },
    {
      "epoch": 5.3,
      "learning_rate": 4.966846758349706e-05,
      "loss": 2.1816,
      "step": 2700
    },
    {
      "epoch": 5.5,
      "learning_rate": 4.965618860510805e-05,
      "loss": 2.151,
      "step": 2800
    },
    {
      "epoch": 5.7,
      "learning_rate": 4.964390962671906e-05,
      "loss": 2.1555,
      "step": 2900
    },
    {
      "epoch": 5.89,
      "learning_rate": 4.9631630648330066e-05,
      "loss": 2.1436,
      "step": 3000
    },
    {
      "epoch": 6.09,
      "learning_rate": 4.961935166994106e-05,
      "loss": 2.1393,
      "step": 3100
    },
    {
      "epoch": 6.29,
      "learning_rate": 4.9607072691552065e-05,
      "loss": 2.1245,
      "step": 3200
    },
    {
      "epoch": 6.48,
      "learning_rate": 4.9594793713163065e-05,
      "loss": 2.134,
      "step": 3300
    },
    {
      "epoch": 6.68,
      "learning_rate": 4.958251473477407e-05,
      "loss": 2.0889,
      "step": 3400
    },
    {
      "epoch": 6.88,
      "learning_rate": 4.957023575638507e-05,
      "loss": 2.0741,
      "step": 3500
    },
    {
      "epoch": 7.07,
      "learning_rate": 4.955795677799607e-05,
      "loss": 2.0943,
      "step": 3600
    },
    {
      "epoch": 7.27,
      "learning_rate": 4.954567779960708e-05,
      "loss": 2.0453,
      "step": 3700
    },
    {
      "epoch": 7.47,
      "learning_rate": 4.953339882121808e-05,
      "loss": 2.076,
      "step": 3800
    },
    {
      "epoch": 7.66,
      "learning_rate": 4.9521119842829077e-05,
      "loss": 2.049,
      "step": 3900
    },
    {
      "epoch": 7.86,
      "learning_rate": 4.950884086444008e-05,
      "loss": 2.0252,
      "step": 4000
    },
    {
      "epoch": 8.06,
      "learning_rate": 4.949656188605108e-05,
      "loss": 2.0073,
      "step": 4100
    },
    {
      "epoch": 8.25,
      "learning_rate": 4.948428290766208e-05,
      "loss": 1.988,
      "step": 4200
    },
    {
      "epoch": 8.45,
      "learning_rate": 4.947200392927309e-05,
      "loss": 1.9748,
      "step": 4300
    },
    {
      "epoch": 8.64,
      "learning_rate": 4.945972495088409e-05,
      "loss": 2.0029,
      "step": 4400
    },
    {
      "epoch": 8.84,
      "learning_rate": 4.9447445972495095e-05,
      "loss": 1.9732,
      "step": 4500
    },
    {
      "epoch": 9.04,
      "learning_rate": 4.9435166994106094e-05,
      "loss": 1.9748,
      "step": 4600
    },
    {
      "epoch": 9.23,
      "learning_rate": 4.9422888015717094e-05,
      "loss": 1.961,
      "step": 4700
    },
    {
      "epoch": 9.43,
      "learning_rate": 4.94106090373281e-05,
      "loss": 1.9504,
      "step": 4800
    },
    {
      "epoch": 9.63,
      "learning_rate": 4.939833005893909e-05,
      "loss": 1.9186,
      "step": 4900
    },
    {
      "epoch": 9.82,
      "learning_rate": 4.93860510805501e-05,
      "loss": 1.9,
      "step": 5000
    },
    {
      "epoch": 10.02,
      "learning_rate": 4.9373772102161106e-05,
      "loss": 1.8958,
      "step": 5100
    },
    {
      "epoch": 10.22,
      "learning_rate": 4.9361493123772106e-05,
      "loss": 1.8945,
      "step": 5200
    },
    {
      "epoch": 10.41,
      "learning_rate": 4.9349214145383105e-05,
      "loss": 1.8969,
      "step": 5300
    },
    {
      "epoch": 10.61,
      "learning_rate": 4.9336935166994105e-05,
      "loss": 1.8543,
      "step": 5400
    },
    {
      "epoch": 10.81,
      "learning_rate": 4.932465618860511e-05,
      "loss": 1.8574,
      "step": 5500
    },
    {
      "epoch": 11.0,
      "learning_rate": 4.931237721021611e-05,
      "loss": 1.8469,
      "step": 5600
    },
    {
      "epoch": 11.2,
      "learning_rate": 4.930009823182711e-05,
      "loss": 1.8367,
      "step": 5700
    },
    {
      "epoch": 11.39,
      "learning_rate": 4.928781925343812e-05,
      "loss": 1.8395,
      "step": 5800
    },
    {
      "epoch": 11.59,
      "learning_rate": 4.927554027504912e-05,
      "loss": 1.8125,
      "step": 5900
    },
    {
      "epoch": 11.79,
      "learning_rate": 4.9263261296660116e-05,
      "loss": 1.8084,
      "step": 6000
    },
    {
      "epoch": 11.98,
      "learning_rate": 4.925098231827112e-05,
      "loss": 1.7972,
      "step": 6100
    },
    {
      "epoch": 12.18,
      "learning_rate": 4.923870333988212e-05,
      "loss": 1.7945,
      "step": 6200
    },
    {
      "epoch": 12.38,
      "learning_rate": 4.922642436149313e-05,
      "loss": 1.7743,
      "step": 6300
    },
    {
      "epoch": 12.57,
      "learning_rate": 4.921414538310413e-05,
      "loss": 1.74,
      "step": 6400
    },
    {
      "epoch": 12.77,
      "learning_rate": 4.920186640471513e-05,
      "loss": 1.7534,
      "step": 6500
    },
    {
      "epoch": 12.97,
      "learning_rate": 4.9189587426326135e-05,
      "loss": 1.7378,
      "step": 6600
    },
    {
      "epoch": 13.16,
      "learning_rate": 4.9177308447937134e-05,
      "loss": 1.7284,
      "step": 6700
    },
    {
      "epoch": 13.36,
      "learning_rate": 4.9165029469548134e-05,
      "loss": 1.7049,
      "step": 6800
    },
    {
      "epoch": 13.56,
      "learning_rate": 4.915275049115914e-05,
      "loss": 1.6924,
      "step": 6900
    },
    {
      "epoch": 13.75,
      "learning_rate": 4.914047151277014e-05,
      "loss": 1.6937,
      "step": 7000
    },
    {
      "epoch": 13.95,
      "learning_rate": 4.912819253438114e-05,
      "loss": 1.6692,
      "step": 7100
    },
    {
      "epoch": 14.15,
      "learning_rate": 4.9115913555992146e-05,
      "loss": 1.6849,
      "step": 7200
    },
    {
      "epoch": 14.34,
      "learning_rate": 4.9103634577603146e-05,
      "loss": 1.6552,
      "step": 7300
    },
    {
      "epoch": 14.54,
      "learning_rate": 4.909135559921415e-05,
      "loss": 1.6549,
      "step": 7400
    },
    {
      "epoch": 14.73,
      "learning_rate": 4.907907662082515e-05,
      "loss": 1.6527,
      "step": 7500
    },
    {
      "epoch": 14.93,
      "learning_rate": 4.906679764243615e-05,
      "loss": 1.624,
      "step": 7600
    },
    {
      "epoch": 15.13,
      "learning_rate": 4.905451866404716e-05,
      "loss": 1.6287,
      "step": 7700
    },
    {
      "epoch": 15.32,
      "learning_rate": 4.904223968565815e-05,
      "loss": 1.6289,
      "step": 7800
    },
    {
      "epoch": 15.52,
      "learning_rate": 4.902996070726916e-05,
      "loss": 1.6095,
      "step": 7900
    },
    {
      "epoch": 15.72,
      "learning_rate": 4.9017681728880164e-05,
      "loss": 1.6,
      "step": 8000
    },
    {
      "epoch": 15.91,
      "learning_rate": 4.900540275049116e-05,
      "loss": 1.5889,
      "step": 8100
    },
    {
      "epoch": 16.11,
      "learning_rate": 4.899312377210216e-05,
      "loss": 1.5553,
      "step": 8200
    },
    {
      "epoch": 16.31,
      "learning_rate": 4.898084479371316e-05,
      "loss": 1.567,
      "step": 8300
    },
    {
      "epoch": 16.5,
      "learning_rate": 4.896856581532417e-05,
      "loss": 1.5477,
      "step": 8400
    },
    {
      "epoch": 16.7,
      "learning_rate": 4.895628683693517e-05,
      "loss": 1.5792,
      "step": 8500
    },
    {
      "epoch": 16.9,
      "learning_rate": 4.894400785854617e-05,
      "loss": 1.5428,
      "step": 8600
    },
    {
      "epoch": 17.09,
      "learning_rate": 4.8931728880157175e-05,
      "loss": 1.5479,
      "step": 8700
    },
    {
      "epoch": 17.29,
      "learning_rate": 4.8919449901768174e-05,
      "loss": 1.5414,
      "step": 8800
    },
    {
      "epoch": 17.49,
      "learning_rate": 4.8907170923379174e-05,
      "loss": 1.51,
      "step": 8900
    },
    {
      "epoch": 17.68,
      "learning_rate": 4.889489194499018e-05,
      "loss": 1.5332,
      "step": 9000
    },
    {
      "epoch": 17.88,
      "learning_rate": 4.888261296660118e-05,
      "loss": 1.5449,
      "step": 9100
    },
    {
      "epoch": 18.07,
      "learning_rate": 4.8870333988212186e-05,
      "loss": 1.5037,
      "step": 9200
    },
    {
      "epoch": 18.27,
      "learning_rate": 4.8858055009823186e-05,
      "loss": 1.5144,
      "step": 9300
    },
    {
      "epoch": 18.47,
      "learning_rate": 4.8845776031434186e-05,
      "loss": 1.5226,
      "step": 9400
    },
    {
      "epoch": 18.66,
      "learning_rate": 4.883349705304519e-05,
      "loss": 1.4957,
      "step": 9500
    },
    {
      "epoch": 18.86,
      "learning_rate": 4.882121807465619e-05,
      "loss": 1.4854,
      "step": 9600
    },
    {
      "epoch": 19.06,
      "learning_rate": 4.880893909626719e-05,
      "loss": 1.464,
      "step": 9700
    },
    {
      "epoch": 19.25,
      "learning_rate": 4.87966601178782e-05,
      "loss": 1.4774,
      "step": 9800
    },
    {
      "epoch": 19.45,
      "learning_rate": 4.87843811394892e-05,
      "loss": 1.4812,
      "step": 9900
    },
    {
      "epoch": 19.65,
      "learning_rate": 4.87721021611002e-05,
      "loss": 1.4556,
      "step": 10000
    },
    {
      "epoch": 19.84,
      "learning_rate": 4.8759823182711203e-05,
      "loss": 1.4761,
      "step": 10100
    },
    {
      "epoch": 20.04,
      "learning_rate": 4.87475442043222e-05,
      "loss": 1.424,
      "step": 10200
    },
    {
      "epoch": 20.24,
      "learning_rate": 4.87352652259332e-05,
      "loss": 1.4551,
      "step": 10300
    },
    {
      "epoch": 20.43,
      "learning_rate": 4.87229862475442e-05,
      "loss": 1.4441,
      "step": 10400
    },
    {
      "epoch": 20.63,
      "learning_rate": 4.871070726915521e-05,
      "loss": 1.4246,
      "step": 10500
    },
    {
      "epoch": 20.83,
      "learning_rate": 4.8698428290766215e-05,
      "loss": 1.4463,
      "step": 10600
    },
    {
      "epoch": 21.02,
      "learning_rate": 4.868614931237721e-05,
      "loss": 1.4316,
      "step": 10700
    },
    {
      "epoch": 21.22,
      "learning_rate": 4.8673870333988215e-05,
      "loss": 1.4149,
      "step": 10800
    },
    {
      "epoch": 21.41,
      "learning_rate": 4.866159135559922e-05,
      "loss": 1.41,
      "step": 10900
    },
    {
      "epoch": 21.61,
      "learning_rate": 4.864931237721022e-05,
      "loss": 1.4091,
      "step": 11000
    },
    {
      "epoch": 21.81,
      "learning_rate": 4.863703339882122e-05,
      "loss": 1.4144,
      "step": 11100
    },
    {
      "epoch": 22.0,
      "learning_rate": 4.862475442043222e-05,
      "loss": 1.42,
      "step": 11200
    },
    {
      "epoch": 22.2,
      "learning_rate": 4.8612475442043226e-05,
      "loss": 1.4,
      "step": 11300
    },
    {
      "epoch": 22.4,
      "learning_rate": 4.8600196463654226e-05,
      "loss": 1.3973,
      "step": 11400
    },
    {
      "epoch": 22.59,
      "learning_rate": 4.8587917485265226e-05,
      "loss": 1.3872,
      "step": 11500
    },
    {
      "epoch": 22.79,
      "learning_rate": 4.857563850687623e-05,
      "loss": 1.3891,
      "step": 11600
    },
    {
      "epoch": 22.99,
      "learning_rate": 4.856335952848723e-05,
      "loss": 1.3801,
      "step": 11700
    },
    {
      "epoch": 23.18,
      "learning_rate": 4.855108055009823e-05,
      "loss": 1.3784,
      "step": 11800
    },
    {
      "epoch": 23.38,
      "learning_rate": 4.853880157170924e-05,
      "loss": 1.3802,
      "step": 11900
    },
    {
      "epoch": 23.58,
      "learning_rate": 4.852652259332024e-05,
      "loss": 1.3481,
      "step": 12000
    },
    {
      "epoch": 23.77,
      "learning_rate": 4.851424361493124e-05,
      "loss": 1.3774,
      "step": 12100
    },
    {
      "epoch": 23.97,
      "learning_rate": 4.8501964636542243e-05,
      "loss": 1.3416,
      "step": 12200
    },
    {
      "epoch": 24.17,
      "learning_rate": 4.848968565815324e-05,
      "loss": 1.3716,
      "step": 12300
    },
    {
      "epoch": 24.36,
      "learning_rate": 4.847740667976425e-05,
      "loss": 1.3375,
      "step": 12400
    },
    {
      "epoch": 24.56,
      "learning_rate": 4.846512770137525e-05,
      "loss": 1.3605,
      "step": 12500
    },
    {
      "epoch": 24.75,
      "learning_rate": 4.845284872298625e-05,
      "loss": 1.3517,
      "step": 12600
    },
    {
      "epoch": 24.95,
      "learning_rate": 4.8440569744597255e-05,
      "loss": 1.3245,
      "step": 12700
    },
    {
      "epoch": 25.15,
      "learning_rate": 4.8428290766208255e-05,
      "loss": 1.3053,
      "step": 12800
    },
    {
      "epoch": 25.34,
      "learning_rate": 4.8416011787819254e-05,
      "loss": 1.3271,
      "step": 12900
    },
    {
      "epoch": 25.54,
      "learning_rate": 4.840373280943026e-05,
      "loss": 1.3281,
      "step": 13000
    },
    {
      "epoch": 25.74,
      "learning_rate": 4.839145383104126e-05,
      "loss": 1.3434,
      "step": 13100
    },
    {
      "epoch": 25.93,
      "learning_rate": 4.837917485265226e-05,
      "loss": 1.3312,
      "step": 13200
    },
    {
      "epoch": 26.13,
      "learning_rate": 4.836689587426326e-05,
      "loss": 1.3275,
      "step": 13300
    },
    {
      "epoch": 26.33,
      "learning_rate": 4.8354616895874266e-05,
      "loss": 1.3265,
      "step": 13400
    },
    {
      "epoch": 26.52,
      "learning_rate": 4.834233791748527e-05,
      "loss": 1.3056,
      "step": 13500
    },
    {
      "epoch": 26.72,
      "learning_rate": 4.8330058939096265e-05,
      "loss": 1.3117,
      "step": 13600
    },
    {
      "epoch": 26.92,
      "learning_rate": 4.831777996070727e-05,
      "loss": 1.2811,
      "step": 13700
    },
    {
      "epoch": 27.11,
      "learning_rate": 4.830550098231827e-05,
      "loss": 1.3059,
      "step": 13800
    },
    {
      "epoch": 27.31,
      "learning_rate": 4.829322200392927e-05,
      "loss": 1.2841,
      "step": 13900
    },
    {
      "epoch": 27.5,
      "learning_rate": 4.828094302554028e-05,
      "loss": 1.2924,
      "step": 14000
    },
    {
      "epoch": 27.7,
      "learning_rate": 4.826866404715128e-05,
      "loss": 1.2854,
      "step": 14100
    },
    {
      "epoch": 27.9,
      "learning_rate": 4.8256385068762284e-05,
      "loss": 1.2784,
      "step": 14200
    },
    {
      "epoch": 28.09,
      "learning_rate": 4.824410609037328e-05,
      "loss": 1.2845,
      "step": 14300
    },
    {
      "epoch": 28.29,
      "learning_rate": 4.823182711198428e-05,
      "loss": 1.2819,
      "step": 14400
    },
    {
      "epoch": 28.49,
      "learning_rate": 4.821954813359529e-05,
      "loss": 1.2884,
      "step": 14500
    },
    {
      "epoch": 28.68,
      "learning_rate": 4.820726915520629e-05,
      "loss": 1.2756,
      "step": 14600
    },
    {
      "epoch": 28.88,
      "learning_rate": 4.819499017681729e-05,
      "loss": 1.2819,
      "step": 14700
    },
    {
      "epoch": 29.08,
      "learning_rate": 4.8182711198428295e-05,
      "loss": 1.265,
      "step": 14800
    },
    {
      "epoch": 29.27,
      "learning_rate": 4.8170432220039295e-05,
      "loss": 1.2598,
      "step": 14900
    },
    {
      "epoch": 29.47,
      "learning_rate": 4.8158153241650294e-05,
      "loss": 1.2499,
      "step": 15000
    },
    {
      "epoch": 29.67,
      "learning_rate": 4.81458742632613e-05,
      "loss": 1.2529,
      "step": 15100
    },
    {
      "epoch": 29.86,
      "learning_rate": 4.81335952848723e-05,
      "loss": 1.2604,
      "step": 15200
    },
    {
      "epoch": 30.06,
      "learning_rate": 4.812131630648331e-05,
      "loss": 1.2584,
      "step": 15300
    },
    {
      "epoch": 30.26,
      "learning_rate": 4.81090373280943e-05,
      "loss": 1.2835,
      "step": 15400
    },
    {
      "epoch": 30.45,
      "learning_rate": 4.8096758349705306e-05,
      "loss": 1.2553,
      "step": 15500
    },
    {
      "epoch": 30.65,
      "learning_rate": 4.808447937131631e-05,
      "loss": 1.2326,
      "step": 15600
    },
    {
      "epoch": 30.84,
      "learning_rate": 4.807220039292731e-05,
      "loss": 1.2431,
      "step": 15700
    },
    {
      "epoch": 31.04,
      "learning_rate": 4.805992141453831e-05,
      "loss": 1.2525,
      "step": 15800
    },
    {
      "epoch": 31.24,
      "learning_rate": 4.804764243614932e-05,
      "loss": 1.2313,
      "step": 15900
    },
    {
      "epoch": 31.43,
      "learning_rate": 4.803536345776032e-05,
      "loss": 1.2353,
      "step": 16000
    },
    {
      "epoch": 31.63,
      "learning_rate": 4.802308447937132e-05,
      "loss": 1.2213,
      "step": 16100
    },
    {
      "epoch": 31.83,
      "learning_rate": 4.801080550098232e-05,
      "loss": 1.212,
      "step": 16200
    },
    {
      "epoch": 32.02,
      "learning_rate": 4.7998526522593324e-05,
      "loss": 1.2437,
      "step": 16300
    },
    {
      "epoch": 32.22,
      "learning_rate": 4.798624754420433e-05,
      "loss": 1.2242,
      "step": 16400
    },
    {
      "epoch": 32.42,
      "learning_rate": 4.797396856581532e-05,
      "loss": 1.2092,
      "step": 16500
    },
    {
      "epoch": 32.61,
      "learning_rate": 4.796168958742633e-05,
      "loss": 1.2087,
      "step": 16600
    },
    {
      "epoch": 32.81,
      "learning_rate": 4.794941060903733e-05,
      "loss": 1.2434,
      "step": 16700
    },
    {
      "epoch": 33.01,
      "learning_rate": 4.793713163064833e-05,
      "loss": 1.1912,
      "step": 16800
    },
    {
      "epoch": 33.2,
      "learning_rate": 4.7924852652259335e-05,
      "loss": 1.2125,
      "step": 16900
    },
    {
      "epoch": 33.4,
      "learning_rate": 4.7912573673870335e-05,
      "loss": 1.1948,
      "step": 17000
    },
    {
      "epoch": 33.6,
      "learning_rate": 4.790029469548134e-05,
      "loss": 1.1951,
      "step": 17100
    },
    {
      "epoch": 33.79,
      "learning_rate": 4.788801571709234e-05,
      "loss": 1.1895,
      "step": 17200
    },
    {
      "epoch": 33.99,
      "learning_rate": 4.787573673870334e-05,
      "loss": 1.2248,
      "step": 17300
    },
    {
      "epoch": 34.18,
      "learning_rate": 4.786345776031435e-05,
      "loss": 1.1961,
      "step": 17400
    },
    {
      "epoch": 34.38,
      "learning_rate": 4.7851178781925346e-05,
      "loss": 1.1918,
      "step": 17500
    },
    {
      "epoch": 34.58,
      "learning_rate": 4.7838899803536346e-05,
      "loss": 1.178,
      "step": 17600
    },
    {
      "epoch": 34.77,
      "learning_rate": 4.782662082514735e-05,
      "loss": 1.2084,
      "step": 17700
    },
    {
      "epoch": 34.97,
      "learning_rate": 4.781434184675835e-05,
      "loss": 1.1915,
      "step": 17800
    },
    {
      "epoch": 35.17,
      "learning_rate": 4.780206286836935e-05,
      "loss": 1.1801,
      "step": 17900
    },
    {
      "epoch": 35.36,
      "learning_rate": 4.778978388998036e-05,
      "loss": 1.2085,
      "step": 18000
    },
    {
      "epoch": 35.56,
      "learning_rate": 4.777750491159136e-05,
      "loss": 1.1873,
      "step": 18100
    },
    {
      "epoch": 35.76,
      "learning_rate": 4.7765225933202364e-05,
      "loss": 1.1918,
      "step": 18200
    },
    {
      "epoch": 35.95,
      "learning_rate": 4.775294695481336e-05,
      "loss": 1.167,
      "step": 18300
    },
    {
      "epoch": 36.15,
      "learning_rate": 4.7740667976424364e-05,
      "loss": 1.1582,
      "step": 18400
    },
    {
      "epoch": 36.35,
      "learning_rate": 4.772838899803537e-05,
      "loss": 1.1646,
      "step": 18500
    },
    {
      "epoch": 36.54,
      "learning_rate": 4.771611001964636e-05,
      "loss": 1.1716,
      "step": 18600
    },
    {
      "epoch": 36.74,
      "learning_rate": 4.770383104125737e-05,
      "loss": 1.1808,
      "step": 18700
    },
    {
      "epoch": 36.94,
      "learning_rate": 4.769155206286837e-05,
      "loss": 1.1766,
      "step": 18800
    },
    {
      "epoch": 37.13,
      "learning_rate": 4.7679273084479375e-05,
      "loss": 1.1617,
      "step": 18900
    },
    {
      "epoch": 37.33,
      "learning_rate": 4.7666994106090375e-05,
      "loss": 1.1825,
      "step": 19000
    },
    {
      "epoch": 37.52,
      "learning_rate": 4.7654715127701375e-05,
      "loss": 1.1828,
      "step": 19100
    },
    {
      "epoch": 37.72,
      "learning_rate": 4.764243614931238e-05,
      "loss": 1.1714,
      "step": 19200
    },
    {
      "epoch": 37.92,
      "learning_rate": 4.763015717092338e-05,
      "loss": 1.1512,
      "step": 19300
    },
    {
      "epoch": 38.11,
      "learning_rate": 4.761787819253438e-05,
      "loss": 1.16,
      "step": 19400
    },
    {
      "epoch": 38.31,
      "learning_rate": 4.760559921414539e-05,
      "loss": 1.1458,
      "step": 19500
    },
    {
      "epoch": 38.51,
      "learning_rate": 4.7593320235756386e-05,
      "loss": 1.1497,
      "step": 19600
    },
    {
      "epoch": 38.7,
      "learning_rate": 4.7581041257367386e-05,
      "loss": 1.1434,
      "step": 19700
    },
    {
      "epoch": 38.9,
      "learning_rate": 4.756876227897839e-05,
      "loss": 1.1552,
      "step": 19800
    },
    {
      "epoch": 39.1,
      "learning_rate": 4.755648330058939e-05,
      "loss": 1.1488,
      "step": 19900
    },
    {
      "epoch": 39.29,
      "learning_rate": 4.75442043222004e-05,
      "loss": 1.1347,
      "step": 20000
    },
    {
      "epoch": 39.49,
      "learning_rate": 4.75319253438114e-05,
      "loss": 1.1399,
      "step": 20100
    },
    {
      "epoch": 39.69,
      "learning_rate": 4.75196463654224e-05,
      "loss": 1.1408,
      "step": 20200
    },
    {
      "epoch": 39.88,
      "learning_rate": 4.7507367387033404e-05,
      "loss": 1.1486,
      "step": 20300
    },
    {
      "epoch": 40.08,
      "learning_rate": 4.74950884086444e-05,
      "loss": 1.1402,
      "step": 20400
    },
    {
      "epoch": 40.28,
      "learning_rate": 4.7482809430255403e-05,
      "loss": 1.1322,
      "step": 20500
    },
    {
      "epoch": 40.47,
      "learning_rate": 4.747053045186641e-05,
      "loss": 1.151,
      "step": 20600
    },
    {
      "epoch": 40.67,
      "learning_rate": 4.745825147347741e-05,
      "loss": 1.1385,
      "step": 20700
    },
    {
      "epoch": 40.86,
      "learning_rate": 4.744597249508841e-05,
      "loss": 1.138,
      "step": 20800
    },
    {
      "epoch": 41.06,
      "learning_rate": 4.7433693516699416e-05,
      "loss": 1.1213,
      "step": 20900
    },
    {
      "epoch": 41.26,
      "learning_rate": 4.7421414538310415e-05,
      "loss": 1.1395,
      "step": 21000
    },
    {
      "epoch": 41.45,
      "learning_rate": 4.740913555992142e-05,
      "loss": 1.128,
      "step": 21100
    },
    {
      "epoch": 41.65,
      "learning_rate": 4.7396856581532415e-05,
      "loss": 1.1173,
      "step": 21200
    },
    {
      "epoch": 41.85,
      "learning_rate": 4.738457760314342e-05,
      "loss": 1.1174,
      "step": 21300
    },
    {
      "epoch": 42.04,
      "learning_rate": 4.737229862475443e-05,
      "loss": 1.1242,
      "step": 21400
    },
    {
      "epoch": 42.24,
      "learning_rate": 4.736001964636542e-05,
      "loss": 1.1286,
      "step": 21500
    },
    {
      "epoch": 42.44,
      "learning_rate": 4.734774066797643e-05,
      "loss": 1.1488,
      "step": 21600
    },
    {
      "epoch": 42.63,
      "learning_rate": 4.7335461689587426e-05,
      "loss": 1.1132,
      "step": 21700
    },
    {
      "epoch": 42.83,
      "learning_rate": 4.732318271119843e-05,
      "loss": 1.1252,
      "step": 21800
    },
    {
      "epoch": 43.03,
      "learning_rate": 4.731090373280943e-05,
      "loss": 1.1069,
      "step": 21900
    },
    {
      "epoch": 43.22,
      "learning_rate": 4.729862475442043e-05,
      "loss": 1.1105,
      "step": 22000
    },
    {
      "epoch": 43.42,
      "learning_rate": 4.728634577603144e-05,
      "loss": 1.128,
      "step": 22100
    },
    {
      "epoch": 43.61,
      "learning_rate": 4.727406679764244e-05,
      "loss": 1.1104,
      "step": 22200
    },
    {
      "epoch": 43.81,
      "learning_rate": 4.726178781925344e-05,
      "loss": 1.1209,
      "step": 22300
    },
    {
      "epoch": 44.01,
      "learning_rate": 4.7249508840864444e-05,
      "loss": 1.1232,
      "step": 22400
    },
    {
      "epoch": 44.2,
      "learning_rate": 4.7237229862475444e-05,
      "loss": 1.0982,
      "step": 22500
    },
    {
      "epoch": 44.4,
      "learning_rate": 4.7224950884086443e-05,
      "loss": 1.1109,
      "step": 22600
    },
    {
      "epoch": 44.6,
      "learning_rate": 4.721267190569745e-05,
      "loss": 1.0959,
      "step": 22700
    },
    {
      "epoch": 44.79,
      "learning_rate": 4.720039292730845e-05,
      "loss": 1.0974,
      "step": 22800
    },
    {
      "epoch": 44.99,
      "learning_rate": 4.7188113948919456e-05,
      "loss": 1.1309,
      "step": 22900
    },
    {
      "epoch": 45.19,
      "learning_rate": 4.7175834970530456e-05,
      "loss": 1.1094,
      "step": 23000
    },
    {
      "epoch": 45.38,
      "learning_rate": 4.7163555992141455e-05,
      "loss": 1.0842,
      "step": 23100
    },
    {
      "epoch": 45.58,
      "learning_rate": 4.715127701375246e-05,
      "loss": 1.1007,
      "step": 23200
    },
    {
      "epoch": 45.78,
      "learning_rate": 4.7138998035363454e-05,
      "loss": 1.0992,
      "step": 23300
    },
    {
      "epoch": 45.97,
      "learning_rate": 4.712671905697446e-05,
      "loss": 1.0803,
      "step": 23400
    },
    {
      "epoch": 46.17,
      "learning_rate": 4.711444007858547e-05,
      "loss": 1.1003,
      "step": 23500
    },
    {
      "epoch": 46.37,
      "learning_rate": 4.710216110019647e-05,
      "loss": 1.091,
      "step": 23600
    },
    {
      "epoch": 46.56,
      "learning_rate": 4.7089882121807467e-05,
      "loss": 1.0953,
      "step": 23700
    },
    {
      "epoch": 46.76,
      "learning_rate": 4.7077603143418466e-05,
      "loss": 1.0647,
      "step": 23800
    },
    {
      "epoch": 46.95,
      "learning_rate": 4.706532416502947e-05,
      "loss": 1.0964,
      "step": 23900
    },
    {
      "epoch": 47.15,
      "learning_rate": 4.705304518664048e-05,
      "loss": 1.0901,
      "step": 24000
    },
    {
      "epoch": 47.35,
      "learning_rate": 4.704076620825147e-05,
      "loss": 1.0909,
      "step": 24100
    },
    {
      "epoch": 47.54,
      "learning_rate": 4.702848722986248e-05,
      "loss": 1.0882,
      "step": 24200
    },
    {
      "epoch": 47.74,
      "learning_rate": 4.7016208251473485e-05,
      "loss": 1.0954,
      "step": 24300
    },
    {
      "epoch": 47.94,
      "learning_rate": 4.700392927308448e-05,
      "loss": 1.0769,
      "step": 24400
    },
    {
      "epoch": 48.13,
      "learning_rate": 4.6991650294695484e-05,
      "loss": 1.0874,
      "step": 24500
    },
    {
      "epoch": 48.33,
      "learning_rate": 4.6979371316306484e-05,
      "loss": 1.0874,
      "step": 24600
    },
    {
      "epoch": 48.53,
      "learning_rate": 4.696709233791749e-05,
      "loss": 1.0931,
      "step": 24700
    },
    {
      "epoch": 48.72,
      "learning_rate": 4.695481335952849e-05,
      "loss": 1.054,
      "step": 24800
    },
    {
      "epoch": 48.92,
      "learning_rate": 4.694253438113949e-05,
      "loss": 1.0697,
      "step": 24900
    },
    {
      "epoch": 49.12,
      "learning_rate": 4.6930255402750496e-05,
      "loss": 1.0801,
      "step": 25000
    },
    {
      "epoch": 49.31,
      "learning_rate": 4.6917976424361495e-05,
      "loss": 1.0781,
      "step": 25100
    },
    {
      "epoch": 49.51,
      "learning_rate": 4.6905697445972495e-05,
      "loss": 1.0564,
      "step": 25200
    },
    {
      "epoch": 49.71,
      "learning_rate": 4.68934184675835e-05,
      "loss": 1.0868,
      "step": 25300
    },
    {
      "epoch": 49.9,
      "learning_rate": 4.68811394891945e-05,
      "loss": 1.0593,
      "step": 25400
    },
    {
      "epoch": 50.1,
      "learning_rate": 4.68688605108055e-05,
      "loss": 1.065,
      "step": 25500
    },
    {
      "epoch": 50.29,
      "learning_rate": 4.685658153241651e-05,
      "loss": 1.0732,
      "step": 25600
    },
    {
      "epoch": 50.49,
      "learning_rate": 4.684430255402751e-05,
      "loss": 1.0602,
      "step": 25700
    },
    {
      "epoch": 50.69,
      "learning_rate": 4.683202357563851e-05,
      "loss": 1.0748,
      "step": 25800
    },
    {
      "epoch": 50.88,
      "learning_rate": 4.681974459724951e-05,
      "loss": 1.0642,
      "step": 25900
    },
    {
      "epoch": 51.08,
      "learning_rate": 4.680746561886051e-05,
      "loss": 1.0685,
      "step": 26000
    },
    {
      "epoch": 51.28,
      "learning_rate": 4.679518664047152e-05,
      "loss": 1.0647,
      "step": 26100
    },
    {
      "epoch": 51.47,
      "learning_rate": 4.678290766208251e-05,
      "loss": 1.039,
      "step": 26200
    },
    {
      "epoch": 51.67,
      "learning_rate": 4.677062868369352e-05,
      "loss": 1.0769,
      "step": 26300
    },
    {
      "epoch": 51.87,
      "learning_rate": 4.6758349705304525e-05,
      "loss": 1.0491,
      "step": 26400
    },
    {
      "epoch": 52.06,
      "learning_rate": 4.6746070726915524e-05,
      "loss": 1.0613,
      "step": 26500
    },
    {
      "epoch": 52.26,
      "learning_rate": 4.6733791748526524e-05,
      "loss": 1.0592,
      "step": 26600
    },
    {
      "epoch": 52.46,
      "learning_rate": 4.6721512770137524e-05,
      "loss": 1.0254,
      "step": 26700
    },
    {
      "epoch": 52.65,
      "learning_rate": 4.670923379174853e-05,
      "loss": 1.0432,
      "step": 26800
    },
    {
      "epoch": 52.85,
      "learning_rate": 4.669695481335953e-05,
      "loss": 1.0502,
      "step": 26900
    },
    {
      "epoch": 53.05,
      "learning_rate": 4.668467583497053e-05,
      "loss": 1.0515,
      "step": 27000
    },
    {
      "epoch": 53.24,
      "learning_rate": 4.6672396856581536e-05,
      "loss": 1.047,
      "step": 27100
    },
    {
      "epoch": 53.44,
      "learning_rate": 4.6660117878192535e-05,
      "loss": 1.064,
      "step": 27200
    },
    {
      "epoch": 53.63,
      "learning_rate": 4.6647838899803535e-05,
      "loss": 1.0603,
      "step": 27300
    },
    {
      "epoch": 53.83,
      "learning_rate": 4.663555992141454e-05,
      "loss": 1.0406,
      "step": 27400
    },
    {
      "epoch": 54.03,
      "learning_rate": 4.662328094302554e-05,
      "loss": 1.0482,
      "step": 27500
    },
    {
      "epoch": 54.22,
      "learning_rate": 4.661100196463655e-05,
      "loss": 1.0559,
      "step": 27600
    },
    {
      "epoch": 54.42,
      "learning_rate": 4.659872298624755e-05,
      "loss": 1.0252,
      "step": 27700
    },
    {
      "epoch": 54.62,
      "learning_rate": 4.658644400785855e-05,
      "loss": 1.0413,
      "step": 27800
    },
    {
      "epoch": 54.81,
      "learning_rate": 4.657416502946955e-05,
      "loss": 1.0559,
      "step": 27900
    },
    {
      "epoch": 55.01,
      "learning_rate": 4.656188605108055e-05,
      "loss": 1.0403,
      "step": 28000
    },
    {
      "epoch": 55.21,
      "learning_rate": 4.654960707269155e-05,
      "loss": 1.0382,
      "step": 28100
    },
    {
      "epoch": 55.4,
      "learning_rate": 4.653732809430256e-05,
      "loss": 1.0294,
      "step": 28200
    },
    {
      "epoch": 55.6,
      "learning_rate": 4.652504911591356e-05,
      "loss": 1.052,
      "step": 28300
    },
    {
      "epoch": 55.8,
      "learning_rate": 4.651277013752456e-05,
      "loss": 1.022,
      "step": 28400
    },
    {
      "epoch": 55.99,
      "learning_rate": 4.6500491159135565e-05,
      "loss": 1.0355,
      "step": 28500
    },
    {
      "epoch": 56.19,
      "learning_rate": 4.6488212180746564e-05,
      "loss": 1.0397,
      "step": 28600
    },
    {
      "epoch": 56.39,
      "learning_rate": 4.6475933202357564e-05,
      "loss": 1.0231,
      "step": 28700
    },
    {
      "epoch": 56.58,
      "learning_rate": 4.6463654223968564e-05,
      "loss": 1.035,
      "step": 28800
    },
    {
      "epoch": 56.78,
      "learning_rate": 4.645137524557957e-05,
      "loss": 1.0182,
      "step": 28900
    },
    {
      "epoch": 56.97,
      "learning_rate": 4.6439096267190576e-05,
      "loss": 1.0323,
      "step": 29000
    },
    {
      "epoch": 57.17,
      "learning_rate": 4.642681728880157e-05,
      "loss": 1.0406,
      "step": 29100
    },
    {
      "epoch": 57.37,
      "learning_rate": 4.6414538310412576e-05,
      "loss": 1.0424,
      "step": 29200
    },
    {
      "epoch": 57.56,
      "learning_rate": 4.640225933202358e-05,
      "loss": 1.0331,
      "step": 29300
    },
    {
      "epoch": 57.76,
      "learning_rate": 4.638998035363458e-05,
      "loss": 1.0392,
      "step": 29400
    },
    {
      "epoch": 57.96,
      "learning_rate": 4.637770137524558e-05,
      "loss": 1.0177,
      "step": 29500
    },
    {
      "epoch": 58.15,
      "learning_rate": 4.636542239685658e-05,
      "loss": 1.0388,
      "step": 29600
    },
    {
      "epoch": 58.35,
      "learning_rate": 4.635314341846759e-05,
      "loss": 1.0199,
      "step": 29700
    },
    {
      "epoch": 58.55,
      "learning_rate": 4.634086444007859e-05,
      "loss": 1.0132,
      "step": 29800
    },
    {
      "epoch": 58.74,
      "learning_rate": 4.632858546168959e-05,
      "loss": 1.0046,
      "step": 29900
    },
    {
      "epoch": 58.94,
      "learning_rate": 4.631630648330059e-05,
      "loss": 1.0313,
      "step": 30000
    },
    {
      "epoch": 59.14,
      "learning_rate": 4.630402750491159e-05,
      "loss": 1.0092,
      "step": 30100
    },
    {
      "epoch": 59.33,
      "learning_rate": 4.629174852652259e-05,
      "loss": 1.04,
      "step": 30200
    },
    {
      "epoch": 59.53,
      "learning_rate": 4.62794695481336e-05,
      "loss": 1.0232,
      "step": 30300
    },
    {
      "epoch": 59.72,
      "learning_rate": 4.62671905697446e-05,
      "loss": 0.9954,
      "step": 30400
    },
    {
      "epoch": 59.92,
      "learning_rate": 4.6254911591355605e-05,
      "loss": 1.016,
      "step": 30500
    },
    {
      "epoch": 60.12,
      "learning_rate": 4.6242632612966605e-05,
      "loss": 1.0119,
      "step": 30600
    },
    {
      "epoch": 60.31,
      "learning_rate": 4.6230353634577604e-05,
      "loss": 1.0071,
      "step": 30700
    },
    {
      "epoch": 60.51,
      "learning_rate": 4.621807465618861e-05,
      "loss": 1.0117,
      "step": 30800
    },
    {
      "epoch": 60.71,
      "learning_rate": 4.620579567779961e-05,
      "loss": 0.9959,
      "step": 30900
    },
    {
      "epoch": 60.9,
      "learning_rate": 4.619351669941061e-05,
      "loss": 1.0083,
      "step": 31000
    },
    {
      "epoch": 61.1,
      "learning_rate": 4.6181237721021616e-05,
      "loss": 1.0027,
      "step": 31100
    },
    {
      "epoch": 61.3,
      "learning_rate": 4.6168958742632616e-05,
      "loss": 0.9995,
      "step": 31200
    },
    {
      "epoch": 61.49,
      "learning_rate": 4.6156679764243616e-05,
      "loss": 1.0146,
      "step": 31300
    },
    {
      "epoch": 61.69,
      "learning_rate": 4.614440078585462e-05,
      "loss": 1.0121,
      "step": 31400
    },
    {
      "epoch": 61.89,
      "learning_rate": 4.613212180746562e-05,
      "loss": 1.0066,
      "step": 31500
    },
    {
      "epoch": 62.08,
      "learning_rate": 4.611984282907662e-05,
      "loss": 1.0051,
      "step": 31600
    },
    {
      "epoch": 62.28,
      "learning_rate": 4.610756385068762e-05,
      "loss": 1.0081,
      "step": 31700
    },
    {
      "epoch": 62.48,
      "learning_rate": 4.609528487229863e-05,
      "loss": 0.991,
      "step": 31800
    },
    {
      "epoch": 62.67,
      "learning_rate": 4.6083005893909634e-05,
      "loss": 0.9927,
      "step": 31900
    },
    {
      "epoch": 62.87,
      "learning_rate": 4.607072691552063e-05,
      "loss": 1.001,
      "step": 32000
    },
    {
      "epoch": 63.06,
      "learning_rate": 4.605844793713163e-05,
      "loss": 0.9952,
      "step": 32100
    },
    {
      "epoch": 63.26,
      "learning_rate": 4.604616895874263e-05,
      "loss": 0.9973,
      "step": 32200
    },
    {
      "epoch": 63.46,
      "learning_rate": 4.603388998035364e-05,
      "loss": 1.0047,
      "step": 32300
    },
    {
      "epoch": 63.65,
      "learning_rate": 4.602161100196464e-05,
      "loss": 1.0043,
      "step": 32400
    },
    {
      "epoch": 63.85,
      "learning_rate": 4.600933202357564e-05,
      "loss": 1.0074,
      "step": 32500
    },
    {
      "epoch": 64.05,
      "learning_rate": 4.5997053045186645e-05,
      "loss": 0.9935,
      "step": 32600
    },
    {
      "epoch": 64.24,
      "learning_rate": 4.5984774066797644e-05,
      "loss": 0.9827,
      "step": 32700
    },
    {
      "epoch": 64.44,
      "learning_rate": 4.5972495088408644e-05,
      "loss": 1.0016,
      "step": 32800
    },
    {
      "epoch": 64.64,
      "learning_rate": 4.596021611001965e-05,
      "loss": 1.0003,
      "step": 32900
    },
    {
      "epoch": 64.83,
      "learning_rate": 4.594793713163065e-05,
      "loss": 0.9936,
      "step": 33000
    },
    {
      "epoch": 65.03,
      "learning_rate": 4.593565815324165e-05,
      "loss": 1.0005,
      "step": 33100
    },
    {
      "epoch": 65.23,
      "learning_rate": 4.5923379174852656e-05,
      "loss": 1.0107,
      "step": 33200
    },
    {
      "epoch": 65.42,
      "learning_rate": 4.5911100196463656e-05,
      "loss": 0.9948,
      "step": 33300
    },
    {
      "epoch": 65.62,
      "learning_rate": 4.5898821218074656e-05,
      "loss": 0.9779,
      "step": 33400
    },
    {
      "epoch": 65.82,
      "learning_rate": 4.588654223968566e-05,
      "loss": 0.998,
      "step": 33500
    },
    {
      "epoch": 66.01,
      "learning_rate": 4.587426326129666e-05,
      "loss": 0.975,
      "step": 33600
    },
    {
      "epoch": 66.21,
      "learning_rate": 4.586198428290767e-05,
      "loss": 0.9759,
      "step": 33700
    },
    {
      "epoch": 66.4,
      "learning_rate": 4.584970530451866e-05,
      "loss": 0.9893,
      "step": 33800
    },
    {
      "epoch": 66.6,
      "learning_rate": 4.583742632612967e-05,
      "loss": 0.9877,
      "step": 33900
    },
    {
      "epoch": 66.8,
      "learning_rate": 4.5825147347740674e-05,
      "loss": 0.9706,
      "step": 34000
    },
    {
      "epoch": 66.99,
      "learning_rate": 4.581286836935167e-05,
      "loss": 0.9816,
      "step": 34100
    },
    {
      "epoch": 67.19,
      "learning_rate": 4.580058939096267e-05,
      "loss": 0.9676,
      "step": 34200
    },
    {
      "epoch": 67.39,
      "learning_rate": 4.578831041257368e-05,
      "loss": 0.9945,
      "step": 34300
    },
    {
      "epoch": 67.58,
      "learning_rate": 4.577603143418468e-05,
      "loss": 0.9867,
      "step": 34400
    },
    {
      "epoch": 67.78,
      "learning_rate": 4.576375245579568e-05,
      "loss": 0.9924,
      "step": 34500
    },
    {
      "epoch": 67.98,
      "learning_rate": 4.575147347740668e-05,
      "loss": 0.9832,
      "step": 34600
    },
    {
      "epoch": 68.17,
      "learning_rate": 4.5739194499017685e-05,
      "loss": 0.9654,
      "step": 34700
    },
    {
      "epoch": 68.37,
      "learning_rate": 4.572691552062869e-05,
      "loss": 0.9879,
      "step": 34800
    },
    {
      "epoch": 68.57,
      "learning_rate": 4.5714636542239684e-05,
      "loss": 0.9779,
      "step": 34900
    },
    {
      "epoch": 68.76,
      "learning_rate": 4.570235756385069e-05,
      "loss": 0.9791,
      "step": 35000
    },
    {
      "epoch": 68.96,
      "learning_rate": 4.569007858546169e-05,
      "loss": 0.9784,
      "step": 35100
    },
    {
      "epoch": 69.16,
      "learning_rate": 4.567779960707269e-05,
      "loss": 0.9733,
      "step": 35200
    },
    {
      "epoch": 69.35,
      "learning_rate": 4.5665520628683696e-05,
      "loss": 0.973,
      "step": 35300
    },
    {
      "epoch": 69.55,
      "learning_rate": 4.5653241650294696e-05,
      "loss": 0.9751,
      "step": 35400
    },
    {
      "epoch": 69.74,
      "learning_rate": 4.56409626719057e-05,
      "loss": 0.9725,
      "step": 35500
    },
    {
      "epoch": 69.94,
      "learning_rate": 4.56286836935167e-05,
      "loss": 0.9864,
      "step": 35600
    },
    {
      "epoch": 70.14,
      "learning_rate": 4.56164047151277e-05,
      "loss": 0.9777,
      "step": 35700
    },
    {
      "epoch": 70.33,
      "learning_rate": 4.560412573673871e-05,
      "loss": 0.9488,
      "step": 35800
    },
    {
      "epoch": 70.53,
      "learning_rate": 4.559184675834971e-05,
      "loss": 0.9621,
      "step": 35900
    },
    {
      "epoch": 70.73,
      "learning_rate": 4.557956777996071e-05,
      "loss": 0.9876,
      "step": 36000
    },
    {
      "epoch": 70.92,
      "learning_rate": 4.5567288801571714e-05,
      "loss": 0.9759,
      "step": 36100
    },
    {
      "epoch": 71.12,
      "learning_rate": 4.555500982318271e-05,
      "loss": 0.9822,
      "step": 36200
    },
    {
      "epoch": 71.32,
      "learning_rate": 4.554273084479371e-05,
      "loss": 0.9611,
      "step": 36300
    },
    {
      "epoch": 71.51,
      "learning_rate": 4.553045186640472e-05,
      "loss": 0.9741,
      "step": 36400
    },
    {
      "epoch": 71.71,
      "learning_rate": 4.551817288801572e-05,
      "loss": 0.9756,
      "step": 36500
    },
    {
      "epoch": 71.91,
      "learning_rate": 4.5505893909626725e-05,
      "loss": 0.9765,
      "step": 36600
    },
    {
      "epoch": 72.1,
      "learning_rate": 4.549361493123772e-05,
      "loss": 0.9706,
      "step": 36700
    },
    {
      "epoch": 72.3,
      "learning_rate": 4.5481335952848725e-05,
      "loss": 0.9374,
      "step": 36800
    },
    {
      "epoch": 72.5,
      "learning_rate": 4.546905697445973e-05,
      "loss": 0.9616,
      "step": 36900
    },
    {
      "epoch": 72.69,
      "learning_rate": 4.545677799607073e-05,
      "loss": 0.9695,
      "step": 37000
    },
    {
      "epoch": 72.89,
      "learning_rate": 4.544449901768173e-05,
      "loss": 0.9604,
      "step": 37100
    },
    {
      "epoch": 73.08,
      "learning_rate": 4.543222003929273e-05,
      "loss": 0.9556,
      "step": 37200
    },
    {
      "epoch": 73.28,
      "learning_rate": 4.5419941060903736e-05,
      "loss": 0.9627,
      "step": 37300
    },
    {
      "epoch": 73.48,
      "learning_rate": 4.5407662082514736e-05,
      "loss": 0.9649,
      "step": 37400
    },
    {
      "epoch": 73.67,
      "learning_rate": 4.5395383104125736e-05,
      "loss": 0.9411,
      "step": 37500
    },
    {
      "epoch": 73.87,
      "learning_rate": 4.538310412573674e-05,
      "loss": 0.9777,
      "step": 37600
    },
    {
      "epoch": 74.07,
      "learning_rate": 4.537082514734775e-05,
      "loss": 0.944,
      "step": 37700
    },
    {
      "epoch": 74.26,
      "learning_rate": 4.535854616895874e-05,
      "loss": 0.9492,
      "step": 37800
    },
    {
      "epoch": 74.46,
      "learning_rate": 4.534626719056975e-05,
      "loss": 0.9585,
      "step": 37900
    },
    {
      "epoch": 74.66,
      "learning_rate": 4.533398821218075e-05,
      "loss": 0.9651,
      "step": 38000
    },
    {
      "epoch": 74.85,
      "learning_rate": 4.532170923379175e-05,
      "loss": 0.9685,
      "step": 38100
    },
    {
      "epoch": 75.05,
      "learning_rate": 4.5309430255402754e-05,
      "loss": 0.948,
      "step": 38200
    },
    {
      "epoch": 75.25,
      "learning_rate": 4.529715127701375e-05,
      "loss": 0.9466,
      "step": 38300
    },
    {
      "epoch": 75.44,
      "learning_rate": 4.528487229862476e-05,
      "loss": 0.9756,
      "step": 38400
    },
    {
      "epoch": 75.64,
      "learning_rate": 4.527259332023576e-05,
      "loss": 0.9533,
      "step": 38500
    },
    {
      "epoch": 75.83,
      "learning_rate": 4.526031434184676e-05,
      "loss": 0.9348,
      "step": 38600
    },
    {
      "epoch": 76.03,
      "learning_rate": 4.5248035363457765e-05,
      "loss": 0.9536,
      "step": 38700
    },
    {
      "epoch": 76.23,
      "learning_rate": 4.5235756385068765e-05,
      "loss": 0.9504,
      "step": 38800
    },
    {
      "epoch": 76.42,
      "learning_rate": 4.5223477406679765e-05,
      "loss": 0.9525,
      "step": 38900
    },
    {
      "epoch": 76.62,
      "learning_rate": 4.521119842829077e-05,
      "loss": 0.9532,
      "step": 39000
    },
    {
      "epoch": 76.82,
      "learning_rate": 4.519891944990177e-05,
      "loss": 0.9335,
      "step": 39100
    },
    {
      "epoch": 77.01,
      "learning_rate": 4.518664047151277e-05,
      "loss": 0.9442,
      "step": 39200
    },
    {
      "epoch": 77.21,
      "learning_rate": 4.517436149312378e-05,
      "loss": 0.9249,
      "step": 39300
    },
    {
      "epoch": 77.41,
      "learning_rate": 4.5162082514734776e-05,
      "loss": 0.9339,
      "step": 39400
    },
    {
      "epoch": 77.6,
      "learning_rate": 4.514980353634578e-05,
      "loss": 0.9342,
      "step": 39500
    },
    {
      "epoch": 77.8,
      "learning_rate": 4.5137524557956776e-05,
      "loss": 0.9565,
      "step": 39600
    },
    {
      "epoch": 78.0,
      "learning_rate": 4.512524557956778e-05,
      "loss": 0.9443,
      "step": 39700
    },
    {
      "epoch": 78.19,
      "learning_rate": 4.511296660117879e-05,
      "loss": 0.9452,
      "step": 39800
    },
    {
      "epoch": 78.39,
      "learning_rate": 4.510068762278978e-05,
      "loss": 0.9432,
      "step": 39900
    },
    {
      "epoch": 78.59,
      "learning_rate": 4.508840864440079e-05,
      "loss": 0.9369,
      "step": 40000
    },
    {
      "epoch": 78.78,
      "learning_rate": 4.507612966601179e-05,
      "loss": 0.9277,
      "step": 40100
    },
    {
      "epoch": 78.98,
      "learning_rate": 4.5063850687622794e-05,
      "loss": 0.9494,
      "step": 40200
    },
    {
      "epoch": 79.17,
      "learning_rate": 4.5051571709233793e-05,
      "loss": 0.9443,
      "step": 40300
    },
    {
      "epoch": 79.37,
      "learning_rate": 4.503929273084479e-05,
      "loss": 0.937,
      "step": 40400
    },
    {
      "epoch": 79.57,
      "learning_rate": 4.50270137524558e-05,
      "loss": 0.923,
      "step": 40500
    },
    {
      "epoch": 79.76,
      "learning_rate": 4.50147347740668e-05,
      "loss": 0.9307,
      "step": 40600
    },
    {
      "epoch": 79.96,
      "learning_rate": 4.50024557956778e-05,
      "loss": 0.9303,
      "step": 40700
    },
    {
      "epoch": 80.16,
      "learning_rate": 4.4990176817288805e-05,
      "loss": 0.9223,
      "step": 40800
    },
    {
      "epoch": 80.35,
      "learning_rate": 4.4977897838899805e-05,
      "loss": 0.9353,
      "step": 40900
    },
    {
      "epoch": 80.55,
      "learning_rate": 4.4965618860510805e-05,
      "loss": 0.9254,
      "step": 41000
    },
    {
      "epoch": 80.75,
      "learning_rate": 4.495333988212181e-05,
      "loss": 0.9452,
      "step": 41100
    },
    {
      "epoch": 80.94,
      "learning_rate": 4.494106090373281e-05,
      "loss": 0.9394,
      "step": 41200
    },
    {
      "epoch": 81.14,
      "learning_rate": 4.492878192534382e-05,
      "loss": 0.9279,
      "step": 41300
    },
    {
      "epoch": 81.34,
      "learning_rate": 4.491650294695482e-05,
      "loss": 0.908,
      "step": 41400
    },
    {
      "epoch": 81.53,
      "learning_rate": 4.4904223968565816e-05,
      "loss": 0.9329,
      "step": 41500
    },
    {
      "epoch": 81.73,
      "learning_rate": 4.489194499017682e-05,
      "loss": 0.9439,
      "step": 41600
    },
    {
      "epoch": 81.93,
      "learning_rate": 4.4879666011787816e-05,
      "loss": 0.9231,
      "step": 41700
    },
    {
      "epoch": 82.12,
      "learning_rate": 4.486738703339882e-05,
      "loss": 0.9311,
      "step": 41800
    },
    {
      "epoch": 82.32,
      "learning_rate": 4.485510805500983e-05,
      "loss": 0.9136,
      "step": 41900
    },
    {
      "epoch": 82.51,
      "learning_rate": 4.484282907662083e-05,
      "loss": 0.9218,
      "step": 42000
    },
    {
      "epoch": 82.71,
      "learning_rate": 4.483055009823183e-05,
      "loss": 0.9284,
      "step": 42100
    },
    {
      "epoch": 82.91,
      "learning_rate": 4.481827111984283e-05,
      "loss": 0.9406,
      "step": 42200
    },
    {
      "epoch": 83.1,
      "learning_rate": 4.4805992141453834e-05,
      "loss": 0.9233,
      "step": 42300
    },
    {
      "epoch": 83.3,
      "learning_rate": 4.479371316306484e-05,
      "loss": 0.9361,
      "step": 42400
    },
    {
      "epoch": 83.5,
      "learning_rate": 4.478143418467583e-05,
      "loss": 0.9351,
      "step": 42500
    },
    {
      "epoch": 83.69,
      "learning_rate": 4.476915520628684e-05,
      "loss": 0.9242,
      "step": 42600
    },
    {
      "epoch": 83.89,
      "learning_rate": 4.4756876227897846e-05,
      "loss": 0.9255,
      "step": 42700
    },
    {
      "epoch": 84.09,
      "learning_rate": 4.474459724950884e-05,
      "loss": 0.9377,
      "step": 42800
    },
    {
      "epoch": 84.28,
      "learning_rate": 4.4732318271119845e-05,
      "loss": 0.9428,
      "step": 42900
    },
    {
      "epoch": 84.48,
      "learning_rate": 4.4720039292730845e-05,
      "loss": 0.9109,
      "step": 43000
    },
    {
      "epoch": 84.68,
      "learning_rate": 4.470776031434185e-05,
      "loss": 0.9201,
      "step": 43100
    },
    {
      "epoch": 84.87,
      "learning_rate": 4.469548133595285e-05,
      "loss": 0.9397,
      "step": 43200
    },
    {
      "epoch": 85.07,
      "learning_rate": 4.468320235756385e-05,
      "loss": 0.9242,
      "step": 43300
    },
    {
      "epoch": 85.27,
      "learning_rate": 4.467092337917486e-05,
      "loss": 0.9324,
      "step": 43400
    },
    {
      "epoch": 85.46,
      "learning_rate": 4.4658644400785857e-05,
      "loss": 0.9197,
      "step": 43500
    },
    {
      "epoch": 85.66,
      "learning_rate": 4.4646365422396856e-05,
      "loss": 0.9171,
      "step": 43600
    },
    {
      "epoch": 85.85,
      "learning_rate": 4.463408644400786e-05,
      "loss": 0.9408,
      "step": 43700
    },
    {
      "epoch": 86.05,
      "learning_rate": 4.462180746561886e-05,
      "loss": 0.9113,
      "step": 43800
    },
    {
      "epoch": 86.25,
      "learning_rate": 4.460952848722986e-05,
      "loss": 0.9095,
      "step": 43900
    },
    {
      "epoch": 86.44,
      "learning_rate": 4.459724950884087e-05,
      "loss": 0.918,
      "step": 44000
    },
    {
      "epoch": 86.64,
      "learning_rate": 4.458497053045187e-05,
      "loss": 0.9093,
      "step": 44100
    },
    {
      "epoch": 86.84,
      "learning_rate": 4.4572691552062874e-05,
      "loss": 0.9285,
      "step": 44200
    },
    {
      "epoch": 87.03,
      "learning_rate": 4.4560412573673874e-05,
      "loss": 0.9257,
      "step": 44300
    },
    {
      "epoch": 87.23,
      "learning_rate": 4.4548133595284874e-05,
      "loss": 0.9316,
      "step": 44400
    },
    {
      "epoch": 87.43,
      "learning_rate": 4.453585461689588e-05,
      "loss": 0.9101,
      "step": 44500
    },
    {
      "epoch": 87.62,
      "learning_rate": 4.452357563850687e-05,
      "loss": 0.9161,
      "step": 44600
    },
    {
      "epoch": 87.82,
      "learning_rate": 4.451129666011788e-05,
      "loss": 0.9204,
      "step": 44700
    },
    {
      "epoch": 88.02,
      "learning_rate": 4.4499017681728886e-05,
      "loss": 0.9064,
      "step": 44800
    },
    {
      "epoch": 88.21,
      "learning_rate": 4.4486738703339885e-05,
      "loss": 0.8871,
      "step": 44900
    },
    {
      "epoch": 88.41,
      "learning_rate": 4.4474459724950885e-05,
      "loss": 0.9198,
      "step": 45000
    },
    {
      "epoch": 88.61,
      "learning_rate": 4.4462180746561885e-05,
      "loss": 0.911,
      "step": 45100
    },
    {
      "epoch": 88.8,
      "learning_rate": 4.444990176817289e-05,
      "loss": 0.8992,
      "step": 45200
    },
    {
      "epoch": 89.0,
      "learning_rate": 4.44376227897839e-05,
      "loss": 0.93,
      "step": 45300
    },
    {
      "epoch": 89.19,
      "learning_rate": 4.442534381139489e-05,
      "loss": 0.9208,
      "step": 45400
    },
    {
      "epoch": 89.39,
      "learning_rate": 4.44130648330059e-05,
      "loss": 0.9295,
      "step": 45500
    },
    {
      "epoch": 89.59,
      "learning_rate": 4.4400785854616897e-05,
      "loss": 0.8889,
      "step": 45600
    },
    {
      "epoch": 89.78,
      "learning_rate": 4.4388506876227896e-05,
      "loss": 0.9118,
      "step": 45700
    },
    {
      "epoch": 89.98,
      "learning_rate": 4.43762278978389e-05,
      "loss": 0.9181,
      "step": 45800
    },
    {
      "epoch": 90.18,
      "learning_rate": 4.43639489194499e-05,
      "loss": 0.9138,
      "step": 45900
    },
    {
      "epoch": 90.37,
      "learning_rate": 4.435166994106091e-05,
      "loss": 0.8975,
      "step": 46000
    },
    {
      "epoch": 90.57,
      "learning_rate": 4.433939096267191e-05,
      "loss": 0.915,
      "step": 46100
    },
    {
      "epoch": 90.77,
      "learning_rate": 4.432711198428291e-05,
      "loss": 0.9078,
      "step": 46200
    },
    {
      "epoch": 90.96,
      "learning_rate": 4.4314833005893914e-05,
      "loss": 0.9295,
      "step": 46300
    },
    {
      "epoch": 91.16,
      "learning_rate": 4.4302554027504914e-05,
      "loss": 0.8954,
      "step": 46400
    },
    {
      "epoch": 91.36,
      "learning_rate": 4.4290275049115914e-05,
      "loss": 0.895,
      "step": 46500
    },
    {
      "epoch": 91.55,
      "learning_rate": 4.427799607072692e-05,
      "loss": 0.9026,
      "step": 46600
    },
    {
      "epoch": 91.75,
      "learning_rate": 4.426571709233792e-05,
      "loss": 0.8984,
      "step": 46700
    },
    {
      "epoch": 91.94,
      "learning_rate": 4.425343811394892e-05,
      "loss": 0.9222,
      "step": 46800
    },
    {
      "epoch": 92.14,
      "learning_rate": 4.4241159135559926e-05,
      "loss": 0.9182,
      "step": 46900
    },
    {
      "epoch": 92.34,
      "learning_rate": 4.4228880157170925e-05,
      "loss": 0.8884,
      "step": 47000
    },
    {
      "epoch": 92.53,
      "learning_rate": 4.421660117878193e-05,
      "loss": 0.8988,
      "step": 47100
    },
    {
      "epoch": 92.73,
      "learning_rate": 4.4204322200392925e-05,
      "loss": 0.9009,
      "step": 47200
    },
    {
      "epoch": 92.93,
      "learning_rate": 4.419204322200393e-05,
      "loss": 0.9059,
      "step": 47300
    },
    {
      "epoch": 93.12,
      "learning_rate": 4.417976424361494e-05,
      "loss": 0.9114,
      "step": 47400
    },
    {
      "epoch": 93.32,
      "learning_rate": 4.416748526522593e-05,
      "loss": 0.9094,
      "step": 47500
    },
    {
      "epoch": 93.52,
      "learning_rate": 4.415520628683694e-05,
      "loss": 0.9115,
      "step": 47600
    },
    {
      "epoch": 93.71,
      "learning_rate": 4.414292730844794e-05,
      "loss": 0.9044,
      "step": 47700
    },
    {
      "epoch": 93.91,
      "learning_rate": 4.413064833005894e-05,
      "loss": 0.8867,
      "step": 47800
    },
    {
      "epoch": 94.11,
      "learning_rate": 4.411836935166994e-05,
      "loss": 0.9073,
      "step": 47900
    },
    {
      "epoch": 94.3,
      "learning_rate": 4.410609037328094e-05,
      "loss": 0.8982,
      "step": 48000
    },
    {
      "epoch": 94.5,
      "learning_rate": 4.409381139489195e-05,
      "loss": 0.8863,
      "step": 48100
    },
    {
      "epoch": 94.7,
      "learning_rate": 4.408153241650295e-05,
      "loss": 0.8998,
      "step": 48200
    },
    {
      "epoch": 94.89,
      "learning_rate": 4.406925343811395e-05,
      "loss": 0.895,
      "step": 48300
    },
    {
      "epoch": 95.09,
      "learning_rate": 4.4056974459724954e-05,
      "loss": 0.8953,
      "step": 48400
    },
    {
      "epoch": 95.28,
      "learning_rate": 4.4044695481335954e-05,
      "loss": 0.8947,
      "step": 48500
    },
    {
      "epoch": 95.48,
      "learning_rate": 4.4032416502946954e-05,
      "loss": 0.9255,
      "step": 48600
    },
    {
      "epoch": 95.68,
      "learning_rate": 4.402013752455796e-05,
      "loss": 0.8977,
      "step": 48700
    },
    {
      "epoch": 95.87,
      "learning_rate": 4.400785854616896e-05,
      "loss": 0.9074,
      "step": 48800
    },
    {
      "epoch": 96.07,
      "learning_rate": 4.3995579567779966e-05,
      "loss": 0.8809,
      "step": 48900
    },
    {
      "epoch": 96.27,
      "learning_rate": 4.3983300589390966e-05,
      "loss": 0.8902,
      "step": 49000
    },
    {
      "epoch": 96.46,
      "learning_rate": 4.3971021611001965e-05,
      "loss": 0.9017,
      "step": 49100
    },
    {
      "epoch": 96.66,
      "learning_rate": 4.395874263261297e-05,
      "loss": 0.8872,
      "step": 49200
    },
    {
      "epoch": 96.86,
      "learning_rate": 4.394646365422397e-05,
      "loss": 0.8983,
      "step": 49300
    },
    {
      "epoch": 97.05,
      "learning_rate": 4.393418467583497e-05,
      "loss": 0.8956,
      "step": 49400
    },
    {
      "epoch": 97.25,
      "learning_rate": 4.392190569744598e-05,
      "loss": 0.8987,
      "step": 49500
    },
    {
      "epoch": 97.45,
      "learning_rate": 4.390962671905698e-05,
      "loss": 0.9036,
      "step": 49600
    },
    {
      "epoch": 97.64,
      "learning_rate": 4.389734774066798e-05,
      "loss": 0.8973,
      "step": 49700
    },
    {
      "epoch": 97.84,
      "learning_rate": 4.388506876227898e-05,
      "loss": 0.9054,
      "step": 49800
    },
    {
      "epoch": 98.04,
      "learning_rate": 4.387278978388998e-05,
      "loss": 0.8794,
      "step": 49900
    },
    {
      "epoch": 98.23,
      "learning_rate": 4.386051080550098e-05,
      "loss": 0.8852,
      "step": 50000
    },
    {
      "epoch": 98.43,
      "learning_rate": 4.384823182711198e-05,
      "loss": 0.8888,
      "step": 50100
    },
    {
      "epoch": 98.62,
      "learning_rate": 4.383595284872299e-05,
      "loss": 0.8812,
      "step": 50200
    },
    {
      "epoch": 98.82,
      "learning_rate": 4.3823673870333995e-05,
      "loss": 0.8846,
      "step": 50300
    },
    {
      "epoch": 99.02,
      "learning_rate": 4.381139489194499e-05,
      "loss": 0.8822,
      "step": 50400
    },
    {
      "epoch": 99.21,
      "learning_rate": 4.3799115913555994e-05,
      "loss": 0.8821,
      "step": 50500
    },
    {
      "epoch": 99.41,
      "learning_rate": 4.3786836935166994e-05,
      "loss": 0.8842,
      "step": 50600
    },
    {
      "epoch": 99.61,
      "learning_rate": 4.3774557956778e-05,
      "loss": 0.8912,
      "step": 50700
    },
    {
      "epoch": 99.8,
      "learning_rate": 4.3762278978389e-05,
      "loss": 0.9098,
      "step": 50800
    },
    {
      "epoch": 100.0,
      "learning_rate": 4.375e-05,
      "loss": 0.8918,
      "step": 50900
    },
    {
      "epoch": 100.2,
      "learning_rate": 4.3737721021611006e-05,
      "loss": 0.8892,
      "step": 51000
    },
    {
      "epoch": 100.39,
      "learning_rate": 4.3725442043222006e-05,
      "loss": 0.8887,
      "step": 51100
    },
    {
      "epoch": 100.59,
      "learning_rate": 4.3713163064833005e-05,
      "loss": 0.8896,
      "step": 51200
    },
    {
      "epoch": 100.79,
      "learning_rate": 4.370088408644401e-05,
      "loss": 0.8978,
      "step": 51300
    },
    {
      "epoch": 100.98,
      "learning_rate": 4.368860510805501e-05,
      "loss": 0.8862,
      "step": 51400
    },
    {
      "epoch": 101.18,
      "learning_rate": 4.367632612966601e-05,
      "loss": 0.8859,
      "step": 51500
    },
    {
      "epoch": 101.38,
      "learning_rate": 4.366404715127702e-05,
      "loss": 0.8816,
      "step": 51600
    },
    {
      "epoch": 101.57,
      "learning_rate": 4.365176817288802e-05,
      "loss": 0.8793,
      "step": 51700
    },
    {
      "epoch": 101.77,
      "learning_rate": 4.3639489194499023e-05,
      "loss": 0.8848,
      "step": 51800
    },
    {
      "epoch": 101.96,
      "learning_rate": 4.362721021611002e-05,
      "loss": 0.8824,
      "step": 51900
    },
    {
      "epoch": 102.16,
      "learning_rate": 4.361493123772102e-05,
      "loss": 0.875,
      "step": 52000
    },
    {
      "epoch": 102.36,
      "learning_rate": 4.360265225933203e-05,
      "loss": 0.8746,
      "step": 52100
    },
    {
      "epoch": 102.55,
      "learning_rate": 4.359037328094303e-05,
      "loss": 0.8827,
      "step": 52200
    },
    {
      "epoch": 102.75,
      "learning_rate": 4.357809430255403e-05,
      "loss": 0.8928,
      "step": 52300
    },
    {
      "epoch": 102.95,
      "learning_rate": 4.3565815324165035e-05,
      "loss": 0.8815,
      "step": 52400
    },
    {
      "epoch": 103.14,
      "learning_rate": 4.3553536345776034e-05,
      "loss": 0.862,
      "step": 52500
    },
    {
      "epoch": 103.34,
      "learning_rate": 4.3541257367387034e-05,
      "loss": 0.8845,
      "step": 52600
    },
    {
      "epoch": 103.54,
      "learning_rate": 4.352897838899804e-05,
      "loss": 0.8928,
      "step": 52700
    },
    {
      "epoch": 103.73,
      "learning_rate": 4.351669941060904e-05,
      "loss": 0.8832,
      "step": 52800
    },
    {
      "epoch": 103.93,
      "learning_rate": 4.350442043222004e-05,
      "loss": 0.8707,
      "step": 52900
    },
    {
      "epoch": 104.13,
      "learning_rate": 4.349214145383104e-05,
      "loss": 0.8785,
      "step": 53000
    },
    {
      "epoch": 104.32,
      "learning_rate": 4.3479862475442046e-05,
      "loss": 0.8856,
      "step": 53100
    },
    {
      "epoch": 104.52,
      "learning_rate": 4.346758349705305e-05,
      "loss": 0.8807,
      "step": 53200
    },
    {
      "epoch": 104.72,
      "learning_rate": 4.3455304518664045e-05,
      "loss": 0.8612,
      "step": 53300
    },
    {
      "epoch": 104.91,
      "learning_rate": 4.344302554027505e-05,
      "loss": 0.8858,
      "step": 53400
    },
    {
      "epoch": 105.11,
      "learning_rate": 4.343074656188605e-05,
      "loss": 0.8649,
      "step": 53500
    },
    {
      "epoch": 105.3,
      "learning_rate": 4.341846758349706e-05,
      "loss": 0.8588,
      "step": 53600
    },
    {
      "epoch": 105.5,
      "learning_rate": 4.340618860510806e-05,
      "loss": 0.8925,
      "step": 53700
    },
    {
      "epoch": 105.7,
      "learning_rate": 4.339390962671906e-05,
      "loss": 0.8803,
      "step": 53800
    },
    {
      "epoch": 105.89,
      "learning_rate": 4.338163064833006e-05,
      "loss": 0.8748,
      "step": 53900
    },
    {
      "epoch": 106.09,
      "learning_rate": 4.336935166994106e-05,
      "loss": 0.8959,
      "step": 54000
    },
    {
      "epoch": 106.29,
      "learning_rate": 4.335707269155206e-05,
      "loss": 0.8938,
      "step": 54100
    },
    {
      "epoch": 106.48,
      "learning_rate": 4.334479371316307e-05,
      "loss": 0.8726,
      "step": 54200
    },
    {
      "epoch": 106.68,
      "learning_rate": 4.333251473477407e-05,
      "loss": 0.8683,
      "step": 54300
    },
    {
      "epoch": 106.88,
      "learning_rate": 4.332023575638507e-05,
      "loss": 0.8928,
      "step": 54400
    },
    {
      "epoch": 107.07,
      "learning_rate": 4.3307956777996075e-05,
      "loss": 0.8542,
      "step": 54500
    },
    {
      "epoch": 107.27,
      "learning_rate": 4.3295677799607074e-05,
      "loss": 0.8789,
      "step": 54600
    },
    {
      "epoch": 107.47,
      "learning_rate": 4.3283398821218074e-05,
      "loss": 0.8607,
      "step": 54700
    },
    {
      "epoch": 107.66,
      "learning_rate": 4.327111984282908e-05,
      "loss": 0.8829,
      "step": 54800
    },
    {
      "epoch": 107.86,
      "learning_rate": 4.325884086444008e-05,
      "loss": 0.8799,
      "step": 54900
    },
    {
      "epoch": 108.06,
      "learning_rate": 4.3246561886051087e-05,
      "loss": 0.8665,
      "step": 55000
    },
    {
      "epoch": 108.25,
      "learning_rate": 4.323428290766208e-05,
      "loss": 0.8881,
      "step": 55100
    },
    {
      "epoch": 108.45,
      "learning_rate": 4.3222003929273086e-05,
      "loss": 0.8809,
      "step": 55200
    },
    {
      "epoch": 108.64,
      "learning_rate": 4.320972495088409e-05,
      "loss": 0.8525,
      "step": 55300
    },
    {
      "epoch": 108.84,
      "learning_rate": 4.319744597249509e-05,
      "loss": 0.8687,
      "step": 55400
    },
    {
      "epoch": 109.04,
      "learning_rate": 4.318516699410609e-05,
      "loss": 0.8582,
      "step": 55500
    },
    {
      "epoch": 109.23,
      "learning_rate": 4.317288801571709e-05,
      "loss": 0.8734,
      "step": 55600
    },
    {
      "epoch": 109.43,
      "learning_rate": 4.31606090373281e-05,
      "loss": 0.8509,
      "step": 55700
    },
    {
      "epoch": 109.63,
      "learning_rate": 4.31483300589391e-05,
      "loss": 0.8759,
      "step": 55800
    },
    {
      "epoch": 109.82,
      "learning_rate": 4.31360510805501e-05,
      "loss": 0.8915,
      "step": 55900
    },
    {
      "epoch": 110.02,
      "learning_rate": 4.31237721021611e-05,
      "loss": 0.8526,
      "step": 56000
    },
    {
      "epoch": 110.22,
      "learning_rate": 4.311149312377211e-05,
      "loss": 0.8591,
      "step": 56100
    },
    {
      "epoch": 110.41,
      "learning_rate": 4.30992141453831e-05,
      "loss": 0.843,
      "step": 56200
    },
    {
      "epoch": 110.61,
      "learning_rate": 4.308693516699411e-05,
      "loss": 0.8675,
      "step": 56300
    },
    {
      "epoch": 110.81,
      "learning_rate": 4.307465618860511e-05,
      "loss": 0.8901,
      "step": 56400
    },
    {
      "epoch": 111.0,
      "learning_rate": 4.306237721021611e-05,
      "loss": 0.8564,
      "step": 56500
    },
    {
      "epoch": 111.2,
      "learning_rate": 4.3050098231827115e-05,
      "loss": 0.8638,
      "step": 56600
    },
    {
      "epoch": 111.39,
      "learning_rate": 4.3037819253438114e-05,
      "loss": 0.87,
      "step": 56700
    },
    {
      "epoch": 111.59,
      "learning_rate": 4.302554027504912e-05,
      "loss": 0.8839,
      "step": 56800
    },
    {
      "epoch": 111.79,
      "learning_rate": 4.301326129666012e-05,
      "loss": 0.8568,
      "step": 56900
    },
    {
      "epoch": 111.98,
      "learning_rate": 4.300098231827112e-05,
      "loss": 0.8719,
      "step": 57000
    },
    {
      "epoch": 112.18,
      "learning_rate": 4.2988703339882126e-05,
      "loss": 0.8526,
      "step": 57100
    },
    {
      "epoch": 112.38,
      "learning_rate": 4.2976424361493126e-05,
      "loss": 0.8472,
      "step": 57200
    },
    {
      "epoch": 112.57,
      "learning_rate": 4.2964145383104126e-05,
      "loss": 0.8696,
      "step": 57300
    },
    {
      "epoch": 112.77,
      "learning_rate": 4.295186640471513e-05,
      "loss": 0.872,
      "step": 57400
    },
    {
      "epoch": 112.97,
      "learning_rate": 4.293958742632613e-05,
      "loss": 0.8603,
      "step": 57500
    },
    {
      "epoch": 113.16,
      "learning_rate": 4.292730844793713e-05,
      "loss": 0.8597,
      "step": 57600
    },
    {
      "epoch": 113.36,
      "learning_rate": 4.291502946954814e-05,
      "loss": 0.8645,
      "step": 57700
    },
    {
      "epoch": 113.56,
      "learning_rate": 4.290275049115914e-05,
      "loss": 0.857,
      "step": 57800
    },
    {
      "epoch": 113.75,
      "learning_rate": 4.2890471512770144e-05,
      "loss": 0.8876,
      "step": 57900
    },
    {
      "epoch": 113.95,
      "learning_rate": 4.287819253438114e-05,
      "loss": 0.8697,
      "step": 58000
    },
    {
      "epoch": 114.15,
      "learning_rate": 4.286591355599214e-05,
      "loss": 0.8631,
      "step": 58100
    },
    {
      "epoch": 114.34,
      "learning_rate": 4.285363457760315e-05,
      "loss": 0.8711,
      "step": 58200
    },
    {
      "epoch": 114.54,
      "learning_rate": 4.284135559921415e-05,
      "loss": 0.8547,
      "step": 58300
    },
    {
      "epoch": 114.73,
      "learning_rate": 4.282907662082515e-05,
      "loss": 0.8589,
      "step": 58400
    },
    {
      "epoch": 114.93,
      "learning_rate": 4.281679764243615e-05,
      "loss": 0.8288,
      "step": 58500
    },
    {
      "epoch": 115.13,
      "learning_rate": 4.2804518664047155e-05,
      "loss": 0.8407,
      "step": 58600
    },
    {
      "epoch": 115.32,
      "learning_rate": 4.2792239685658155e-05,
      "loss": 0.8626,
      "step": 58700
    },
    {
      "epoch": 115.52,
      "learning_rate": 4.2779960707269154e-05,
      "loss": 0.8509,
      "step": 58800
    },
    {
      "epoch": 115.72,
      "learning_rate": 4.276768172888016e-05,
      "loss": 0.861,
      "step": 58900
    },
    {
      "epoch": 115.91,
      "learning_rate": 4.275540275049116e-05,
      "loss": 0.8736,
      "step": 59000
    },
    {
      "epoch": 116.11,
      "learning_rate": 4.274312377210216e-05,
      "loss": 0.8526,
      "step": 59100
    },
    {
      "epoch": 116.31,
      "learning_rate": 4.2730844793713166e-05,
      "loss": 0.8805,
      "step": 59200
    },
    {
      "epoch": 116.5,
      "learning_rate": 4.2718565815324166e-05,
      "loss": 0.8541,
      "step": 59300
    },
    {
      "epoch": 116.7,
      "learning_rate": 4.2706286836935166e-05,
      "loss": 0.8471,
      "step": 59400
    },
    {
      "epoch": 116.9,
      "learning_rate": 4.269400785854617e-05,
      "loss": 0.8502,
      "step": 59500
    },
    {
      "epoch": 117.09,
      "learning_rate": 4.268172888015717e-05,
      "loss": 0.8617,
      "step": 59600
    },
    {
      "epoch": 117.29,
      "learning_rate": 4.266944990176818e-05,
      "loss": 0.8707,
      "step": 59700
    },
    {
      "epoch": 117.49,
      "learning_rate": 4.265717092337918e-05,
      "loss": 0.844,
      "step": 59800
    },
    {
      "epoch": 117.68,
      "learning_rate": 4.264489194499018e-05,
      "loss": 0.848,
      "step": 59900
    },
    {
      "epoch": 117.88,
      "learning_rate": 4.2632612966601184e-05,
      "loss": 0.8504,
      "step": 60000
    },
    {
      "epoch": 118.07,
      "learning_rate": 4.2620333988212184e-05,
      "loss": 0.8538,
      "step": 60100
    },
    {
      "epoch": 118.27,
      "learning_rate": 4.260805500982318e-05,
      "loss": 0.8548,
      "step": 60200
    },
    {
      "epoch": 118.47,
      "learning_rate": 4.259577603143419e-05,
      "loss": 0.8637,
      "step": 60300
    },
    {
      "epoch": 118.66,
      "learning_rate": 4.258349705304519e-05,
      "loss": 0.8557,
      "step": 60400
    },
    {
      "epoch": 118.86,
      "learning_rate": 4.257121807465619e-05,
      "loss": 0.8532,
      "step": 60500
    },
    {
      "epoch": 119.06,
      "learning_rate": 4.255893909626719e-05,
      "loss": 0.8421,
      "step": 60600
    },
    {
      "epoch": 119.25,
      "learning_rate": 4.2546660117878195e-05,
      "loss": 0.8883,
      "step": 60700
    },
    {
      "epoch": 119.45,
      "learning_rate": 4.25343811394892e-05,
      "loss": 0.8564,
      "step": 60800
    },
    {
      "epoch": 119.65,
      "learning_rate": 4.2522102161100194e-05,
      "loss": 0.8582,
      "step": 60900
    },
    {
      "epoch": 119.84,
      "learning_rate": 4.25098231827112e-05,
      "loss": 0.8377,
      "step": 61000
    },
    {
      "epoch": 120.04,
      "learning_rate": 4.249754420432221e-05,
      "loss": 0.8413,
      "step": 61100
    },
    {
      "epoch": 120.24,
      "learning_rate": 4.24852652259332e-05,
      "loss": 0.8588,
      "step": 61200
    },
    {
      "epoch": 120.43,
      "learning_rate": 4.2472986247544206e-05,
      "loss": 0.8529,
      "step": 61300
    },
    {
      "epoch": 120.63,
      "learning_rate": 4.2460707269155206e-05,
      "loss": 0.8594,
      "step": 61400
    },
    {
      "epoch": 120.83,
      "learning_rate": 4.244842829076621e-05,
      "loss": 0.8431,
      "step": 61500
    },
    {
      "epoch": 121.02,
      "learning_rate": 4.243614931237721e-05,
      "loss": 0.8513,
      "step": 61600
    },
    {
      "epoch": 121.22,
      "learning_rate": 4.242387033398821e-05,
      "loss": 0.8354,
      "step": 61700
    },
    {
      "epoch": 121.41,
      "learning_rate": 4.241159135559922e-05,
      "loss": 0.8386,
      "step": 61800
    },
    {
      "epoch": 121.61,
      "learning_rate": 4.239931237721022e-05,
      "loss": 0.8535,
      "step": 61900
    },
    {
      "epoch": 121.81,
      "learning_rate": 4.238703339882122e-05,
      "loss": 0.8594,
      "step": 62000
    },
    {
      "epoch": 122.0,
      "learning_rate": 4.2374754420432224e-05,
      "loss": 0.8634,
      "step": 62100
    },
    {
      "epoch": 122.2,
      "learning_rate": 4.2362475442043223e-05,
      "loss": 0.853,
      "step": 62200
    },
    {
      "epoch": 122.4,
      "learning_rate": 4.235019646365422e-05,
      "loss": 0.8395,
      "step": 62300
    },
    {
      "epoch": 122.59,
      "learning_rate": 4.233791748526523e-05,
      "loss": 0.844,
      "step": 62400
    },
    {
      "epoch": 122.79,
      "learning_rate": 4.232563850687623e-05,
      "loss": 0.8456,
      "step": 62500
    },
    {
      "epoch": 122.99,
      "learning_rate": 4.2313359528487236e-05,
      "loss": 0.8392,
      "step": 62600
    },
    {
      "epoch": 123.18,
      "learning_rate": 4.2301080550098235e-05,
      "loss": 0.8432,
      "step": 62700
    },
    {
      "epoch": 123.38,
      "learning_rate": 4.2288801571709235e-05,
      "loss": 0.8568,
      "step": 62800
    },
    {
      "epoch": 123.58,
      "learning_rate": 4.227652259332024e-05,
      "loss": 0.8297,
      "step": 62900
    },
    {
      "epoch": 123.77,
      "learning_rate": 4.2264243614931234e-05,
      "loss": 0.847,
      "step": 63000
    },
    {
      "epoch": 123.97,
      "learning_rate": 4.225196463654224e-05,
      "loss": 0.8473,
      "step": 63100
    },
    {
      "epoch": 124.17,
      "learning_rate": 4.223968565815325e-05,
      "loss": 0.8372,
      "step": 63200
    },
    {
      "epoch": 124.36,
      "learning_rate": 4.222740667976425e-05,
      "loss": 0.8586,
      "step": 63300
    },
    {
      "epoch": 124.56,
      "learning_rate": 4.2215127701375246e-05,
      "loss": 0.8596,
      "step": 63400
    },
    {
      "epoch": 124.75,
      "learning_rate": 4.2202848722986246e-05,
      "loss": 0.8461,
      "step": 63500
    },
    {
      "epoch": 124.95,
      "learning_rate": 4.219056974459725e-05,
      "loss": 0.8344,
      "step": 63600
    },
    {
      "epoch": 125.15,
      "learning_rate": 4.217829076620826e-05,
      "loss": 0.8326,
      "step": 63700
    },
    {
      "epoch": 125.34,
      "learning_rate": 4.216601178781925e-05,
      "loss": 0.8411,
      "step": 63800
    },
    {
      "epoch": 125.54,
      "learning_rate": 4.215373280943026e-05,
      "loss": 0.8469,
      "step": 63900
    },
    {
      "epoch": 125.74,
      "learning_rate": 4.214145383104126e-05,
      "loss": 0.84,
      "step": 64000
    },
    {
      "epoch": 125.93,
      "learning_rate": 4.212917485265226e-05,
      "loss": 0.8592,
      "step": 64100
    },
    {
      "epoch": 126.13,
      "learning_rate": 4.2116895874263264e-05,
      "loss": 0.8307,
      "step": 64200
    },
    {
      "epoch": 126.33,
      "learning_rate": 4.210461689587426e-05,
      "loss": 0.8434,
      "step": 64300
    },
    {
      "epoch": 126.52,
      "learning_rate": 4.209233791748527e-05,
      "loss": 0.8415,
      "step": 64400
    },
    {
      "epoch": 126.72,
      "learning_rate": 4.208005893909627e-05,
      "loss": 0.8547,
      "step": 64500
    },
    {
      "epoch": 126.92,
      "learning_rate": 4.206777996070727e-05,
      "loss": 0.8348,
      "step": 64600
    },
    {
      "epoch": 127.11,
      "learning_rate": 4.2055500982318275e-05,
      "loss": 0.8471,
      "step": 64700
    },
    {
      "epoch": 127.31,
      "learning_rate": 4.2043222003929275e-05,
      "loss": 0.8259,
      "step": 64800
    },
    {
      "epoch": 127.5,
      "learning_rate": 4.2030943025540275e-05,
      "loss": 0.826,
      "step": 64900
    },
    {
      "epoch": 127.7,
      "learning_rate": 4.201866404715128e-05,
      "loss": 0.8228,
      "step": 65000
    },
    {
      "epoch": 127.9,
      "learning_rate": 4.200638506876228e-05,
      "loss": 0.8376,
      "step": 65100
    },
    {
      "epoch": 128.09,
      "learning_rate": 4.199410609037328e-05,
      "loss": 0.8264,
      "step": 65200
    },
    {
      "epoch": 128.29,
      "learning_rate": 4.198182711198429e-05,
      "loss": 0.8449,
      "step": 65300
    },
    {
      "epoch": 128.49,
      "learning_rate": 4.1969548133595287e-05,
      "loss": 0.8355,
      "step": 65400
    },
    {
      "epoch": 128.68,
      "learning_rate": 4.195726915520629e-05,
      "loss": 0.8347,
      "step": 65500
    },
    {
      "epoch": 128.88,
      "learning_rate": 4.194499017681729e-05,
      "loss": 0.843,
      "step": 65600
    },
    {
      "epoch": 129.08,
      "learning_rate": 4.193271119842829e-05,
      "loss": 0.83,
      "step": 65700
    },
    {
      "epoch": 129.27,
      "learning_rate": 4.19204322200393e-05,
      "loss": 0.8312,
      "step": 65800
    },
    {
      "epoch": 129.47,
      "learning_rate": 4.190815324165029e-05,
      "loss": 0.8383,
      "step": 65900
    },
    {
      "epoch": 129.67,
      "learning_rate": 4.18958742632613e-05,
      "loss": 0.8317,
      "step": 66000
    },
    {
      "epoch": 129.86,
      "learning_rate": 4.1883595284872304e-05,
      "loss": 0.8476,
      "step": 66100
    },
    {
      "epoch": 130.06,
      "learning_rate": 4.1871316306483304e-05,
      "loss": 0.8302,
      "step": 66200
    },
    {
      "epoch": 130.26,
      "learning_rate": 4.1859037328094304e-05,
      "loss": 0.824,
      "step": 66300
    },
    {
      "epoch": 130.45,
      "learning_rate": 4.18467583497053e-05,
      "loss": 0.8268,
      "step": 66400
    },
    {
      "epoch": 130.65,
      "learning_rate": 4.183447937131631e-05,
      "loss": 0.8268,
      "step": 66500
    },
    {
      "epoch": 130.84,
      "learning_rate": 4.1822200392927316e-05,
      "loss": 0.8498,
      "step": 66600
    },
    {
      "epoch": 131.04,
      "learning_rate": 4.180992141453831e-05,
      "loss": 0.802,
      "step": 66700
    },
    {
      "epoch": 131.24,
      "learning_rate": 4.1797642436149315e-05,
      "loss": 0.8231,
      "step": 66800
    },
    {
      "epoch": 131.43,
      "learning_rate": 4.1785363457760315e-05,
      "loss": 0.8233,
      "step": 66900
    },
    {
      "epoch": 131.63,
      "learning_rate": 4.1773084479371315e-05,
      "loss": 0.8278,
      "step": 67000
    },
    {
      "epoch": 131.83,
      "learning_rate": 4.176080550098232e-05,
      "loss": 0.8053,
      "step": 67100
    },
    {
      "epoch": 132.02,
      "learning_rate": 4.174852652259332e-05,
      "loss": 0.8431,
      "step": 67200
    },
    {
      "epoch": 132.22,
      "learning_rate": 4.173624754420433e-05,
      "loss": 0.8173,
      "step": 67300
    },
    {
      "epoch": 132.42,
      "learning_rate": 4.172396856581533e-05,
      "loss": 0.8298,
      "step": 67400
    },
    {
      "epoch": 132.61,
      "learning_rate": 4.1711689587426326e-05,
      "loss": 0.8311,
      "step": 67500
    },
    {
      "epoch": 132.81,
      "learning_rate": 4.169941060903733e-05,
      "loss": 0.8432,
      "step": 67600
    },
    {
      "epoch": 133.01,
      "learning_rate": 4.168713163064833e-05,
      "loss": 0.8325,
      "step": 67700
    },
    {
      "epoch": 133.2,
      "learning_rate": 4.167485265225933e-05,
      "loss": 0.8367,
      "step": 67800
    },
    {
      "epoch": 133.4,
      "learning_rate": 4.166257367387034e-05,
      "loss": 0.8181,
      "step": 67900
    },
    {
      "epoch": 133.6,
      "learning_rate": 4.165029469548134e-05,
      "loss": 0.851,
      "step": 68000
    },
    {
      "epoch": 133.79,
      "learning_rate": 4.163801571709234e-05,
      "loss": 0.8276,
      "step": 68100
    },
    {
      "epoch": 133.99,
      "learning_rate": 4.1625736738703344e-05,
      "loss": 0.8345,
      "step": 68200
    },
    {
      "epoch": 134.18,
      "learning_rate": 4.1613457760314344e-05,
      "loss": 0.8224,
      "step": 68300
    },
    {
      "epoch": 134.38,
      "learning_rate": 4.160117878192535e-05,
      "loss": 0.8431,
      "step": 68400
    },
    {
      "epoch": 134.58,
      "learning_rate": 4.158889980353634e-05,
      "loss": 0.8497,
      "step": 68500
    },
    {
      "epoch": 134.77,
      "learning_rate": 4.157662082514735e-05,
      "loss": 0.8186,
      "step": 68600
    },
    {
      "epoch": 134.97,
      "learning_rate": 4.1564341846758356e-05,
      "loss": 0.8391,
      "step": 68700
    },
    {
      "epoch": 135.17,
      "learning_rate": 4.155206286836935e-05,
      "loss": 0.8244,
      "step": 68800
    },
    {
      "epoch": 135.36,
      "learning_rate": 4.1539783889980355e-05,
      "loss": 0.8333,
      "step": 68900
    },
    {
      "epoch": 135.56,
      "learning_rate": 4.1527504911591355e-05,
      "loss": 0.8417,
      "step": 69000
    },
    {
      "epoch": 135.76,
      "learning_rate": 4.151522593320236e-05,
      "loss": 0.8464,
      "step": 69100
    },
    {
      "epoch": 135.95,
      "learning_rate": 4.150294695481336e-05,
      "loss": 0.8229,
      "step": 69200
    },
    {
      "epoch": 136.15,
      "learning_rate": 4.149066797642436e-05,
      "loss": 0.8348,
      "step": 69300
    },
    {
      "epoch": 136.35,
      "learning_rate": 4.147838899803537e-05,
      "loss": 0.8296,
      "step": 69400
    },
    {
      "epoch": 136.54,
      "learning_rate": 4.146611001964637e-05,
      "loss": 0.8174,
      "step": 69500
    },
    {
      "epoch": 136.74,
      "learning_rate": 4.1453831041257366e-05,
      "loss": 0.8418,
      "step": 69600
    },
    {
      "epoch": 136.94,
      "learning_rate": 4.144155206286837e-05,
      "loss": 0.8205,
      "step": 69700
    },
    {
      "epoch": 137.13,
      "learning_rate": 4.142927308447937e-05,
      "loss": 0.8406,
      "step": 69800
    },
    {
      "epoch": 137.33,
      "learning_rate": 4.141699410609037e-05,
      "loss": 0.8242,
      "step": 69900
    },
    {
      "epoch": 137.52,
      "learning_rate": 4.140471512770138e-05,
      "loss": 0.8237,
      "step": 70000
    },
    {
      "epoch": 137.72,
      "learning_rate": 4.139243614931238e-05,
      "loss": 0.826,
      "step": 70100
    },
    {
      "epoch": 137.92,
      "learning_rate": 4.1380157170923385e-05,
      "loss": 0.8129,
      "step": 70200
    },
    {
      "epoch": 138.11,
      "learning_rate": 4.1367878192534384e-05,
      "loss": 0.8063,
      "step": 70300
    },
    {
      "epoch": 138.31,
      "learning_rate": 4.1355599214145384e-05,
      "loss": 0.8156,
      "step": 70400
    },
    {
      "epoch": 138.51,
      "learning_rate": 4.134332023575639e-05,
      "loss": 0.8188,
      "step": 70500
    },
    {
      "epoch": 138.7,
      "learning_rate": 4.133104125736739e-05,
      "loss": 0.8277,
      "step": 70600
    },
    {
      "epoch": 138.9,
      "learning_rate": 4.131876227897839e-05,
      "loss": 0.8192,
      "step": 70700
    },
    {
      "epoch": 139.1,
      "learning_rate": 4.1306483300589396e-05,
      "loss": 0.8281,
      "step": 70800
    },
    {
      "epoch": 139.29,
      "learning_rate": 4.1294204322200396e-05,
      "loss": 0.8002,
      "step": 70900
    },
    {
      "epoch": 139.49,
      "learning_rate": 4.1281925343811395e-05,
      "loss": 0.8132,
      "step": 71000
    },
    {
      "epoch": 139.69,
      "learning_rate": 4.12696463654224e-05,
      "loss": 0.8398,
      "step": 71100
    },
    {
      "epoch": 139.88,
      "learning_rate": 4.12573673870334e-05,
      "loss": 0.8166,
      "step": 71200
    },
    {
      "epoch": 140.08,
      "learning_rate": 4.12450884086444e-05,
      "loss": 0.813,
      "step": 71300
    },
    {
      "epoch": 140.28,
      "learning_rate": 4.12328094302554e-05,
      "loss": 0.8364,
      "step": 71400
    },
    {
      "epoch": 140.47,
      "learning_rate": 4.122053045186641e-05,
      "loss": 0.8079,
      "step": 71500
    },
    {
      "epoch": 140.67,
      "learning_rate": 4.1208251473477413e-05,
      "loss": 0.8176,
      "step": 71600
    },
    {
      "epoch": 140.86,
      "learning_rate": 4.1195972495088406e-05,
      "loss": 0.8161,
      "step": 71700
    },
    {
      "epoch": 141.06,
      "learning_rate": 4.118369351669941e-05,
      "loss": 0.8232,
      "step": 71800
    },
    {
      "epoch": 141.26,
      "learning_rate": 4.117141453831041e-05,
      "loss": 0.827,
      "step": 71900
    },
    {
      "epoch": 141.45,
      "learning_rate": 4.115913555992142e-05,
      "loss": 0.8215,
      "step": 72000
    },
    {
      "epoch": 141.65,
      "learning_rate": 4.114685658153242e-05,
      "loss": 0.8181,
      "step": 72100
    },
    {
      "epoch": 141.85,
      "learning_rate": 4.113457760314342e-05,
      "loss": 0.8195,
      "step": 72200
    },
    {
      "epoch": 142.04,
      "learning_rate": 4.1122298624754425e-05,
      "loss": 0.8132,
      "step": 72300
    },
    {
      "epoch": 142.24,
      "learning_rate": 4.1110019646365424e-05,
      "loss": 0.8166,
      "step": 72400
    },
    {
      "epoch": 142.44,
      "learning_rate": 4.1097740667976424e-05,
      "loss": 0.826,
      "step": 72500
    },
    {
      "epoch": 142.63,
      "learning_rate": 4.108546168958743e-05,
      "loss": 0.8155,
      "step": 72600
    },
    {
      "epoch": 142.83,
      "learning_rate": 4.107318271119843e-05,
      "loss": 0.8064,
      "step": 72700
    },
    {
      "epoch": 143.03,
      "learning_rate": 4.106090373280943e-05,
      "loss": 0.8325,
      "step": 72800
    },
    {
      "epoch": 143.22,
      "learning_rate": 4.1048624754420436e-05,
      "loss": 0.8102,
      "step": 72900
    },
    {
      "epoch": 143.42,
      "learning_rate": 4.1036345776031436e-05,
      "loss": 0.8234,
      "step": 73000
    },
    {
      "epoch": 143.61,
      "learning_rate": 4.102406679764244e-05,
      "loss": 0.8096,
      "step": 73100
    },
    {
      "epoch": 143.81,
      "learning_rate": 4.101178781925344e-05,
      "loss": 0.8111,
      "step": 73200
    },
    {
      "epoch": 144.01,
      "learning_rate": 4.099950884086444e-05,
      "loss": 0.8152,
      "step": 73300
    },
    {
      "epoch": 144.2,
      "learning_rate": 4.098722986247545e-05,
      "loss": 0.8163,
      "step": 73400
    },
    {
      "epoch": 144.4,
      "learning_rate": 4.097495088408644e-05,
      "loss": 0.8099,
      "step": 73500
    },
    {
      "epoch": 144.6,
      "learning_rate": 4.096267190569745e-05,
      "loss": 0.8052,
      "step": 73600
    },
    {
      "epoch": 144.79,
      "learning_rate": 4.0950392927308453e-05,
      "loss": 0.803,
      "step": 73700
    },
    {
      "epoch": 144.99,
      "learning_rate": 4.093811394891945e-05,
      "loss": 0.8031,
      "step": 73800
    },
    {
      "epoch": 145.19,
      "learning_rate": 4.092583497053045e-05,
      "loss": 0.8117,
      "step": 73900
    },
    {
      "epoch": 145.38,
      "learning_rate": 4.091355599214146e-05,
      "loss": 0.8171,
      "step": 74000
    },
    {
      "epoch": 145.58,
      "learning_rate": 4.090127701375246e-05,
      "loss": 0.8138,
      "step": 74100
    },
    {
      "epoch": 145.78,
      "learning_rate": 4.088899803536346e-05,
      "loss": 0.7975,
      "step": 74200
    },
    {
      "epoch": 145.97,
      "learning_rate": 4.087671905697446e-05,
      "loss": 0.8071,
      "step": 74300
    },
    {
      "epoch": 146.17,
      "learning_rate": 4.0864440078585464e-05,
      "loss": 0.7979,
      "step": 74400
    },
    {
      "epoch": 146.37,
      "learning_rate": 4.085216110019647e-05,
      "loss": 0.8166,
      "step": 74500
    },
    {
      "epoch": 146.56,
      "learning_rate": 4.0839882121807464e-05,
      "loss": 0.8226,
      "step": 74600
    },
    {
      "epoch": 146.76,
      "learning_rate": 4.082760314341847e-05,
      "loss": 0.8109,
      "step": 74700
    },
    {
      "epoch": 146.95,
      "learning_rate": 4.081532416502947e-05,
      "loss": 0.8081,
      "step": 74800
    },
    {
      "epoch": 147.15,
      "learning_rate": 4.0803045186640476e-05,
      "loss": 0.8289,
      "step": 74900
    },
    {
      "epoch": 147.35,
      "learning_rate": 4.0790766208251476e-05,
      "loss": 0.8261,
      "step": 75000
    },
    {
      "epoch": 147.54,
      "learning_rate": 4.0778487229862475e-05,
      "loss": 0.8155,
      "step": 75100
    },
    {
      "epoch": 147.74,
      "learning_rate": 4.076620825147348e-05,
      "loss": 0.802,
      "step": 75200
    },
    {
      "epoch": 147.94,
      "learning_rate": 4.075392927308448e-05,
      "loss": 0.8319,
      "step": 75300
    },
    {
      "epoch": 148.13,
      "learning_rate": 4.074165029469548e-05,
      "loss": 0.785,
      "step": 75400
    },
    {
      "epoch": 148.33,
      "learning_rate": 4.072937131630649e-05,
      "loss": 0.7901,
      "step": 75500
    },
    {
      "epoch": 148.53,
      "learning_rate": 4.071709233791749e-05,
      "loss": 0.8244,
      "step": 75600
    },
    {
      "epoch": 148.72,
      "learning_rate": 4.070481335952849e-05,
      "loss": 0.7955,
      "step": 75700
    },
    {
      "epoch": 148.92,
      "learning_rate": 4.069253438113949e-05,
      "loss": 0.8263,
      "step": 75800
    },
    {
      "epoch": 149.12,
      "learning_rate": 4.068025540275049e-05,
      "loss": 0.7999,
      "step": 75900
    },
    {
      "epoch": 149.31,
      "learning_rate": 4.066797642436149e-05,
      "loss": 0.8016,
      "step": 76000
    },
    {
      "epoch": 149.51,
      "learning_rate": 4.06556974459725e-05,
      "loss": 0.8217,
      "step": 76100
    },
    {
      "epoch": 149.71,
      "learning_rate": 4.06434184675835e-05,
      "loss": 0.8068,
      "step": 76200
    },
    {
      "epoch": 149.9,
      "learning_rate": 4.0631139489194505e-05,
      "loss": 0.8036,
      "step": 76300
    },
    {
      "epoch": 150.1,
      "learning_rate": 4.06188605108055e-05,
      "loss": 0.8051,
      "step": 76400
    },
    {
      "epoch": 150.29,
      "learning_rate": 4.0606581532416504e-05,
      "loss": 0.7944,
      "step": 76500
    },
    {
      "epoch": 150.49,
      "learning_rate": 4.059430255402751e-05,
      "loss": 0.8087,
      "step": 76600
    },
    {
      "epoch": 150.69,
      "learning_rate": 4.058202357563851e-05,
      "loss": 0.8029,
      "step": 76700
    },
    {
      "epoch": 150.88,
      "learning_rate": 4.056974459724951e-05,
      "loss": 0.8127,
      "step": 76800
    },
    {
      "epoch": 151.08,
      "learning_rate": 4.055746561886051e-05,
      "loss": 0.8138,
      "step": 76900
    },
    {
      "epoch": 151.28,
      "learning_rate": 4.0545186640471516e-05,
      "loss": 0.8156,
      "step": 77000
    },
    {
      "epoch": 151.47,
      "learning_rate": 4.0532907662082516e-05,
      "loss": 0.8039,
      "step": 77100
    },
    {
      "epoch": 151.67,
      "learning_rate": 4.0520628683693515e-05,
      "loss": 0.7803,
      "step": 77200
    },
    {
      "epoch": 151.87,
      "learning_rate": 4.050834970530452e-05,
      "loss": 0.7829,
      "step": 77300
    },
    {
      "epoch": 152.06,
      "learning_rate": 4.049607072691552e-05,
      "loss": 0.8093,
      "step": 77400
    },
    {
      "epoch": 152.26,
      "learning_rate": 4.048379174852652e-05,
      "loss": 0.7932,
      "step": 77500
    },
    {
      "epoch": 152.46,
      "learning_rate": 4.047151277013753e-05,
      "loss": 0.8252,
      "step": 77600
    },
    {
      "epoch": 152.65,
      "learning_rate": 4.045923379174853e-05,
      "loss": 0.8158,
      "step": 77700
    },
    {
      "epoch": 152.85,
      "learning_rate": 4.044695481335953e-05,
      "loss": 0.7965,
      "step": 77800
    },
    {
      "epoch": 153.05,
      "learning_rate": 4.043467583497053e-05,
      "loss": 0.8112,
      "step": 77900
    },
    {
      "epoch": 153.24,
      "learning_rate": 4.042239685658153e-05,
      "loss": 0.7992,
      "step": 78000
    },
    {
      "epoch": 153.44,
      "learning_rate": 4.041011787819254e-05,
      "loss": 0.8117,
      "step": 78100
    },
    {
      "epoch": 153.63,
      "learning_rate": 4.039783889980354e-05,
      "loss": 0.7896,
      "step": 78200
    },
    {
      "epoch": 153.83,
      "learning_rate": 4.038555992141454e-05,
      "loss": 0.8003,
      "step": 78300
    },
    {
      "epoch": 154.03,
      "learning_rate": 4.0373280943025545e-05,
      "loss": 0.7974,
      "step": 78400
    },
    {
      "epoch": 154.22,
      "learning_rate": 4.0361001964636545e-05,
      "loss": 0.7923,
      "step": 78500
    },
    {
      "epoch": 154.42,
      "learning_rate": 4.0348722986247544e-05,
      "loss": 0.8034,
      "step": 78600
    },
    {
      "epoch": 154.62,
      "learning_rate": 4.033644400785855e-05,
      "loss": 0.796,
      "step": 78700
    },
    {
      "epoch": 154.81,
      "learning_rate": 4.032416502946955e-05,
      "loss": 0.797,
      "step": 78800
    },
    {
      "epoch": 155.01,
      "learning_rate": 4.031188605108055e-05,
      "loss": 0.8014,
      "step": 78900
    },
    {
      "epoch": 155.21,
      "learning_rate": 4.0299607072691556e-05,
      "loss": 0.8023,
      "step": 79000
    },
    {
      "epoch": 155.4,
      "learning_rate": 4.0287328094302556e-05,
      "loss": 0.8041,
      "step": 79100
    },
    {
      "epoch": 155.6,
      "learning_rate": 4.027504911591356e-05,
      "loss": 0.7983,
      "step": 79200
    },
    {
      "epoch": 155.8,
      "learning_rate": 4.0262770137524555e-05,
      "loss": 0.813,
      "step": 79300
    },
    {
      "epoch": 155.99,
      "learning_rate": 4.025049115913556e-05,
      "loss": 0.8101,
      "step": 79400
    },
    {
      "epoch": 156.19,
      "learning_rate": 4.023821218074657e-05,
      "loss": 0.7806,
      "step": 79500
    },
    {
      "epoch": 156.39,
      "learning_rate": 4.022593320235756e-05,
      "loss": 0.7756,
      "step": 79600
    },
    {
      "epoch": 156.58,
      "learning_rate": 4.021365422396857e-05,
      "loss": 0.804,
      "step": 79700
    },
    {
      "epoch": 156.78,
      "learning_rate": 4.020137524557957e-05,
      "loss": 0.8131,
      "step": 79800
    },
    {
      "epoch": 156.97,
      "learning_rate": 4.0189096267190574e-05,
      "loss": 0.8116,
      "step": 79900
    },
    {
      "epoch": 157.17,
      "learning_rate": 4.017681728880157e-05,
      "loss": 0.7919,
      "step": 80000
    },
    {
      "epoch": 157.37,
      "learning_rate": 4.016453831041257e-05,
      "loss": 0.7958,
      "step": 80100
    },
    {
      "epoch": 157.56,
      "learning_rate": 4.015225933202358e-05,
      "loss": 0.7955,
      "step": 80200
    },
    {
      "epoch": 157.76,
      "learning_rate": 4.013998035363458e-05,
      "loss": 0.7981,
      "step": 80300
    },
    {
      "epoch": 157.96,
      "learning_rate": 4.012770137524558e-05,
      "loss": 0.8052,
      "step": 80400
    },
    {
      "epoch": 158.15,
      "learning_rate": 4.0115422396856585e-05,
      "loss": 0.8026,
      "step": 80500
    },
    {
      "epoch": 158.35,
      "learning_rate": 4.0103143418467585e-05,
      "loss": 0.8042,
      "step": 80600
    },
    {
      "epoch": 158.55,
      "learning_rate": 4.0090864440078584e-05,
      "loss": 0.7978,
      "step": 80700
    },
    {
      "epoch": 158.74,
      "learning_rate": 4.007858546168959e-05,
      "loss": 0.7971,
      "step": 80800
    },
    {
      "epoch": 158.94,
      "learning_rate": 4.006630648330059e-05,
      "loss": 0.7776,
      "step": 80900
    },
    {
      "epoch": 159.14,
      "learning_rate": 4.00540275049116e-05,
      "loss": 0.7886,
      "step": 81000
    },
    {
      "epoch": 159.33,
      "learning_rate": 4.0041748526522596e-05,
      "loss": 0.8024,
      "step": 81100
    },
    {
      "epoch": 159.53,
      "learning_rate": 4.0029469548133596e-05,
      "loss": 0.797,
      "step": 81200
    },
    {
      "epoch": 159.72,
      "learning_rate": 4.00171905697446e-05,
      "loss": 0.7962,
      "step": 81300
    },
    {
      "epoch": 159.92,
      "learning_rate": 4.00049115913556e-05,
      "loss": 0.8077,
      "step": 81400
    },
    {
      "epoch": 160.12,
      "learning_rate": 3.99926326129666e-05,
      "loss": 0.7976,
      "step": 81500
    },
    {
      "epoch": 160.31,
      "learning_rate": 3.998035363457761e-05,
      "loss": 0.8064,
      "step": 81600
    },
    {
      "epoch": 160.51,
      "learning_rate": 3.996807465618861e-05,
      "loss": 0.7828,
      "step": 81700
    },
    {
      "epoch": 160.71,
      "learning_rate": 3.995579567779961e-05,
      "loss": 0.7985,
      "step": 81800
    },
    {
      "epoch": 160.9,
      "learning_rate": 3.994351669941061e-05,
      "loss": 0.7964,
      "step": 81900
    },
    {
      "epoch": 161.1,
      "learning_rate": 3.9931237721021613e-05,
      "loss": 0.8077,
      "step": 82000
    },
    {
      "epoch": 161.3,
      "learning_rate": 3.991895874263262e-05,
      "loss": 0.7878,
      "step": 82100
    },
    {
      "epoch": 161.49,
      "learning_rate": 3.990667976424361e-05,
      "loss": 0.7788,
      "step": 82200
    },
    {
      "epoch": 161.69,
      "learning_rate": 3.989440078585462e-05,
      "loss": 0.8052,
      "step": 82300
    },
    {
      "epoch": 161.89,
      "learning_rate": 3.9882121807465626e-05,
      "loss": 0.8101,
      "step": 82400
    },
    {
      "epoch": 162.08,
      "learning_rate": 3.986984282907662e-05,
      "loss": 0.7723,
      "step": 82500
    },
    {
      "epoch": 162.28,
      "learning_rate": 3.9857563850687625e-05,
      "loss": 0.7849,
      "step": 82600
    },
    {
      "epoch": 162.48,
      "learning_rate": 3.9845284872298625e-05,
      "loss": 0.7875,
      "step": 82700
    },
    {
      "epoch": 162.67,
      "learning_rate": 3.983300589390963e-05,
      "loss": 0.7904,
      "step": 82800
    },
    {
      "epoch": 162.87,
      "learning_rate": 3.982072691552063e-05,
      "loss": 0.7945,
      "step": 82900
    },
    {
      "epoch": 163.06,
      "learning_rate": 3.980844793713163e-05,
      "loss": 0.7994,
      "step": 83000
    },
    {
      "epoch": 163.26,
      "learning_rate": 3.979616895874264e-05,
      "loss": 0.8036,
      "step": 83100
    },
    {
      "epoch": 163.46,
      "learning_rate": 3.9783889980353636e-05,
      "loss": 0.7941,
      "step": 83200
    },
    {
      "epoch": 163.65,
      "learning_rate": 3.9771611001964636e-05,
      "loss": 0.7885,
      "step": 83300
    },
    {
      "epoch": 163.85,
      "learning_rate": 3.975933202357564e-05,
      "loss": 0.7945,
      "step": 83400
    },
    {
      "epoch": 164.05,
      "learning_rate": 3.974705304518664e-05,
      "loss": 0.8053,
      "step": 83500
    },
    {
      "epoch": 164.24,
      "learning_rate": 3.973477406679764e-05,
      "loss": 0.7907,
      "step": 83600
    },
    {
      "epoch": 164.44,
      "learning_rate": 3.972249508840865e-05,
      "loss": 0.7786,
      "step": 83700
    },
    {
      "epoch": 164.64,
      "learning_rate": 3.971021611001965e-05,
      "loss": 0.7972,
      "step": 83800
    },
    {
      "epoch": 164.83,
      "learning_rate": 3.9697937131630654e-05,
      "loss": 0.7996,
      "step": 83900
    },
    {
      "epoch": 165.03,
      "learning_rate": 3.9685658153241654e-05,
      "loss": 0.7975,
      "step": 84000
    },
    {
      "epoch": 165.23,
      "learning_rate": 3.9673379174852653e-05,
      "loss": 0.8087,
      "step": 84100
    },
    {
      "epoch": 165.42,
      "learning_rate": 3.966110019646366e-05,
      "loss": 0.7924,
      "step": 84200
    },
    {
      "epoch": 165.62,
      "learning_rate": 3.964882121807465e-05,
      "loss": 0.7778,
      "step": 84300
    },
    {
      "epoch": 165.82,
      "learning_rate": 3.963654223968566e-05,
      "loss": 0.7982,
      "step": 84400
    },
    {
      "epoch": 166.01,
      "learning_rate": 3.9624263261296666e-05,
      "loss": 0.7881,
      "step": 84500
    },
    {
      "epoch": 166.21,
      "learning_rate": 3.9611984282907665e-05,
      "loss": 0.7872,
      "step": 84600
    },
    {
      "epoch": 166.4,
      "learning_rate": 3.9599705304518665e-05,
      "loss": 0.7908,
      "step": 84700
    },
    {
      "epoch": 166.6,
      "learning_rate": 3.9587426326129664e-05,
      "loss": 0.7757,
      "step": 84800
    },
    {
      "epoch": 166.8,
      "learning_rate": 3.957514734774067e-05,
      "loss": 0.8021,
      "step": 84900
    },
    {
      "epoch": 166.99,
      "learning_rate": 3.956286836935168e-05,
      "loss": 0.7927,
      "step": 85000
    },
    {
      "epoch": 167.19,
      "learning_rate": 3.955058939096267e-05,
      "loss": 0.7965,
      "step": 85100
    },
    {
      "epoch": 167.39,
      "learning_rate": 3.9538310412573677e-05,
      "loss": 0.7742,
      "step": 85200
    },
    {
      "epoch": 167.58,
      "learning_rate": 3.9526031434184676e-05,
      "loss": 0.7813,
      "step": 85300
    },
    {
      "epoch": 167.78,
      "learning_rate": 3.9513752455795676e-05,
      "loss": 0.7984,
      "step": 85400
    },
    {
      "epoch": 167.98,
      "learning_rate": 3.950147347740668e-05,
      "loss": 0.7852,
      "step": 85500
    },
    {
      "epoch": 168.17,
      "learning_rate": 3.948919449901768e-05,
      "loss": 0.7821,
      "step": 85600
    },
    {
      "epoch": 168.37,
      "learning_rate": 3.947691552062869e-05,
      "loss": 0.7806,
      "step": 85700
    },
    {
      "epoch": 168.57,
      "learning_rate": 3.946463654223969e-05,
      "loss": 0.79,
      "step": 85800
    },
    {
      "epoch": 168.76,
      "learning_rate": 3.945235756385069e-05,
      "loss": 0.7813,
      "step": 85900
    },
    {
      "epoch": 168.96,
      "learning_rate": 3.9440078585461694e-05,
      "loss": 0.8041,
      "step": 86000
    },
    {
      "epoch": 169.16,
      "learning_rate": 3.9427799607072694e-05,
      "loss": 0.7891,
      "step": 86100
    },
    {
      "epoch": 169.35,
      "learning_rate": 3.941552062868369e-05,
      "loss": 0.8091,
      "step": 86200
    },
    {
      "epoch": 169.55,
      "learning_rate": 3.94032416502947e-05,
      "loss": 0.7691,
      "step": 86300
    },
    {
      "epoch": 169.74,
      "learning_rate": 3.93909626719057e-05,
      "loss": 0.7895,
      "step": 86400
    },
    {
      "epoch": 169.94,
      "learning_rate": 3.93786836935167e-05,
      "loss": 0.7675,
      "step": 86500
    },
    {
      "epoch": 170.14,
      "learning_rate": 3.9366404715127705e-05,
      "loss": 0.7857,
      "step": 86600
    },
    {
      "epoch": 170.33,
      "learning_rate": 3.9354125736738705e-05,
      "loss": 0.7887,
      "step": 86700
    },
    {
      "epoch": 170.53,
      "learning_rate": 3.934184675834971e-05,
      "loss": 0.7813,
      "step": 86800
    },
    {
      "epoch": 170.73,
      "learning_rate": 3.9329567779960704e-05,
      "loss": 0.7785,
      "step": 86900
    },
    {
      "epoch": 170.92,
      "learning_rate": 3.931728880157171e-05,
      "loss": 0.8068,
      "step": 87000
    },
    {
      "epoch": 171.12,
      "learning_rate": 3.930500982318272e-05,
      "loss": 0.7947,
      "step": 87100
    },
    {
      "epoch": 171.32,
      "learning_rate": 3.929273084479371e-05,
      "loss": 0.7766,
      "step": 87200
    },
    {
      "epoch": 171.51,
      "learning_rate": 3.9280451866404716e-05,
      "loss": 0.7805,
      "step": 87300
    },
    {
      "epoch": 171.71,
      "learning_rate": 3.926817288801572e-05,
      "loss": 0.7972,
      "step": 87400
    },
    {
      "epoch": 171.91,
      "learning_rate": 3.925589390962672e-05,
      "loss": 0.7958,
      "step": 87500
    },
    {
      "epoch": 172.1,
      "learning_rate": 3.924361493123772e-05,
      "loss": 0.7853,
      "step": 87600
    },
    {
      "epoch": 172.3,
      "learning_rate": 3.923133595284872e-05,
      "loss": 0.8005,
      "step": 87700
    },
    {
      "epoch": 172.5,
      "learning_rate": 3.921905697445973e-05,
      "loss": 0.7869,
      "step": 87800
    },
    {
      "epoch": 172.69,
      "learning_rate": 3.9206777996070735e-05,
      "loss": 0.7646,
      "step": 87900
    },
    {
      "epoch": 172.89,
      "learning_rate": 3.919449901768173e-05,
      "loss": 0.7686,
      "step": 88000
    },
    {
      "epoch": 173.08,
      "learning_rate": 3.9182220039292734e-05,
      "loss": 0.7839,
      "step": 88100
    },
    {
      "epoch": 173.28,
      "learning_rate": 3.9169941060903734e-05,
      "loss": 0.7885,
      "step": 88200
    },
    {
      "epoch": 173.48,
      "learning_rate": 3.915766208251473e-05,
      "loss": 0.775,
      "step": 88300
    },
    {
      "epoch": 173.67,
      "learning_rate": 3.914538310412574e-05,
      "loss": 0.7611,
      "step": 88400
    },
    {
      "epoch": 173.87,
      "learning_rate": 3.913310412573674e-05,
      "loss": 0.7805,
      "step": 88500
    },
    {
      "epoch": 174.07,
      "learning_rate": 3.9120825147347746e-05,
      "loss": 0.7801,
      "step": 88600
    },
    {
      "epoch": 174.26,
      "learning_rate": 3.9108546168958745e-05,
      "loss": 0.7718,
      "step": 88700
    },
    {
      "epoch": 174.46,
      "learning_rate": 3.9096267190569745e-05,
      "loss": 0.7845,
      "step": 88800
    },
    {
      "epoch": 174.66,
      "learning_rate": 3.908398821218075e-05,
      "loss": 0.7806,
      "step": 88900
    },
    {
      "epoch": 174.85,
      "learning_rate": 3.907170923379175e-05,
      "loss": 0.7737,
      "step": 89000
    },
    {
      "epoch": 175.05,
      "learning_rate": 3.905943025540275e-05,
      "loss": 0.779,
      "step": 89100
    },
    {
      "epoch": 175.25,
      "learning_rate": 3.904715127701376e-05,
      "loss": 0.7885,
      "step": 89200
    },
    {
      "epoch": 175.44,
      "learning_rate": 3.903487229862476e-05,
      "loss": 0.7729,
      "step": 89300
    },
    {
      "epoch": 175.64,
      "learning_rate": 3.9022593320235756e-05,
      "loss": 0.7989,
      "step": 89400
    },
    {
      "epoch": 175.83,
      "learning_rate": 3.901031434184676e-05,
      "loss": 0.7805,
      "step": 89500
    },
    {
      "epoch": 176.03,
      "learning_rate": 3.899803536345776e-05,
      "loss": 0.789,
      "step": 89600
    },
    {
      "epoch": 176.23,
      "learning_rate": 3.898575638506877e-05,
      "loss": 0.7642,
      "step": 89700
    },
    {
      "epoch": 176.42,
      "learning_rate": 3.897347740667976e-05,
      "loss": 0.7858,
      "step": 89800
    },
    {
      "epoch": 176.62,
      "learning_rate": 3.896119842829077e-05,
      "loss": 0.7868,
      "step": 89900
    },
    {
      "epoch": 176.82,
      "learning_rate": 3.8948919449901775e-05,
      "loss": 0.7861,
      "step": 90000
    },
    {
      "epoch": 177.01,
      "learning_rate": 3.893664047151277e-05,
      "loss": 0.7769,
      "step": 90100
    },
    {
      "epoch": 177.21,
      "learning_rate": 3.8924361493123774e-05,
      "loss": 0.7777,
      "step": 90200
    },
    {
      "epoch": 177.41,
      "learning_rate": 3.8912082514734774e-05,
      "loss": 0.7787,
      "step": 90300
    },
    {
      "epoch": 177.6,
      "learning_rate": 3.889980353634578e-05,
      "loss": 0.7654,
      "step": 90400
    },
    {
      "epoch": 177.8,
      "learning_rate": 3.888752455795678e-05,
      "loss": 0.7642,
      "step": 90500
    },
    {
      "epoch": 178.0,
      "learning_rate": 3.887524557956778e-05,
      "loss": 0.7825,
      "step": 90600
    },
    {
      "epoch": 178.19,
      "learning_rate": 3.8862966601178786e-05,
      "loss": 0.7743,
      "step": 90700
    },
    {
      "epoch": 178.39,
      "learning_rate": 3.8850687622789785e-05,
      "loss": 0.7764,
      "step": 90800
    },
    {
      "epoch": 178.59,
      "learning_rate": 3.8838408644400785e-05,
      "loss": 0.7821,
      "step": 90900
    },
    {
      "epoch": 178.78,
      "learning_rate": 3.882612966601179e-05,
      "loss": 0.781,
      "step": 91000
    },
    {
      "epoch": 178.98,
      "learning_rate": 3.881385068762279e-05,
      "loss": 0.7837,
      "step": 91100
    },
    {
      "epoch": 179.17,
      "learning_rate": 3.880157170923379e-05,
      "loss": 0.775,
      "step": 91200
    },
    {
      "epoch": 179.37,
      "learning_rate": 3.87892927308448e-05,
      "loss": 0.7822,
      "step": 91300
    },
    {
      "epoch": 179.57,
      "learning_rate": 3.87770137524558e-05,
      "loss": 0.7722,
      "step": 91400
    },
    {
      "epoch": 179.76,
      "learning_rate": 3.87647347740668e-05,
      "loss": 0.7815,
      "step": 91500
    },
    {
      "epoch": 179.96,
      "learning_rate": 3.87524557956778e-05,
      "loss": 0.7788,
      "step": 91600
    },
    {
      "epoch": 180.16,
      "learning_rate": 3.87401768172888e-05,
      "loss": 0.7855,
      "step": 91700
    },
    {
      "epoch": 180.35,
      "learning_rate": 3.872789783889981e-05,
      "loss": 0.7875,
      "step": 91800
    },
    {
      "epoch": 180.55,
      "learning_rate": 3.87156188605108e-05,
      "loss": 0.779,
      "step": 91900
    },
    {
      "epoch": 180.75,
      "learning_rate": 3.870333988212181e-05,
      "loss": 0.7714,
      "step": 92000
    },
    {
      "epoch": 180.94,
      "learning_rate": 3.8691060903732815e-05,
      "loss": 0.7755,
      "step": 92100
    },
    {
      "epoch": 181.14,
      "learning_rate": 3.8678781925343814e-05,
      "loss": 0.7747,
      "step": 92200
    },
    {
      "epoch": 181.34,
      "learning_rate": 3.8666502946954814e-05,
      "loss": 0.7608,
      "step": 92300
    },
    {
      "epoch": 181.53,
      "learning_rate": 3.865422396856582e-05,
      "loss": 0.7741,
      "step": 92400
    },
    {
      "epoch": 181.73,
      "learning_rate": 3.864194499017682e-05,
      "loss": 0.7733,
      "step": 92500
    },
    {
      "epoch": 181.93,
      "learning_rate": 3.862966601178782e-05,
      "loss": 0.7839,
      "step": 92600
    },
    {
      "epoch": 182.12,
      "learning_rate": 3.861738703339882e-05,
      "loss": 0.7766,
      "step": 92700
    },
    {
      "epoch": 182.32,
      "learning_rate": 3.8605108055009826e-05,
      "loss": 0.772,
      "step": 92800
    },
    {
      "epoch": 182.51,
      "learning_rate": 3.859282907662083e-05,
      "loss": 0.7848,
      "step": 92900
    },
    {
      "epoch": 182.71,
      "learning_rate": 3.8580550098231825e-05,
      "loss": 0.7821,
      "step": 93000
    },
    {
      "epoch": 182.91,
      "learning_rate": 3.856827111984283e-05,
      "loss": 0.7809,
      "step": 93100
    },
    {
      "epoch": 183.1,
      "learning_rate": 3.855599214145383e-05,
      "loss": 0.7619,
      "step": 93200
    },
    {
      "epoch": 183.3,
      "learning_rate": 3.854371316306484e-05,
      "loss": 0.7815,
      "step": 93300
    },
    {
      "epoch": 183.5,
      "learning_rate": 3.853143418467584e-05,
      "loss": 0.7644,
      "step": 93400
    },
    {
      "epoch": 183.69,
      "learning_rate": 3.851915520628684e-05,
      "loss": 0.7871,
      "step": 93500
    },
    {
      "epoch": 183.89,
      "learning_rate": 3.850687622789784e-05,
      "loss": 0.7626,
      "step": 93600
    },
    {
      "epoch": 184.09,
      "learning_rate": 3.849459724950884e-05,
      "loss": 0.7846,
      "step": 93700
    },
    {
      "epoch": 184.28,
      "learning_rate": 3.848231827111984e-05,
      "loss": 0.7597,
      "step": 93800
    },
    {
      "epoch": 184.48,
      "learning_rate": 3.847003929273085e-05,
      "loss": 0.7611,
      "step": 93900
    },
    {
      "epoch": 184.68,
      "learning_rate": 3.845776031434185e-05,
      "loss": 0.7808,
      "step": 94000
    },
    {
      "epoch": 184.87,
      "learning_rate": 3.844548133595285e-05,
      "loss": 0.7808,
      "step": 94100
    },
    {
      "epoch": 185.07,
      "learning_rate": 3.8433202357563854e-05,
      "loss": 0.7793,
      "step": 94200
    },
    {
      "epoch": 185.27,
      "learning_rate": 3.8420923379174854e-05,
      "loss": 0.7587,
      "step": 94300
    },
    {
      "epoch": 185.46,
      "learning_rate": 3.8408644400785854e-05,
      "loss": 0.7597,
      "step": 94400
    },
    {
      "epoch": 185.66,
      "learning_rate": 3.839636542239686e-05,
      "loss": 0.7598,
      "step": 94500
    },
    {
      "epoch": 185.85,
      "learning_rate": 3.838408644400786e-05,
      "loss": 0.7811,
      "step": 94600
    },
    {
      "epoch": 186.05,
      "learning_rate": 3.8371807465618866e-05,
      "loss": 0.7747,
      "step": 94700
    },
    {
      "epoch": 186.25,
      "learning_rate": 3.835952848722986e-05,
      "loss": 0.7813,
      "step": 94800
    },
    {
      "epoch": 186.44,
      "learning_rate": 3.8347249508840866e-05,
      "loss": 0.7754,
      "step": 94900
    },
    {
      "epoch": 186.64,
      "learning_rate": 3.833497053045187e-05,
      "loss": 0.7703,
      "step": 95000
    },
    {
      "epoch": 186.84,
      "learning_rate": 3.832269155206287e-05,
      "loss": 0.7703,
      "step": 95100
    },
    {
      "epoch": 187.03,
      "learning_rate": 3.831041257367387e-05,
      "loss": 0.7795,
      "step": 95200
    },
    {
      "epoch": 187.23,
      "learning_rate": 3.829813359528487e-05,
      "loss": 0.7583,
      "step": 95300
    },
    {
      "epoch": 187.43,
      "learning_rate": 3.828585461689588e-05,
      "loss": 0.7762,
      "step": 95400
    },
    {
      "epoch": 187.62,
      "learning_rate": 3.827357563850688e-05,
      "loss": 0.7549,
      "step": 95500
    },
    {
      "epoch": 187.82,
      "learning_rate": 3.8261296660117877e-05,
      "loss": 0.7756,
      "step": 95600
    },
    {
      "epoch": 188.02,
      "learning_rate": 3.824901768172888e-05,
      "loss": 0.7754,
      "step": 95700
    },
    {
      "epoch": 188.21,
      "learning_rate": 3.823673870333989e-05,
      "loss": 0.78,
      "step": 95800
    },
    {
      "epoch": 188.41,
      "learning_rate": 3.822445972495088e-05,
      "loss": 0.77,
      "step": 95900
    },
    {
      "epoch": 188.61,
      "learning_rate": 3.821218074656189e-05,
      "loss": 0.7654,
      "step": 96000
    },
    {
      "epoch": 188.8,
      "learning_rate": 3.819990176817289e-05,
      "loss": 0.7792,
      "step": 96100
    },
    {
      "epoch": 189.0,
      "learning_rate": 3.8187622789783895e-05,
      "loss": 0.7623,
      "step": 96200
    },
    {
      "epoch": 189.19,
      "learning_rate": 3.8175343811394894e-05,
      "loss": 0.7792,
      "step": 96300
    },
    {
      "epoch": 189.39,
      "learning_rate": 3.8163064833005894e-05,
      "loss": 0.7606,
      "step": 96400
    },
    {
      "epoch": 189.59,
      "learning_rate": 3.81507858546169e-05,
      "loss": 0.7651,
      "step": 96500
    },
    {
      "epoch": 189.78,
      "learning_rate": 3.81385068762279e-05,
      "loss": 0.7546,
      "step": 96600
    },
    {
      "epoch": 189.98,
      "learning_rate": 3.81262278978389e-05,
      "loss": 0.756,
      "step": 96700
    },
    {
      "epoch": 190.18,
      "learning_rate": 3.8113948919449906e-05,
      "loss": 0.7668,
      "step": 96800
    },
    {
      "epoch": 190.37,
      "learning_rate": 3.8101669941060906e-05,
      "loss": 0.7806,
      "step": 96900
    },
    {
      "epoch": 190.57,
      "learning_rate": 3.8089390962671905e-05,
      "loss": 0.7634,
      "step": 97000
    },
    {
      "epoch": 190.77,
      "learning_rate": 3.807711198428291e-05,
      "loss": 0.761,
      "step": 97100
    },
    {
      "epoch": 190.96,
      "learning_rate": 3.806483300589391e-05,
      "loss": 0.7671,
      "step": 97200
    },
    {
      "epoch": 191.16,
      "learning_rate": 3.805255402750491e-05,
      "loss": 0.7743,
      "step": 97300
    },
    {
      "epoch": 191.36,
      "learning_rate": 3.804027504911592e-05,
      "loss": 0.7579,
      "step": 97400
    },
    {
      "epoch": 191.55,
      "learning_rate": 3.802799607072692e-05,
      "loss": 0.7821,
      "step": 97500
    },
    {
      "epoch": 191.75,
      "learning_rate": 3.8015717092337924e-05,
      "loss": 0.7705,
      "step": 97600
    },
    {
      "epoch": 191.94,
      "learning_rate": 3.8003438113948917e-05,
      "loss": 0.7495,
      "step": 97700
    },
    {
      "epoch": 192.14,
      "learning_rate": 3.799115913555992e-05,
      "loss": 0.7595,
      "step": 97800
    },
    {
      "epoch": 192.34,
      "learning_rate": 3.797888015717093e-05,
      "loss": 0.7584,
      "step": 97900
    },
    {
      "epoch": 192.53,
      "learning_rate": 3.796660117878193e-05,
      "loss": 0.7586,
      "step": 98000
    },
    {
      "epoch": 192.73,
      "learning_rate": 3.795432220039293e-05,
      "loss": 0.7804,
      "step": 98100
    },
    {
      "epoch": 192.93,
      "learning_rate": 3.794204322200393e-05,
      "loss": 0.7573,
      "step": 98200
    },
    {
      "epoch": 193.12,
      "learning_rate": 3.7929764243614935e-05,
      "loss": 0.7513,
      "step": 98300
    },
    {
      "epoch": 193.32,
      "learning_rate": 3.7917485265225934e-05,
      "loss": 0.767,
      "step": 98400
    },
    {
      "epoch": 193.52,
      "learning_rate": 3.7905206286836934e-05,
      "loss": 0.7608,
      "step": 98500
    },
    {
      "epoch": 193.71,
      "learning_rate": 3.789292730844794e-05,
      "loss": 0.7757,
      "step": 98600
    },
    {
      "epoch": 193.91,
      "learning_rate": 3.788064833005894e-05,
      "loss": 0.762,
      "step": 98700
    },
    {
      "epoch": 194.11,
      "learning_rate": 3.786836935166994e-05,
      "loss": 0.7542,
      "step": 98800
    },
    {
      "epoch": 194.3,
      "learning_rate": 3.7856090373280946e-05,
      "loss": 0.7528,
      "step": 98900
    },
    {
      "epoch": 194.5,
      "learning_rate": 3.7843811394891946e-05,
      "loss": 0.769,
      "step": 99000
    },
    {
      "epoch": 194.7,
      "learning_rate": 3.7831532416502945e-05,
      "loss": 0.7677,
      "step": 99100
    },
    {
      "epoch": 194.89,
      "learning_rate": 3.781925343811395e-05,
      "loss": 0.7656,
      "step": 99200
    },
    {
      "epoch": 195.09,
      "learning_rate": 3.780697445972495e-05,
      "loss": 0.7568,
      "step": 99300
    },
    {
      "epoch": 195.28,
      "learning_rate": 3.779469548133596e-05,
      "loss": 0.7588,
      "step": 99400
    },
    {
      "epoch": 195.48,
      "learning_rate": 3.778241650294696e-05,
      "loss": 0.7608,
      "step": 99500
    },
    {
      "epoch": 195.68,
      "learning_rate": 3.777013752455796e-05,
      "loss": 0.7716,
      "step": 99600
    },
    {
      "epoch": 195.87,
      "learning_rate": 3.7757858546168964e-05,
      "loss": 0.7651,
      "step": 99700
    },
    {
      "epoch": 196.07,
      "learning_rate": 3.774557956777996e-05,
      "loss": 0.7559,
      "step": 99800
    },
    {
      "epoch": 196.27,
      "learning_rate": 3.773330058939096e-05,
      "loss": 0.7547,
      "step": 99900
    },
    {
      "epoch": 196.46,
      "learning_rate": 3.772102161100197e-05,
      "loss": 0.7576,
      "step": 100000
    },
    {
      "epoch": 196.66,
      "learning_rate": 3.770874263261297e-05,
      "loss": 0.7684,
      "step": 100100
    },
    {
      "epoch": 196.86,
      "learning_rate": 3.769646365422397e-05,
      "loss": 0.7744,
      "step": 100200
    },
    {
      "epoch": 197.05,
      "learning_rate": 3.768418467583497e-05,
      "loss": 0.7774,
      "step": 100300
    },
    {
      "epoch": 197.25,
      "learning_rate": 3.7671905697445975e-05,
      "loss": 0.7694,
      "step": 100400
    },
    {
      "epoch": 197.45,
      "learning_rate": 3.765962671905698e-05,
      "loss": 0.7584,
      "step": 100500
    },
    {
      "epoch": 197.64,
      "learning_rate": 3.7647347740667974e-05,
      "loss": 0.7452,
      "step": 100600
    },
    {
      "epoch": 197.84,
      "learning_rate": 3.763506876227898e-05,
      "loss": 0.7817,
      "step": 100700
    },
    {
      "epoch": 198.04,
      "learning_rate": 3.762278978388999e-05,
      "loss": 0.7546,
      "step": 100800
    },
    {
      "epoch": 198.23,
      "learning_rate": 3.761051080550098e-05,
      "loss": 0.7563,
      "step": 100900
    },
    {
      "epoch": 198.43,
      "learning_rate": 3.7598231827111986e-05,
      "loss": 0.7512,
      "step": 101000
    },
    {
      "epoch": 198.62,
      "learning_rate": 3.7585952848722986e-05,
      "loss": 0.7781,
      "step": 101100
    },
    {
      "epoch": 198.82,
      "learning_rate": 3.757367387033399e-05,
      "loss": 0.7553,
      "step": 101200
    },
    {
      "epoch": 199.02,
      "learning_rate": 3.756139489194499e-05,
      "loss": 0.7478,
      "step": 101300
    },
    {
      "epoch": 199.21,
      "learning_rate": 3.754911591355599e-05,
      "loss": 0.756,
      "step": 101400
    },
    {
      "epoch": 199.41,
      "learning_rate": 3.7536836935167e-05,
      "loss": 0.7417,
      "step": 101500
    },
    {
      "epoch": 199.61,
      "learning_rate": 3.7524557956778e-05,
      "loss": 0.7646,
      "step": 101600
    },
    {
      "epoch": 199.8,
      "learning_rate": 3.7512278978389e-05,
      "loss": 0.7646,
      "step": 101700
    },
    {
      "epoch": 200.0,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.7636,
      "step": 101800
    },
    {
      "epoch": 200.2,
      "learning_rate": 3.7487721021611e-05,
      "loss": 0.7576,
      "step": 101900
    },
    {
      "epoch": 200.39,
      "learning_rate": 3.7475442043222e-05,
      "loss": 0.7681,
      "step": 102000
    },
    {
      "epoch": 200.59,
      "learning_rate": 3.746316306483301e-05,
      "loss": 0.7516,
      "step": 102100
    },
    {
      "epoch": 200.79,
      "learning_rate": 3.745088408644401e-05,
      "loss": 0.7596,
      "step": 102200
    },
    {
      "epoch": 200.98,
      "learning_rate": 3.7438605108055015e-05,
      "loss": 0.7493,
      "step": 102300
    },
    {
      "epoch": 201.18,
      "learning_rate": 3.7426326129666015e-05,
      "loss": 0.7524,
      "step": 102400
    },
    {
      "epoch": 201.38,
      "learning_rate": 3.7414047151277015e-05,
      "loss": 0.767,
      "step": 102500
    },
    {
      "epoch": 201.57,
      "learning_rate": 3.740176817288802e-05,
      "loss": 0.7564,
      "step": 102600
    },
    {
      "epoch": 201.77,
      "learning_rate": 3.738948919449902e-05,
      "loss": 0.7593,
      "step": 102700
    },
    {
      "epoch": 201.96,
      "learning_rate": 3.737721021611002e-05,
      "loss": 0.7559,
      "step": 102800
    },
    {
      "epoch": 202.16,
      "learning_rate": 3.736493123772103e-05,
      "loss": 0.7505,
      "step": 102900
    },
    {
      "epoch": 202.36,
      "learning_rate": 3.7352652259332026e-05,
      "loss": 0.7531,
      "step": 103000
    },
    {
      "epoch": 202.55,
      "learning_rate": 3.7340373280943026e-05,
      "loss": 0.761,
      "step": 103100
    },
    {
      "epoch": 202.75,
      "learning_rate": 3.7328094302554026e-05,
      "loss": 0.7543,
      "step": 103200
    },
    {
      "epoch": 202.95,
      "learning_rate": 3.731581532416503e-05,
      "loss": 0.7568,
      "step": 103300
    },
    {
      "epoch": 203.14,
      "learning_rate": 3.730353634577604e-05,
      "loss": 0.7712,
      "step": 103400
    },
    {
      "epoch": 203.34,
      "learning_rate": 3.729125736738703e-05,
      "loss": 0.7535,
      "step": 103500
    },
    {
      "epoch": 203.54,
      "learning_rate": 3.727897838899804e-05,
      "loss": 0.7438,
      "step": 103600
    },
    {
      "epoch": 203.73,
      "learning_rate": 3.726669941060904e-05,
      "loss": 0.7624,
      "step": 103700
    },
    {
      "epoch": 203.93,
      "learning_rate": 3.725442043222004e-05,
      "loss": 0.7493,
      "step": 103800
    },
    {
      "epoch": 204.13,
      "learning_rate": 3.7242141453831043e-05,
      "loss": 0.7634,
      "step": 103900
    },
    {
      "epoch": 204.32,
      "learning_rate": 3.722986247544204e-05,
      "loss": 0.7723,
      "step": 104000
    },
    {
      "epoch": 204.52,
      "learning_rate": 3.721758349705305e-05,
      "loss": 0.7639,
      "step": 104100
    },
    {
      "epoch": 204.72,
      "learning_rate": 3.720530451866405e-05,
      "loss": 0.7618,
      "step": 104200
    },
    {
      "epoch": 204.91,
      "learning_rate": 3.719302554027505e-05,
      "loss": 0.75,
      "step": 104300
    },
    {
      "epoch": 205.11,
      "learning_rate": 3.7180746561886055e-05,
      "loss": 0.7546,
      "step": 104400
    },
    {
      "epoch": 205.3,
      "learning_rate": 3.7168467583497055e-05,
      "loss": 0.7518,
      "step": 104500
    },
    {
      "epoch": 205.5,
      "learning_rate": 3.7156188605108054e-05,
      "loss": 0.7492,
      "step": 104600
    },
    {
      "epoch": 205.7,
      "learning_rate": 3.714390962671906e-05,
      "loss": 0.7634,
      "step": 104700
    },
    {
      "epoch": 205.89,
      "learning_rate": 3.713163064833006e-05,
      "loss": 0.7373,
      "step": 104800
    },
    {
      "epoch": 206.09,
      "learning_rate": 3.711935166994106e-05,
      "loss": 0.7613,
      "step": 104900
    },
    {
      "epoch": 206.29,
      "learning_rate": 3.7107072691552067e-05,
      "loss": 0.7486,
      "step": 105000
    },
    {
      "epoch": 206.48,
      "learning_rate": 3.7094793713163066e-05,
      "loss": 0.7579,
      "step": 105100
    },
    {
      "epoch": 206.68,
      "learning_rate": 3.708251473477407e-05,
      "loss": 0.7553,
      "step": 105200
    },
    {
      "epoch": 206.88,
      "learning_rate": 3.7070235756385066e-05,
      "loss": 0.7623,
      "step": 105300
    },
    {
      "epoch": 207.07,
      "learning_rate": 3.705795677799607e-05,
      "loss": 0.758,
      "step": 105400
    },
    {
      "epoch": 207.27,
      "learning_rate": 3.704567779960708e-05,
      "loss": 0.7426,
      "step": 105500
    },
    {
      "epoch": 207.47,
      "learning_rate": 3.703339882121807e-05,
      "loss": 0.7456,
      "step": 105600
    },
    {
      "epoch": 207.66,
      "learning_rate": 3.702111984282908e-05,
      "loss": 0.7573,
      "step": 105700
    },
    {
      "epoch": 207.86,
      "learning_rate": 3.7008840864440084e-05,
      "loss": 0.7498,
      "step": 105800
    },
    {
      "epoch": 208.06,
      "learning_rate": 3.6996561886051084e-05,
      "loss": 0.7327,
      "step": 105900
    },
    {
      "epoch": 208.25,
      "learning_rate": 3.698428290766208e-05,
      "loss": 0.7452,
      "step": 106000
    },
    {
      "epoch": 208.45,
      "learning_rate": 3.697200392927308e-05,
      "loss": 0.769,
      "step": 106100
    },
    {
      "epoch": 208.64,
      "learning_rate": 3.695972495088409e-05,
      "loss": 0.7291,
      "step": 106200
    },
    {
      "epoch": 208.84,
      "learning_rate": 3.6947445972495096e-05,
      "loss": 0.7478,
      "step": 106300
    },
    {
      "epoch": 209.04,
      "learning_rate": 3.693516699410609e-05,
      "loss": 0.7635,
      "step": 106400
    },
    {
      "epoch": 209.23,
      "learning_rate": 3.6922888015717095e-05,
      "loss": 0.7345,
      "step": 106500
    },
    {
      "epoch": 209.43,
      "learning_rate": 3.6910609037328095e-05,
      "loss": 0.7615,
      "step": 106600
    },
    {
      "epoch": 209.63,
      "learning_rate": 3.6898330058939094e-05,
      "loss": 0.731,
      "step": 106700
    },
    {
      "epoch": 209.82,
      "learning_rate": 3.68860510805501e-05,
      "loss": 0.765,
      "step": 106800
    },
    {
      "epoch": 210.02,
      "learning_rate": 3.68737721021611e-05,
      "loss": 0.7341,
      "step": 106900
    },
    {
      "epoch": 210.22,
      "learning_rate": 3.686149312377211e-05,
      "loss": 0.7473,
      "step": 107000
    },
    {
      "epoch": 210.41,
      "learning_rate": 3.6849214145383107e-05,
      "loss": 0.7422,
      "step": 107100
    },
    {
      "epoch": 210.61,
      "learning_rate": 3.6836935166994106e-05,
      "loss": 0.7335,
      "step": 107200
    },
    {
      "epoch": 210.81,
      "learning_rate": 3.682465618860511e-05,
      "loss": 0.756,
      "step": 107300
    },
    {
      "epoch": 211.0,
      "learning_rate": 3.681237721021611e-05,
      "loss": 0.7608,
      "step": 107400
    },
    {
      "epoch": 211.2,
      "learning_rate": 3.680009823182711e-05,
      "loss": 0.7616,
      "step": 107500
    },
    {
      "epoch": 211.39,
      "learning_rate": 3.678781925343812e-05,
      "loss": 0.7455,
      "step": 107600
    },
    {
      "epoch": 211.59,
      "learning_rate": 3.677554027504912e-05,
      "loss": 0.7581,
      "step": 107700
    },
    {
      "epoch": 211.79,
      "learning_rate": 3.676326129666012e-05,
      "loss": 0.7547,
      "step": 107800
    },
    {
      "epoch": 211.98,
      "learning_rate": 3.6750982318271124e-05,
      "loss": 0.745,
      "step": 107900
    },
    {
      "epoch": 212.18,
      "learning_rate": 3.6738703339882124e-05,
      "loss": 0.7457,
      "step": 108000
    },
    {
      "epoch": 212.38,
      "learning_rate": 3.672642436149313e-05,
      "loss": 0.7625,
      "step": 108100
    },
    {
      "epoch": 212.57,
      "learning_rate": 3.671414538310412e-05,
      "loss": 0.743,
      "step": 108200
    },
    {
      "epoch": 212.77,
      "learning_rate": 3.670186640471513e-05,
      "loss": 0.7457,
      "step": 108300
    },
    {
      "epoch": 212.97,
      "learning_rate": 3.6689587426326136e-05,
      "loss": 0.7396,
      "step": 108400
    },
    {
      "epoch": 213.16,
      "learning_rate": 3.667730844793713e-05,
      "loss": 0.7482,
      "step": 108500
    },
    {
      "epoch": 213.36,
      "learning_rate": 3.6665029469548135e-05,
      "loss": 0.7436,
      "step": 108600
    },
    {
      "epoch": 213.56,
      "learning_rate": 3.6652750491159135e-05,
      "loss": 0.7437,
      "step": 108700
    },
    {
      "epoch": 213.75,
      "learning_rate": 3.664047151277014e-05,
      "loss": 0.7589,
      "step": 108800
    },
    {
      "epoch": 213.95,
      "learning_rate": 3.662819253438114e-05,
      "loss": 0.7662,
      "step": 108900
    },
    {
      "epoch": 214.15,
      "learning_rate": 3.661591355599214e-05,
      "loss": 0.7455,
      "step": 109000
    },
    {
      "epoch": 214.34,
      "learning_rate": 3.660363457760315e-05,
      "loss": 0.7348,
      "step": 109100
    },
    {
      "epoch": 214.54,
      "learning_rate": 3.659135559921415e-05,
      "loss": 0.7434,
      "step": 109200
    },
    {
      "epoch": 214.73,
      "learning_rate": 3.6579076620825146e-05,
      "loss": 0.7581,
      "step": 109300
    },
    {
      "epoch": 214.93,
      "learning_rate": 3.656679764243615e-05,
      "loss": 0.7602,
      "step": 109400
    },
    {
      "epoch": 215.13,
      "learning_rate": 3.655451866404715e-05,
      "loss": 0.7522,
      "step": 109500
    },
    {
      "epoch": 215.32,
      "learning_rate": 3.654223968565815e-05,
      "loss": 0.7454,
      "step": 109600
    },
    {
      "epoch": 215.52,
      "learning_rate": 3.652996070726916e-05,
      "loss": 0.7576,
      "step": 109700
    },
    {
      "epoch": 215.72,
      "learning_rate": 3.651768172888016e-05,
      "loss": 0.7397,
      "step": 109800
    },
    {
      "epoch": 215.91,
      "learning_rate": 3.6505402750491164e-05,
      "loss": 0.7481,
      "step": 109900
    },
    {
      "epoch": 216.11,
      "learning_rate": 3.6493123772102164e-05,
      "loss": 0.7143,
      "step": 110000
    },
    {
      "epoch": 216.31,
      "learning_rate": 3.6480844793713164e-05,
      "loss": 0.7376,
      "step": 110100
    },
    {
      "epoch": 216.5,
      "learning_rate": 3.646856581532417e-05,
      "loss": 0.7358,
      "step": 110200
    },
    {
      "epoch": 216.7,
      "learning_rate": 3.645628683693516e-05,
      "loss": 0.7496,
      "step": 110300
    },
    {
      "epoch": 216.9,
      "learning_rate": 3.644400785854617e-05,
      "loss": 0.7498,
      "step": 110400
    },
    {
      "epoch": 217.09,
      "learning_rate": 3.6431728880157176e-05,
      "loss": 0.7557,
      "step": 110500
    },
    {
      "epoch": 217.29,
      "learning_rate": 3.6419449901768175e-05,
      "loss": 0.7417,
      "step": 110600
    },
    {
      "epoch": 217.49,
      "learning_rate": 3.6407170923379175e-05,
      "loss": 0.7402,
      "step": 110700
    },
    {
      "epoch": 217.68,
      "learning_rate": 3.639489194499018e-05,
      "loss": 0.7376,
      "step": 110800
    },
    {
      "epoch": 217.88,
      "learning_rate": 3.638261296660118e-05,
      "loss": 0.7554,
      "step": 110900
    },
    {
      "epoch": 218.07,
      "learning_rate": 3.637033398821219e-05,
      "loss": 0.7625,
      "step": 111000
    },
    {
      "epoch": 218.27,
      "learning_rate": 3.635805500982318e-05,
      "loss": 0.7626,
      "step": 111100
    },
    {
      "epoch": 218.47,
      "learning_rate": 3.634577603143419e-05,
      "loss": 0.7622,
      "step": 111200
    },
    {
      "epoch": 218.66,
      "learning_rate": 3.633349705304519e-05,
      "loss": 0.7414,
      "step": 111300
    },
    {
      "epoch": 218.86,
      "learning_rate": 3.6321218074656186e-05,
      "loss": 0.7349,
      "step": 111400
    },
    {
      "epoch": 219.06,
      "learning_rate": 3.630893909626719e-05,
      "loss": 0.7488,
      "step": 111500
    },
    {
      "epoch": 219.25,
      "learning_rate": 3.629666011787819e-05,
      "loss": 0.7381,
      "step": 111600
    },
    {
      "epoch": 219.45,
      "learning_rate": 3.62843811394892e-05,
      "loss": 0.7461,
      "step": 111700
    },
    {
      "epoch": 219.65,
      "learning_rate": 3.62721021611002e-05,
      "loss": 0.7527,
      "step": 111800
    },
    {
      "epoch": 219.84,
      "learning_rate": 3.62598231827112e-05,
      "loss": 0.7266,
      "step": 111900
    },
    {
      "epoch": 220.04,
      "learning_rate": 3.6247544204322204e-05,
      "loss": 0.7452,
      "step": 112000
    },
    {
      "epoch": 220.24,
      "learning_rate": 3.6235265225933204e-05,
      "loss": 0.7458,
      "step": 112100
    },
    {
      "epoch": 220.43,
      "learning_rate": 3.6222986247544203e-05,
      "loss": 0.7397,
      "step": 112200
    },
    {
      "epoch": 220.63,
      "learning_rate": 3.621070726915521e-05,
      "loss": 0.7348,
      "step": 112300
    },
    {
      "epoch": 220.83,
      "learning_rate": 3.619842829076621e-05,
      "loss": 0.7517,
      "step": 112400
    },
    {
      "epoch": 221.02,
      "learning_rate": 3.618614931237721e-05,
      "loss": 0.7627,
      "step": 112500
    },
    {
      "epoch": 221.22,
      "learning_rate": 3.6173870333988216e-05,
      "loss": 0.726,
      "step": 112600
    },
    {
      "epoch": 221.41,
      "learning_rate": 3.6161591355599215e-05,
      "loss": 0.7583,
      "step": 112700
    },
    {
      "epoch": 221.61,
      "learning_rate": 3.614931237721022e-05,
      "loss": 0.7559,
      "step": 112800
    },
    {
      "epoch": 221.81,
      "learning_rate": 3.613703339882122e-05,
      "loss": 0.734,
      "step": 112900
    },
    {
      "epoch": 222.0,
      "learning_rate": 3.612475442043222e-05,
      "loss": 0.7279,
      "step": 113000
    },
    {
      "epoch": 222.2,
      "learning_rate": 3.611247544204323e-05,
      "loss": 0.7392,
      "step": 113100
    },
    {
      "epoch": 222.4,
      "learning_rate": 3.610019646365422e-05,
      "loss": 0.7465,
      "step": 113200
    },
    {
      "epoch": 222.59,
      "learning_rate": 3.608791748526523e-05,
      "loss": 0.7447,
      "step": 113300
    },
    {
      "epoch": 222.79,
      "learning_rate": 3.607563850687623e-05,
      "loss": 0.7443,
      "step": 113400
    },
    {
      "epoch": 222.99,
      "learning_rate": 3.606335952848723e-05,
      "loss": 0.7421,
      "step": 113500
    },
    {
      "epoch": 223.18,
      "learning_rate": 3.605108055009823e-05,
      "loss": 0.729,
      "step": 113600
    },
    {
      "epoch": 223.38,
      "learning_rate": 3.603880157170923e-05,
      "loss": 0.7381,
      "step": 113700
    },
    {
      "epoch": 223.58,
      "learning_rate": 3.602652259332024e-05,
      "loss": 0.7472,
      "step": 113800
    },
    {
      "epoch": 223.77,
      "learning_rate": 3.601424361493124e-05,
      "loss": 0.7596,
      "step": 113900
    },
    {
      "epoch": 223.97,
      "learning_rate": 3.600196463654224e-05,
      "loss": 0.7432,
      "step": 114000
    },
    {
      "epoch": 224.17,
      "learning_rate": 3.5989685658153244e-05,
      "loss": 0.7485,
      "step": 114100
    },
    {
      "epoch": 224.36,
      "learning_rate": 3.597740667976425e-05,
      "loss": 0.7421,
      "step": 114200
    },
    {
      "epoch": 224.56,
      "learning_rate": 3.5965127701375243e-05,
      "loss": 0.7414,
      "step": 114300
    },
    {
      "epoch": 224.75,
      "learning_rate": 3.595284872298625e-05,
      "loss": 0.7452,
      "step": 114400
    },
    {
      "epoch": 224.95,
      "learning_rate": 3.594056974459725e-05,
      "loss": 0.725,
      "step": 114500
    },
    {
      "epoch": 225.15,
      "learning_rate": 3.5928290766208256e-05,
      "loss": 0.7311,
      "step": 114600
    },
    {
      "epoch": 225.34,
      "learning_rate": 3.5916011787819256e-05,
      "loss": 0.7277,
      "step": 114700
    },
    {
      "epoch": 225.54,
      "learning_rate": 3.5903732809430255e-05,
      "loss": 0.7345,
      "step": 114800
    },
    {
      "epoch": 225.74,
      "learning_rate": 3.589145383104126e-05,
      "loss": 0.7457,
      "step": 114900
    },
    {
      "epoch": 225.93,
      "learning_rate": 3.587917485265226e-05,
      "loss": 0.732,
      "step": 115000
    },
    {
      "epoch": 226.13,
      "learning_rate": 3.586689587426326e-05,
      "loss": 0.7255,
      "step": 115100
    },
    {
      "epoch": 226.33,
      "learning_rate": 3.585461689587427e-05,
      "loss": 0.747,
      "step": 115200
    },
    {
      "epoch": 226.52,
      "learning_rate": 3.584233791748527e-05,
      "loss": 0.7368,
      "step": 115300
    },
    {
      "epoch": 226.72,
      "learning_rate": 3.5830058939096267e-05,
      "loss": 0.7364,
      "step": 115400
    },
    {
      "epoch": 226.92,
      "learning_rate": 3.581777996070727e-05,
      "loss": 0.7507,
      "step": 115500
    },
    {
      "epoch": 227.11,
      "learning_rate": 3.580550098231827e-05,
      "loss": 0.7329,
      "step": 115600
    },
    {
      "epoch": 227.31,
      "learning_rate": 3.579322200392927e-05,
      "loss": 0.7385,
      "step": 115700
    },
    {
      "epoch": 227.5,
      "learning_rate": 3.578094302554028e-05,
      "loss": 0.7487,
      "step": 115800
    },
    {
      "epoch": 227.7,
      "learning_rate": 3.576866404715128e-05,
      "loss": 0.7407,
      "step": 115900
    },
    {
      "epoch": 227.9,
      "learning_rate": 3.5756385068762285e-05,
      "loss": 0.7415,
      "step": 116000
    },
    {
      "epoch": 228.09,
      "learning_rate": 3.574410609037328e-05,
      "loss": 0.7384,
      "step": 116100
    },
    {
      "epoch": 228.29,
      "learning_rate": 3.5731827111984284e-05,
      "loss": 0.7367,
      "step": 116200
    },
    {
      "epoch": 228.49,
      "learning_rate": 3.571954813359529e-05,
      "loss": 0.7308,
      "step": 116300
    },
    {
      "epoch": 228.68,
      "learning_rate": 3.570726915520629e-05,
      "loss": 0.7324,
      "step": 116400
    },
    {
      "epoch": 228.88,
      "learning_rate": 3.569499017681729e-05,
      "loss": 0.7596,
      "step": 116500
    },
    {
      "epoch": 229.08,
      "learning_rate": 3.568271119842829e-05,
      "loss": 0.736,
      "step": 116600
    },
    {
      "epoch": 229.27,
      "learning_rate": 3.5670432220039296e-05,
      "loss": 0.7421,
      "step": 116700
    },
    {
      "epoch": 229.47,
      "learning_rate": 3.5658153241650295e-05,
      "loss": 0.7272,
      "step": 116800
    },
    {
      "epoch": 229.67,
      "learning_rate": 3.5645874263261295e-05,
      "loss": 0.7342,
      "step": 116900
    },
    {
      "epoch": 229.86,
      "learning_rate": 3.56335952848723e-05,
      "loss": 0.7506,
      "step": 117000
    },
    {
      "epoch": 230.06,
      "learning_rate": 3.56213163064833e-05,
      "loss": 0.7369,
      "step": 117100
    },
    {
      "epoch": 230.26,
      "learning_rate": 3.56090373280943e-05,
      "loss": 0.7343,
      "step": 117200
    },
    {
      "epoch": 230.45,
      "learning_rate": 3.559675834970531e-05,
      "loss": 0.7163,
      "step": 117300
    },
    {
      "epoch": 230.65,
      "learning_rate": 3.558447937131631e-05,
      "loss": 0.7462,
      "step": 117400
    },
    {
      "epoch": 230.84,
      "learning_rate": 3.557220039292731e-05,
      "loss": 0.7452,
      "step": 117500
    },
    {
      "epoch": 231.04,
      "learning_rate": 3.555992141453831e-05,
      "loss": 0.76,
      "step": 117600
    },
    {
      "epoch": 231.24,
      "learning_rate": 3.554764243614931e-05,
      "loss": 0.7287,
      "step": 117700
    },
    {
      "epoch": 231.43,
      "learning_rate": 3.553536345776032e-05,
      "loss": 0.7416,
      "step": 117800
    },
    {
      "epoch": 231.63,
      "learning_rate": 3.552308447937132e-05,
      "loss": 0.7396,
      "step": 117900
    },
    {
      "epoch": 231.83,
      "learning_rate": 3.551080550098232e-05,
      "loss": 0.7223,
      "step": 118000
    },
    {
      "epoch": 232.02,
      "learning_rate": 3.5498526522593325e-05,
      "loss": 0.7528,
      "step": 118100
    },
    {
      "epoch": 232.22,
      "learning_rate": 3.5486247544204324e-05,
      "loss": 0.7362,
      "step": 118200
    },
    {
      "epoch": 232.42,
      "learning_rate": 3.5473968565815324e-05,
      "loss": 0.7148,
      "step": 118300
    },
    {
      "epoch": 232.61,
      "learning_rate": 3.546168958742633e-05,
      "loss": 0.7227,
      "step": 118400
    },
    {
      "epoch": 232.81,
      "learning_rate": 3.544941060903733e-05,
      "loss": 0.7402,
      "step": 118500
    },
    {
      "epoch": 233.01,
      "learning_rate": 3.543713163064833e-05,
      "loss": 0.7321,
      "step": 118600
    },
    {
      "epoch": 233.2,
      "learning_rate": 3.542485265225933e-05,
      "loss": 0.735,
      "step": 118700
    },
    {
      "epoch": 233.4,
      "learning_rate": 3.5412573673870336e-05,
      "loss": 0.7515,
      "step": 118800
    },
    {
      "epoch": 233.6,
      "learning_rate": 3.540029469548134e-05,
      "loss": 0.7407,
      "step": 118900
    },
    {
      "epoch": 233.79,
      "learning_rate": 3.5388015717092335e-05,
      "loss": 0.7517,
      "step": 119000
    },
    {
      "epoch": 233.99,
      "learning_rate": 3.537573673870334e-05,
      "loss": 0.7233,
      "step": 119100
    },
    {
      "epoch": 234.18,
      "learning_rate": 3.536345776031435e-05,
      "loss": 0.7404,
      "step": 119200
    },
    {
      "epoch": 234.38,
      "learning_rate": 3.535117878192535e-05,
      "loss": 0.7267,
      "step": 119300
    },
    {
      "epoch": 234.58,
      "learning_rate": 3.533889980353635e-05,
      "loss": 0.7233,
      "step": 119400
    },
    {
      "epoch": 234.77,
      "learning_rate": 3.532662082514735e-05,
      "loss": 0.7248,
      "step": 119500
    },
    {
      "epoch": 234.97,
      "learning_rate": 3.531434184675835e-05,
      "loss": 0.7125,
      "step": 119600
    },
    {
      "epoch": 235.17,
      "learning_rate": 3.530206286836935e-05,
      "loss": 0.7291,
      "step": 119700
    },
    {
      "epoch": 235.36,
      "learning_rate": 3.528978388998035e-05,
      "loss": 0.7174,
      "step": 119800
    },
    {
      "epoch": 235.56,
      "learning_rate": 3.527750491159136e-05,
      "loss": 0.7313,
      "step": 119900
    },
    {
      "epoch": 235.76,
      "learning_rate": 3.526522593320236e-05,
      "loss": 0.7325,
      "step": 120000
    },
    {
      "epoch": 235.95,
      "learning_rate": 3.525294695481336e-05,
      "loss": 0.7305,
      "step": 120100
    },
    {
      "epoch": 236.15,
      "learning_rate": 3.5240667976424365e-05,
      "loss": 0.7206,
      "step": 120200
    },
    {
      "epoch": 236.35,
      "learning_rate": 3.5228388998035364e-05,
      "loss": 0.7431,
      "step": 120300
    },
    {
      "epoch": 236.54,
      "learning_rate": 3.5216110019646364e-05,
      "loss": 0.7288,
      "step": 120400
    },
    {
      "epoch": 236.74,
      "learning_rate": 3.520383104125737e-05,
      "loss": 0.7403,
      "step": 120500
    },
    {
      "epoch": 236.94,
      "learning_rate": 3.519155206286837e-05,
      "loss": 0.7225,
      "step": 120600
    },
    {
      "epoch": 237.13,
      "learning_rate": 3.5179273084479376e-05,
      "loss": 0.7282,
      "step": 120700
    },
    {
      "epoch": 237.33,
      "learning_rate": 3.5166994106090376e-05,
      "loss": 0.718,
      "step": 120800
    },
    {
      "epoch": 237.52,
      "learning_rate": 3.5154715127701376e-05,
      "loss": 0.7438,
      "step": 120900
    },
    {
      "epoch": 237.72,
      "learning_rate": 3.514243614931238e-05,
      "loss": 0.7264,
      "step": 121000
    },
    {
      "epoch": 237.92,
      "learning_rate": 3.513015717092338e-05,
      "loss": 0.7263,
      "step": 121100
    },
    {
      "epoch": 238.11,
      "learning_rate": 3.511787819253438e-05,
      "loss": 0.7352,
      "step": 121200
    },
    {
      "epoch": 238.31,
      "learning_rate": 3.510559921414539e-05,
      "loss": 0.7273,
      "step": 121300
    },
    {
      "epoch": 238.51,
      "learning_rate": 3.509332023575639e-05,
      "loss": 0.7279,
      "step": 121400
    },
    {
      "epoch": 238.7,
      "learning_rate": 3.508104125736739e-05,
      "loss": 0.7289,
      "step": 121500
    },
    {
      "epoch": 238.9,
      "learning_rate": 3.506876227897839e-05,
      "loss": 0.7315,
      "step": 121600
    },
    {
      "epoch": 239.1,
      "learning_rate": 3.505648330058939e-05,
      "loss": 0.7348,
      "step": 121700
    },
    {
      "epoch": 239.29,
      "learning_rate": 3.50442043222004e-05,
      "loss": 0.7339,
      "step": 121800
    },
    {
      "epoch": 239.49,
      "learning_rate": 3.503192534381139e-05,
      "loss": 0.7231,
      "step": 121900
    },
    {
      "epoch": 239.69,
      "learning_rate": 3.50196463654224e-05,
      "loss": 0.7347,
      "step": 122000
    },
    {
      "epoch": 239.88,
      "learning_rate": 3.50073673870334e-05,
      "loss": 0.7397,
      "step": 122100
    },
    {
      "epoch": 240.08,
      "learning_rate": 3.49950884086444e-05,
      "loss": 0.7474,
      "step": 122200
    },
    {
      "epoch": 240.28,
      "learning_rate": 3.4982809430255405e-05,
      "loss": 0.7303,
      "step": 122300
    },
    {
      "epoch": 240.47,
      "learning_rate": 3.4970530451866404e-05,
      "loss": 0.7351,
      "step": 122400
    },
    {
      "epoch": 240.67,
      "learning_rate": 3.495825147347741e-05,
      "loss": 0.7338,
      "step": 122500
    },
    {
      "epoch": 240.86,
      "learning_rate": 3.494597249508841e-05,
      "loss": 0.7224,
      "step": 122600
    },
    {
      "epoch": 241.06,
      "learning_rate": 3.493369351669941e-05,
      "loss": 0.7421,
      "step": 122700
    },
    {
      "epoch": 241.26,
      "learning_rate": 3.4921414538310416e-05,
      "loss": 0.7267,
      "step": 122800
    },
    {
      "epoch": 241.45,
      "learning_rate": 3.4909135559921416e-05,
      "loss": 0.7296,
      "step": 122900
    },
    {
      "epoch": 241.65,
      "learning_rate": 3.4896856581532416e-05,
      "loss": 0.7302,
      "step": 123000
    },
    {
      "epoch": 241.85,
      "learning_rate": 3.488457760314342e-05,
      "loss": 0.7261,
      "step": 123100
    },
    {
      "epoch": 242.04,
      "learning_rate": 3.487229862475442e-05,
      "loss": 0.7281,
      "step": 123200
    },
    {
      "epoch": 242.24,
      "learning_rate": 3.486001964636542e-05,
      "loss": 0.7313,
      "step": 123300
    },
    {
      "epoch": 242.44,
      "learning_rate": 3.484774066797643e-05,
      "loss": 0.7143,
      "step": 123400
    },
    {
      "epoch": 242.63,
      "learning_rate": 3.483546168958743e-05,
      "loss": 0.7323,
      "step": 123500
    },
    {
      "epoch": 242.83,
      "learning_rate": 3.4823182711198434e-05,
      "loss": 0.7254,
      "step": 123600
    },
    {
      "epoch": 243.03,
      "learning_rate": 3.4810903732809433e-05,
      "loss": 0.7288,
      "step": 123700
    },
    {
      "epoch": 243.22,
      "learning_rate": 3.479862475442043e-05,
      "loss": 0.7289,
      "step": 123800
    },
    {
      "epoch": 243.42,
      "learning_rate": 3.478634577603144e-05,
      "loss": 0.7286,
      "step": 123900
    },
    {
      "epoch": 243.61,
      "learning_rate": 3.477406679764244e-05,
      "loss": 0.7356,
      "step": 124000
    },
    {
      "epoch": 243.81,
      "learning_rate": 3.476178781925344e-05,
      "loss": 0.7364,
      "step": 124100
    },
    {
      "epoch": 244.01,
      "learning_rate": 3.4749508840864445e-05,
      "loss": 0.7545,
      "step": 124200
    },
    {
      "epoch": 244.2,
      "learning_rate": 3.4737229862475445e-05,
      "loss": 0.7315,
      "step": 124300
    },
    {
      "epoch": 244.4,
      "learning_rate": 3.4724950884086444e-05,
      "loss": 0.7156,
      "step": 124400
    },
    {
      "epoch": 244.6,
      "learning_rate": 3.4712671905697444e-05,
      "loss": 0.7296,
      "step": 124500
    },
    {
      "epoch": 244.79,
      "learning_rate": 3.470039292730845e-05,
      "loss": 0.732,
      "step": 124600
    },
    {
      "epoch": 244.99,
      "learning_rate": 3.468811394891946e-05,
      "loss": 0.7264,
      "step": 124700
    },
    {
      "epoch": 245.19,
      "learning_rate": 3.467583497053045e-05,
      "loss": 0.7232,
      "step": 124800
    },
    {
      "epoch": 245.38,
      "learning_rate": 3.4663555992141456e-05,
      "loss": 0.7449,
      "step": 124900
    },
    {
      "epoch": 245.58,
      "learning_rate": 3.4651277013752456e-05,
      "loss": 0.7402,
      "step": 125000
    },
    {
      "epoch": 245.78,
      "learning_rate": 3.4638998035363456e-05,
      "loss": 0.7359,
      "step": 125100
    },
    {
      "epoch": 245.97,
      "learning_rate": 3.462671905697446e-05,
      "loss": 0.7469,
      "step": 125200
    },
    {
      "epoch": 246.17,
      "learning_rate": 3.461444007858546e-05,
      "loss": 0.724,
      "step": 125300
    },
    {
      "epoch": 246.37,
      "learning_rate": 3.460216110019647e-05,
      "loss": 0.7297,
      "step": 125400
    },
    {
      "epoch": 246.56,
      "learning_rate": 3.458988212180747e-05,
      "loss": 0.7214,
      "step": 125500
    },
    {
      "epoch": 246.76,
      "learning_rate": 3.457760314341847e-05,
      "loss": 0.7153,
      "step": 125600
    },
    {
      "epoch": 246.95,
      "learning_rate": 3.4565324165029474e-05,
      "loss": 0.7367,
      "step": 125700
    },
    {
      "epoch": 247.15,
      "learning_rate": 3.455304518664047e-05,
      "loss": 0.7332,
      "step": 125800
    },
    {
      "epoch": 247.35,
      "learning_rate": 3.454076620825147e-05,
      "loss": 0.7256,
      "step": 125900
    },
    {
      "epoch": 247.54,
      "learning_rate": 3.452848722986248e-05,
      "loss": 0.7151,
      "step": 126000
    },
    {
      "epoch": 247.74,
      "learning_rate": 3.451620825147348e-05,
      "loss": 0.7362,
      "step": 126100
    },
    {
      "epoch": 247.94,
      "learning_rate": 3.450392927308448e-05,
      "loss": 0.733,
      "step": 126200
    },
    {
      "epoch": 248.13,
      "learning_rate": 3.4491650294695485e-05,
      "loss": 0.7256,
      "step": 126300
    },
    {
      "epoch": 248.33,
      "learning_rate": 3.4479371316306485e-05,
      "loss": 0.7253,
      "step": 126400
    },
    {
      "epoch": 248.53,
      "learning_rate": 3.446709233791749e-05,
      "loss": 0.7199,
      "step": 126500
    },
    {
      "epoch": 248.72,
      "learning_rate": 3.4454813359528484e-05,
      "loss": 0.7258,
      "step": 126600
    },
    {
      "epoch": 248.92,
      "learning_rate": 3.444253438113949e-05,
      "loss": 0.7316,
      "step": 126700
    },
    {
      "epoch": 249.12,
      "learning_rate": 3.44302554027505e-05,
      "loss": 0.7183,
      "step": 126800
    },
    {
      "epoch": 249.31,
      "learning_rate": 3.441797642436149e-05,
      "loss": 0.7205,
      "step": 126900
    },
    {
      "epoch": 249.51,
      "learning_rate": 3.4405697445972496e-05,
      "loss": 0.741,
      "step": 127000
    },
    {
      "epoch": 249.71,
      "learning_rate": 3.4393418467583496e-05,
      "loss": 0.7136,
      "step": 127100
    },
    {
      "epoch": 249.9,
      "learning_rate": 3.43811394891945e-05,
      "loss": 0.7341,
      "step": 127200
    },
    {
      "epoch": 250.1,
      "learning_rate": 3.43688605108055e-05,
      "loss": 0.7231,
      "step": 127300
    },
    {
      "epoch": 250.29,
      "learning_rate": 3.43565815324165e-05,
      "loss": 0.716,
      "step": 127400
    },
    {
      "epoch": 250.49,
      "learning_rate": 3.434430255402751e-05,
      "loss": 0.7267,
      "step": 127500
    },
    {
      "epoch": 250.69,
      "learning_rate": 3.4332023575638514e-05,
      "loss": 0.7272,
      "step": 127600
    },
    {
      "epoch": 250.88,
      "learning_rate": 3.431974459724951e-05,
      "loss": 0.745,
      "step": 127700
    },
    {
      "epoch": 251.08,
      "learning_rate": 3.4307465618860514e-05,
      "loss": 0.7235,
      "step": 127800
    },
    {
      "epoch": 251.28,
      "learning_rate": 3.429518664047151e-05,
      "loss": 0.7384,
      "step": 127900
    },
    {
      "epoch": 251.47,
      "learning_rate": 3.428290766208251e-05,
      "loss": 0.7175,
      "step": 128000
    },
    {
      "epoch": 251.67,
      "learning_rate": 3.427062868369352e-05,
      "loss": 0.7322,
      "step": 128100
    },
    {
      "epoch": 251.87,
      "learning_rate": 3.425834970530452e-05,
      "loss": 0.7256,
      "step": 128200
    },
    {
      "epoch": 252.06,
      "learning_rate": 3.4246070726915525e-05,
      "loss": 0.7101,
      "step": 128300
    },
    {
      "epoch": 252.26,
      "learning_rate": 3.4233791748526525e-05,
      "loss": 0.7144,
      "step": 128400
    },
    {
      "epoch": 252.46,
      "learning_rate": 3.4221512770137525e-05,
      "loss": 0.7083,
      "step": 128500
    },
    {
      "epoch": 252.65,
      "learning_rate": 3.420923379174853e-05,
      "loss": 0.7295,
      "step": 128600
    },
    {
      "epoch": 252.85,
      "learning_rate": 3.419695481335953e-05,
      "loss": 0.7283,
      "step": 128700
    },
    {
      "epoch": 253.05,
      "learning_rate": 3.418467583497053e-05,
      "loss": 0.7439,
      "step": 128800
    },
    {
      "epoch": 253.24,
      "learning_rate": 3.417239685658154e-05,
      "loss": 0.7205,
      "step": 128900
    },
    {
      "epoch": 253.44,
      "learning_rate": 3.4160117878192536e-05,
      "loss": 0.7218,
      "step": 129000
    },
    {
      "epoch": 253.63,
      "learning_rate": 3.4147838899803536e-05,
      "loss": 0.7462,
      "step": 129100
    },
    {
      "epoch": 253.83,
      "learning_rate": 3.413555992141454e-05,
      "loss": 0.7249,
      "step": 129200
    },
    {
      "epoch": 254.03,
      "learning_rate": 3.412328094302554e-05,
      "loss": 0.7263,
      "step": 129300
    },
    {
      "epoch": 254.22,
      "learning_rate": 3.411100196463655e-05,
      "loss": 0.724,
      "step": 129400
    },
    {
      "epoch": 254.42,
      "learning_rate": 3.409872298624754e-05,
      "loss": 0.7337,
      "step": 129500
    },
    {
      "epoch": 254.62,
      "learning_rate": 3.408644400785855e-05,
      "loss": 0.7113,
      "step": 129600
    },
    {
      "epoch": 254.81,
      "learning_rate": 3.4074165029469554e-05,
      "loss": 0.7337,
      "step": 129700
    },
    {
      "epoch": 255.01,
      "learning_rate": 3.406188605108055e-05,
      "loss": 0.7214,
      "step": 129800
    },
    {
      "epoch": 255.21,
      "learning_rate": 3.4049607072691554e-05,
      "loss": 0.7171,
      "step": 129900
    },
    {
      "epoch": 255.4,
      "learning_rate": 3.403732809430255e-05,
      "loss": 0.7417,
      "step": 130000
    },
    {
      "epoch": 255.6,
      "learning_rate": 3.402504911591356e-05,
      "loss": 0.7209,
      "step": 130100
    },
    {
      "epoch": 255.8,
      "learning_rate": 3.401277013752456e-05,
      "loss": 0.7216,
      "step": 130200
    },
    {
      "epoch": 255.99,
      "learning_rate": 3.400049115913556e-05,
      "loss": 0.7274,
      "step": 130300
    },
    {
      "epoch": 256.19,
      "learning_rate": 3.3988212180746565e-05,
      "loss": 0.7173,
      "step": 130400
    },
    {
      "epoch": 256.39,
      "learning_rate": 3.3975933202357565e-05,
      "loss": 0.7435,
      "step": 130500
    },
    {
      "epoch": 256.58,
      "learning_rate": 3.3963654223968565e-05,
      "loss": 0.7404,
      "step": 130600
    },
    {
      "epoch": 256.78,
      "learning_rate": 3.395137524557957e-05,
      "loss": 0.735,
      "step": 130700
    },
    {
      "epoch": 256.97,
      "learning_rate": 3.393909626719057e-05,
      "loss": 0.6951,
      "step": 130800
    },
    {
      "epoch": 257.17,
      "learning_rate": 3.392681728880157e-05,
      "loss": 0.7174,
      "step": 130900
    },
    {
      "epoch": 257.37,
      "learning_rate": 3.391453831041258e-05,
      "loss": 0.727,
      "step": 131000
    },
    {
      "epoch": 257.56,
      "learning_rate": 3.3902259332023576e-05,
      "loss": 0.6931,
      "step": 131100
    },
    {
      "epoch": 257.76,
      "learning_rate": 3.388998035363458e-05,
      "loss": 0.7137,
      "step": 131200
    },
    {
      "epoch": 257.96,
      "learning_rate": 3.387770137524558e-05,
      "loss": 0.725,
      "step": 131300
    },
    {
      "epoch": 258.15,
      "learning_rate": 3.386542239685658e-05,
      "loss": 0.7468,
      "step": 131400
    },
    {
      "epoch": 258.35,
      "learning_rate": 3.385314341846759e-05,
      "loss": 0.7184,
      "step": 131500
    },
    {
      "epoch": 258.55,
      "learning_rate": 3.384086444007858e-05,
      "loss": 0.732,
      "step": 131600
    },
    {
      "epoch": 258.74,
      "learning_rate": 3.382858546168959e-05,
      "loss": 0.7199,
      "step": 131700
    },
    {
      "epoch": 258.94,
      "learning_rate": 3.3816306483300594e-05,
      "loss": 0.7325,
      "step": 131800
    },
    {
      "epoch": 259.14,
      "learning_rate": 3.3804027504911594e-05,
      "loss": 0.7237,
      "step": 131900
    },
    {
      "epoch": 259.33,
      "learning_rate": 3.3791748526522594e-05,
      "loss": 0.7179,
      "step": 132000
    },
    {
      "epoch": 259.53,
      "learning_rate": 3.377946954813359e-05,
      "loss": 0.7094,
      "step": 132100
    },
    {
      "epoch": 259.72,
      "learning_rate": 3.37671905697446e-05,
      "loss": 0.7242,
      "step": 132200
    },
    {
      "epoch": 259.92,
      "learning_rate": 3.3754911591355606e-05,
      "loss": 0.7177,
      "step": 132300
    },
    {
      "epoch": 260.12,
      "learning_rate": 3.37426326129666e-05,
      "loss": 0.7238,
      "step": 132400
    },
    {
      "epoch": 260.31,
      "learning_rate": 3.3730353634577605e-05,
      "loss": 0.7243,
      "step": 132500
    },
    {
      "epoch": 260.51,
      "learning_rate": 3.371807465618861e-05,
      "loss": 0.7229,
      "step": 132600
    },
    {
      "epoch": 260.71,
      "learning_rate": 3.3705795677799605e-05,
      "loss": 0.7325,
      "step": 132700
    },
    {
      "epoch": 260.9,
      "learning_rate": 3.369351669941061e-05,
      "loss": 0.7181,
      "step": 132800
    },
    {
      "epoch": 261.1,
      "learning_rate": 3.368123772102161e-05,
      "loss": 0.7069,
      "step": 132900
    },
    {
      "epoch": 261.3,
      "learning_rate": 3.366895874263262e-05,
      "loss": 0.7248,
      "step": 133000
    },
    {
      "epoch": 261.49,
      "learning_rate": 3.365667976424362e-05,
      "loss": 0.7028,
      "step": 133100
    },
    {
      "epoch": 261.69,
      "learning_rate": 3.3644400785854616e-05,
      "loss": 0.7312,
      "step": 133200
    },
    {
      "epoch": 261.89,
      "learning_rate": 3.363212180746562e-05,
      "loss": 0.7362,
      "step": 133300
    },
    {
      "epoch": 262.08,
      "learning_rate": 3.361984282907662e-05,
      "loss": 0.7143,
      "step": 133400
    },
    {
      "epoch": 262.28,
      "learning_rate": 3.360756385068762e-05,
      "loss": 0.7256,
      "step": 133500
    },
    {
      "epoch": 262.48,
      "learning_rate": 3.359528487229863e-05,
      "loss": 0.7185,
      "step": 133600
    },
    {
      "epoch": 262.67,
      "learning_rate": 3.358300589390963e-05,
      "loss": 0.7178,
      "step": 133700
    },
    {
      "epoch": 262.87,
      "learning_rate": 3.357072691552063e-05,
      "loss": 0.7232,
      "step": 133800
    },
    {
      "epoch": 263.06,
      "learning_rate": 3.3558447937131634e-05,
      "loss": 0.7146,
      "step": 133900
    },
    {
      "epoch": 263.26,
      "learning_rate": 3.3546168958742634e-05,
      "loss": 0.7156,
      "step": 134000
    },
    {
      "epoch": 263.46,
      "learning_rate": 3.353388998035364e-05,
      "loss": 0.7243,
      "step": 134100
    },
    {
      "epoch": 263.65,
      "learning_rate": 3.352161100196464e-05,
      "loss": 0.7145,
      "step": 134200
    },
    {
      "epoch": 263.85,
      "learning_rate": 3.350933202357564e-05,
      "loss": 0.7122,
      "step": 134300
    },
    {
      "epoch": 264.05,
      "learning_rate": 3.3497053045186646e-05,
      "loss": 0.7089,
      "step": 134400
    },
    {
      "epoch": 264.24,
      "learning_rate": 3.348477406679764e-05,
      "loss": 0.7139,
      "step": 134500
    },
    {
      "epoch": 264.44,
      "learning_rate": 3.3472495088408645e-05,
      "loss": 0.7117,
      "step": 134600
    },
    {
      "epoch": 264.64,
      "learning_rate": 3.346021611001965e-05,
      "loss": 0.7164,
      "step": 134700
    },
    {
      "epoch": 264.83,
      "learning_rate": 3.344793713163065e-05,
      "loss": 0.7044,
      "step": 134800
    },
    {
      "epoch": 265.03,
      "learning_rate": 3.343565815324165e-05,
      "loss": 0.7327,
      "step": 134900
    },
    {
      "epoch": 265.23,
      "learning_rate": 3.342337917485265e-05,
      "loss": 0.717,
      "step": 135000
    },
    {
      "epoch": 265.42,
      "learning_rate": 3.341110019646366e-05,
      "loss": 0.71,
      "step": 135100
    },
    {
      "epoch": 265.62,
      "learning_rate": 3.339882121807466e-05,
      "loss": 0.703,
      "step": 135200
    },
    {
      "epoch": 265.82,
      "learning_rate": 3.3386542239685656e-05,
      "loss": 0.7176,
      "step": 135300
    },
    {
      "epoch": 266.01,
      "learning_rate": 3.337426326129666e-05,
      "loss": 0.7431,
      "step": 135400
    },
    {
      "epoch": 266.21,
      "learning_rate": 3.336198428290766e-05,
      "loss": 0.7242,
      "step": 135500
    },
    {
      "epoch": 266.4,
      "learning_rate": 3.334970530451866e-05,
      "loss": 0.7062,
      "step": 135600
    },
    {
      "epoch": 266.6,
      "learning_rate": 3.333742632612967e-05,
      "loss": 0.7055,
      "step": 135700
    },
    {
      "epoch": 266.8,
      "learning_rate": 3.332514734774067e-05,
      "loss": 0.7292,
      "step": 135800
    },
    {
      "epoch": 266.99,
      "learning_rate": 3.3312868369351674e-05,
      "loss": 0.7122,
      "step": 135900
    },
    {
      "epoch": 267.19,
      "learning_rate": 3.3300589390962674e-05,
      "loss": 0.7224,
      "step": 136000
    },
    {
      "epoch": 267.39,
      "learning_rate": 3.3288310412573674e-05,
      "loss": 0.6956,
      "step": 136100
    },
    {
      "epoch": 267.58,
      "learning_rate": 3.327603143418468e-05,
      "loss": 0.7004,
      "step": 136200
    },
    {
      "epoch": 267.78,
      "learning_rate": 3.326375245579568e-05,
      "loss": 0.7139,
      "step": 136300
    },
    {
      "epoch": 267.98,
      "learning_rate": 3.325147347740668e-05,
      "loss": 0.7323,
      "step": 136400
    },
    {
      "epoch": 268.17,
      "learning_rate": 3.3239194499017686e-05,
      "loss": 0.7038,
      "step": 136500
    },
    {
      "epoch": 268.37,
      "learning_rate": 3.3226915520628685e-05,
      "loss": 0.7115,
      "step": 136600
    },
    {
      "epoch": 268.57,
      "learning_rate": 3.3214636542239685e-05,
      "loss": 0.7,
      "step": 136700
    },
    {
      "epoch": 268.76,
      "learning_rate": 3.320235756385069e-05,
      "loss": 0.707,
      "step": 136800
    },
    {
      "epoch": 268.96,
      "learning_rate": 3.319007858546169e-05,
      "loss": 0.7294,
      "step": 136900
    },
    {
      "epoch": 269.16,
      "learning_rate": 3.317779960707269e-05,
      "loss": 0.7201,
      "step": 137000
    },
    {
      "epoch": 269.35,
      "learning_rate": 3.31655206286837e-05,
      "loss": 0.7129,
      "step": 137100
    },
    {
      "epoch": 269.55,
      "learning_rate": 3.31532416502947e-05,
      "loss": 0.7193,
      "step": 137200
    },
    {
      "epoch": 269.74,
      "learning_rate": 3.31409626719057e-05,
      "loss": 0.7221,
      "step": 137300
    },
    {
      "epoch": 269.94,
      "learning_rate": 3.3128683693516696e-05,
      "loss": 0.7287,
      "step": 137400
    },
    {
      "epoch": 270.14,
      "learning_rate": 3.31164047151277e-05,
      "loss": 0.6989,
      "step": 137500
    },
    {
      "epoch": 270.33,
      "learning_rate": 3.310412573673871e-05,
      "loss": 0.7133,
      "step": 137600
    },
    {
      "epoch": 270.53,
      "learning_rate": 3.309184675834971e-05,
      "loss": 0.7125,
      "step": 137700
    },
    {
      "epoch": 270.73,
      "learning_rate": 3.307956777996071e-05,
      "loss": 0.7082,
      "step": 137800
    },
    {
      "epoch": 270.92,
      "learning_rate": 3.306728880157171e-05,
      "loss": 0.7087,
      "step": 137900
    },
    {
      "epoch": 271.12,
      "learning_rate": 3.3055009823182714e-05,
      "loss": 0.7025,
      "step": 138000
    },
    {
      "epoch": 271.32,
      "learning_rate": 3.3042730844793714e-05,
      "loss": 0.6988,
      "step": 138100
    },
    {
      "epoch": 271.51,
      "learning_rate": 3.3030451866404714e-05,
      "loss": 0.7004,
      "step": 138200
    },
    {
      "epoch": 271.71,
      "learning_rate": 3.301817288801572e-05,
      "loss": 0.7014,
      "step": 138300
    },
    {
      "epoch": 271.91,
      "learning_rate": 3.300589390962672e-05,
      "loss": 0.7187,
      "step": 138400
    },
    {
      "epoch": 272.1,
      "learning_rate": 3.299361493123772e-05,
      "loss": 0.7121,
      "step": 138500
    },
    {
      "epoch": 272.3,
      "learning_rate": 3.2981335952848726e-05,
      "loss": 0.7085,
      "step": 138600
    },
    {
      "epoch": 272.5,
      "learning_rate": 3.2969056974459725e-05,
      "loss": 0.7251,
      "step": 138700
    },
    {
      "epoch": 272.69,
      "learning_rate": 3.295677799607073e-05,
      "loss": 0.7015,
      "step": 138800
    },
    {
      "epoch": 272.89,
      "learning_rate": 3.294449901768173e-05,
      "loss": 0.7235,
      "step": 138900
    },
    {
      "epoch": 273.08,
      "learning_rate": 3.293222003929273e-05,
      "loss": 0.7123,
      "step": 139000
    },
    {
      "epoch": 273.28,
      "learning_rate": 3.291994106090374e-05,
      "loss": 0.7139,
      "step": 139100
    },
    {
      "epoch": 273.48,
      "learning_rate": 3.290766208251474e-05,
      "loss": 0.7131,
      "step": 139200
    },
    {
      "epoch": 273.67,
      "learning_rate": 3.289538310412574e-05,
      "loss": 0.7296,
      "step": 139300
    },
    {
      "epoch": 273.87,
      "learning_rate": 3.288310412573674e-05,
      "loss": 0.7151,
      "step": 139400
    },
    {
      "epoch": 274.07,
      "learning_rate": 3.287082514734774e-05,
      "loss": 0.7227,
      "step": 139500
    },
    {
      "epoch": 274.26,
      "learning_rate": 3.285854616895874e-05,
      "loss": 0.7205,
      "step": 139600
    },
    {
      "epoch": 274.46,
      "learning_rate": 3.284626719056975e-05,
      "loss": 0.7096,
      "step": 139700
    },
    {
      "epoch": 274.66,
      "learning_rate": 3.283398821218075e-05,
      "loss": 0.7062,
      "step": 139800
    },
    {
      "epoch": 274.85,
      "learning_rate": 3.282170923379175e-05,
      "loss": 0.7119,
      "step": 139900
    },
    {
      "epoch": 275.05,
      "learning_rate": 3.280943025540275e-05,
      "loss": 0.7266,
      "step": 140000
    },
    {
      "epoch": 275.25,
      "learning_rate": 3.2797151277013754e-05,
      "loss": 0.7268,
      "step": 140100
    },
    {
      "epoch": 275.44,
      "learning_rate": 3.278487229862476e-05,
      "loss": 0.7144,
      "step": 140200
    },
    {
      "epoch": 275.64,
      "learning_rate": 3.2772593320235754e-05,
      "loss": 0.7029,
      "step": 140300
    },
    {
      "epoch": 275.83,
      "learning_rate": 3.276031434184676e-05,
      "loss": 0.7133,
      "step": 140400
    },
    {
      "epoch": 276.03,
      "learning_rate": 3.274803536345776e-05,
      "loss": 0.7104,
      "step": 140500
    },
    {
      "epoch": 276.23,
      "learning_rate": 3.2735756385068766e-05,
      "loss": 0.7093,
      "step": 140600
    },
    {
      "epoch": 276.42,
      "learning_rate": 3.2723477406679766e-05,
      "loss": 0.7124,
      "step": 140700
    },
    {
      "epoch": 276.62,
      "learning_rate": 3.2711198428290765e-05,
      "loss": 0.6897,
      "step": 140800
    },
    {
      "epoch": 276.82,
      "learning_rate": 3.269891944990177e-05,
      "loss": 0.7222,
      "step": 140900
    },
    {
      "epoch": 277.01,
      "learning_rate": 3.268664047151277e-05,
      "loss": 0.7016,
      "step": 141000
    },
    {
      "epoch": 277.21,
      "learning_rate": 3.267436149312377e-05,
      "loss": 0.707,
      "step": 141100
    },
    {
      "epoch": 277.41,
      "learning_rate": 3.266208251473478e-05,
      "loss": 0.7089,
      "step": 141200
    },
    {
      "epoch": 277.6,
      "learning_rate": 3.264980353634578e-05,
      "loss": 0.7182,
      "step": 141300
    },
    {
      "epoch": 277.8,
      "learning_rate": 3.263752455795678e-05,
      "loss": 0.7228,
      "step": 141400
    },
    {
      "epoch": 278.0,
      "learning_rate": 3.262524557956778e-05,
      "loss": 0.7166,
      "step": 141500
    },
    {
      "epoch": 278.19,
      "learning_rate": 3.261296660117878e-05,
      "loss": 0.7241,
      "step": 141600
    },
    {
      "epoch": 278.39,
      "learning_rate": 3.260068762278978e-05,
      "loss": 0.6905,
      "step": 141700
    },
    {
      "epoch": 278.59,
      "learning_rate": 3.258840864440079e-05,
      "loss": 0.7141,
      "step": 141800
    },
    {
      "epoch": 278.78,
      "learning_rate": 3.257612966601179e-05,
      "loss": 0.7168,
      "step": 141900
    },
    {
      "epoch": 278.98,
      "learning_rate": 3.2563850687622795e-05,
      "loss": 0.7124,
      "step": 142000
    },
    {
      "epoch": 279.17,
      "learning_rate": 3.2551571709233795e-05,
      "loss": 0.7142,
      "step": 142100
    },
    {
      "epoch": 279.37,
      "learning_rate": 3.2539292730844794e-05,
      "loss": 0.6991,
      "step": 142200
    },
    {
      "epoch": 279.57,
      "learning_rate": 3.25270137524558e-05,
      "loss": 0.7018,
      "step": 142300
    },
    {
      "epoch": 279.76,
      "learning_rate": 3.25147347740668e-05,
      "loss": 0.7141,
      "step": 142400
    },
    {
      "epoch": 279.96,
      "learning_rate": 3.25024557956778e-05,
      "loss": 0.7141,
      "step": 142500
    },
    {
      "epoch": 280.16,
      "learning_rate": 3.2490176817288806e-05,
      "loss": 0.7171,
      "step": 142600
    },
    {
      "epoch": 280.35,
      "learning_rate": 3.2477897838899806e-05,
      "loss": 0.7071,
      "step": 142700
    },
    {
      "epoch": 280.55,
      "learning_rate": 3.2465618860510806e-05,
      "loss": 0.6943,
      "step": 142800
    },
    {
      "epoch": 280.75,
      "learning_rate": 3.2453339882121805e-05,
      "loss": 0.7026,
      "step": 142900
    },
    {
      "epoch": 280.94,
      "learning_rate": 3.244106090373281e-05,
      "loss": 0.7166,
      "step": 143000
    },
    {
      "epoch": 281.14,
      "learning_rate": 3.242878192534382e-05,
      "loss": 0.7121,
      "step": 143100
    },
    {
      "epoch": 281.34,
      "learning_rate": 3.241650294695481e-05,
      "loss": 0.7066,
      "step": 143200
    },
    {
      "epoch": 281.53,
      "learning_rate": 3.240422396856582e-05,
      "loss": 0.7051,
      "step": 143300
    },
    {
      "epoch": 281.73,
      "learning_rate": 3.239194499017682e-05,
      "loss": 0.7204,
      "step": 143400
    },
    {
      "epoch": 281.93,
      "learning_rate": 3.237966601178782e-05,
      "loss": 0.7108,
      "step": 143500
    },
    {
      "epoch": 282.12,
      "learning_rate": 3.236738703339882e-05,
      "loss": 0.717,
      "step": 143600
    },
    {
      "epoch": 282.32,
      "learning_rate": 3.235510805500982e-05,
      "loss": 0.6989,
      "step": 143700
    },
    {
      "epoch": 282.51,
      "learning_rate": 3.234282907662083e-05,
      "loss": 0.6996,
      "step": 143800
    },
    {
      "epoch": 282.71,
      "learning_rate": 3.233055009823183e-05,
      "loss": 0.7176,
      "step": 143900
    },
    {
      "epoch": 282.91,
      "learning_rate": 3.231827111984283e-05,
      "loss": 0.7184,
      "step": 144000
    },
    {
      "epoch": 283.1,
      "learning_rate": 3.2305992141453835e-05,
      "loss": 0.7073,
      "step": 144100
    },
    {
      "epoch": 283.3,
      "learning_rate": 3.2293713163064835e-05,
      "loss": 0.7068,
      "step": 144200
    },
    {
      "epoch": 283.5,
      "learning_rate": 3.2281434184675834e-05,
      "loss": 0.6961,
      "step": 144300
    },
    {
      "epoch": 283.69,
      "learning_rate": 3.226915520628684e-05,
      "loss": 0.7134,
      "step": 144400
    },
    {
      "epoch": 283.89,
      "learning_rate": 3.225687622789784e-05,
      "loss": 0.7112,
      "step": 144500
    },
    {
      "epoch": 284.09,
      "learning_rate": 3.224459724950884e-05,
      "loss": 0.7113,
      "step": 144600
    },
    {
      "epoch": 284.28,
      "learning_rate": 3.2232318271119846e-05,
      "loss": 0.7198,
      "step": 144700
    },
    {
      "epoch": 284.48,
      "learning_rate": 3.2220039292730846e-05,
      "loss": 0.6938,
      "step": 144800
    },
    {
      "epoch": 284.68,
      "learning_rate": 3.220776031434185e-05,
      "loss": 0.7163,
      "step": 144900
    },
    {
      "epoch": 284.87,
      "learning_rate": 3.2195481335952845e-05,
      "loss": 0.7195,
      "step": 145000
    },
    {
      "epoch": 285.07,
      "learning_rate": 3.218320235756385e-05,
      "loss": 0.7123,
      "step": 145100
    },
    {
      "epoch": 285.27,
      "learning_rate": 3.217092337917486e-05,
      "loss": 0.7097,
      "step": 145200
    },
    {
      "epoch": 285.46,
      "learning_rate": 3.215864440078585e-05,
      "loss": 0.7186,
      "step": 145300
    },
    {
      "epoch": 285.66,
      "learning_rate": 3.214636542239686e-05,
      "loss": 0.7079,
      "step": 145400
    },
    {
      "epoch": 285.85,
      "learning_rate": 3.2134086444007864e-05,
      "loss": 0.7202,
      "step": 145500
    },
    {
      "epoch": 286.05,
      "learning_rate": 3.2121807465618863e-05,
      "loss": 0.7016,
      "step": 145600
    },
    {
      "epoch": 286.25,
      "learning_rate": 3.210952848722986e-05,
      "loss": 0.7101,
      "step": 145700
    },
    {
      "epoch": 286.44,
      "learning_rate": 3.209724950884086e-05,
      "loss": 0.7037,
      "step": 145800
    },
    {
      "epoch": 286.64,
      "learning_rate": 3.208497053045187e-05,
      "loss": 0.6965,
      "step": 145900
    },
    {
      "epoch": 286.84,
      "learning_rate": 3.2072691552062876e-05,
      "loss": 0.7131,
      "step": 146000
    },
    {
      "epoch": 287.03,
      "learning_rate": 3.206041257367387e-05,
      "loss": 0.6961,
      "step": 146100
    },
    {
      "epoch": 287.23,
      "learning_rate": 3.2048133595284875e-05,
      "loss": 0.6976,
      "step": 146200
    },
    {
      "epoch": 287.43,
      "learning_rate": 3.2035854616895874e-05,
      "loss": 0.7098,
      "step": 146300
    },
    {
      "epoch": 287.62,
      "learning_rate": 3.2023575638506874e-05,
      "loss": 0.7132,
      "step": 146400
    },
    {
      "epoch": 287.82,
      "learning_rate": 3.201129666011788e-05,
      "loss": 0.7151,
      "step": 146500
    },
    {
      "epoch": 288.02,
      "learning_rate": 3.199901768172888e-05,
      "loss": 0.7116,
      "step": 146600
    },
    {
      "epoch": 288.21,
      "learning_rate": 3.1986738703339887e-05,
      "loss": 0.7087,
      "step": 146700
    },
    {
      "epoch": 288.41,
      "learning_rate": 3.1974459724950886e-05,
      "loss": 0.7008,
      "step": 146800
    },
    {
      "epoch": 288.61,
      "learning_rate": 3.1962180746561886e-05,
      "loss": 0.7174,
      "step": 146900
    },
    {
      "epoch": 288.8,
      "learning_rate": 3.194990176817289e-05,
      "loss": 0.7016,
      "step": 147000
    },
    {
      "epoch": 289.0,
      "learning_rate": 3.193762278978389e-05,
      "loss": 0.7217,
      "step": 147100
    },
    {
      "epoch": 289.19,
      "learning_rate": 3.192534381139489e-05,
      "loss": 0.7073,
      "step": 147200
    },
    {
      "epoch": 289.39,
      "learning_rate": 3.19130648330059e-05,
      "loss": 0.7039,
      "step": 147300
    },
    {
      "epoch": 289.59,
      "learning_rate": 3.19007858546169e-05,
      "loss": 0.6988,
      "step": 147400
    },
    {
      "epoch": 289.78,
      "learning_rate": 3.18885068762279e-05,
      "loss": 0.7189,
      "step": 147500
    },
    {
      "epoch": 289.98,
      "learning_rate": 3.1876227897838904e-05,
      "loss": 0.6992,
      "step": 147600
    },
    {
      "epoch": 290.18,
      "learning_rate": 3.18639489194499e-05,
      "loss": 0.6994,
      "step": 147700
    },
    {
      "epoch": 290.37,
      "learning_rate": 3.185166994106091e-05,
      "loss": 0.703,
      "step": 147800
    },
    {
      "epoch": 290.57,
      "learning_rate": 3.18393909626719e-05,
      "loss": 0.6948,
      "step": 147900
    },
    {
      "epoch": 290.77,
      "learning_rate": 3.182711198428291e-05,
      "loss": 0.6903,
      "step": 148000
    },
    {
      "epoch": 290.96,
      "learning_rate": 3.1814833005893915e-05,
      "loss": 0.7185,
      "step": 148100
    },
    {
      "epoch": 291.16,
      "learning_rate": 3.180255402750491e-05,
      "loss": 0.7002,
      "step": 148200
    },
    {
      "epoch": 291.36,
      "learning_rate": 3.1790275049115915e-05,
      "loss": 0.7118,
      "step": 148300
    },
    {
      "epoch": 291.55,
      "learning_rate": 3.1777996070726914e-05,
      "loss": 0.6973,
      "step": 148400
    },
    {
      "epoch": 291.75,
      "learning_rate": 3.176571709233792e-05,
      "loss": 0.6982,
      "step": 148500
    },
    {
      "epoch": 291.94,
      "learning_rate": 3.175343811394892e-05,
      "loss": 0.6951,
      "step": 148600
    },
    {
      "epoch": 292.14,
      "learning_rate": 3.174115913555992e-05,
      "loss": 0.6993,
      "step": 148700
    },
    {
      "epoch": 292.34,
      "learning_rate": 3.1728880157170926e-05,
      "loss": 0.7026,
      "step": 148800
    },
    {
      "epoch": 292.53,
      "learning_rate": 3.1716601178781926e-05,
      "loss": 0.6959,
      "step": 148900
    },
    {
      "epoch": 292.73,
      "learning_rate": 3.1704322200392926e-05,
      "loss": 0.7009,
      "step": 149000
    },
    {
      "epoch": 292.93,
      "learning_rate": 3.169204322200393e-05,
      "loss": 0.6929,
      "step": 149100
    },
    {
      "epoch": 293.12,
      "learning_rate": 3.167976424361493e-05,
      "loss": 0.7109,
      "step": 149200
    },
    {
      "epoch": 293.32,
      "learning_rate": 3.166748526522593e-05,
      "loss": 0.7078,
      "step": 149300
    },
    {
      "epoch": 293.52,
      "learning_rate": 3.165520628683694e-05,
      "loss": 0.7151,
      "step": 149400
    },
    {
      "epoch": 293.71,
      "learning_rate": 3.164292730844794e-05,
      "loss": 0.7068,
      "step": 149500
    },
    {
      "epoch": 293.91,
      "learning_rate": 3.1630648330058944e-05,
      "loss": 0.6954,
      "step": 149600
    },
    {
      "epoch": 294.11,
      "learning_rate": 3.1618369351669944e-05,
      "loss": 0.7114,
      "step": 149700
    },
    {
      "epoch": 294.3,
      "learning_rate": 3.160609037328094e-05,
      "loss": 0.6959,
      "step": 149800
    },
    {
      "epoch": 294.5,
      "learning_rate": 3.159381139489195e-05,
      "loss": 0.7118,
      "step": 149900
    },
    {
      "epoch": 294.7,
      "learning_rate": 3.158153241650294e-05,
      "loss": 0.6886,
      "step": 150000
    },
    {
      "epoch": 294.89,
      "learning_rate": 3.156925343811395e-05,
      "loss": 0.6937,
      "step": 150100
    },
    {
      "epoch": 295.09,
      "learning_rate": 3.1556974459724955e-05,
      "loss": 0.6921,
      "step": 150200
    },
    {
      "epoch": 295.28,
      "learning_rate": 3.1544695481335955e-05,
      "loss": 0.7084,
      "step": 150300
    },
    {
      "epoch": 295.48,
      "learning_rate": 3.1532416502946955e-05,
      "loss": 0.6863,
      "step": 150400
    },
    {
      "epoch": 295.68,
      "learning_rate": 3.152013752455796e-05,
      "loss": 0.695,
      "step": 150500
    },
    {
      "epoch": 295.87,
      "learning_rate": 3.150785854616896e-05,
      "loss": 0.7103,
      "step": 150600
    },
    {
      "epoch": 296.07,
      "learning_rate": 3.149557956777997e-05,
      "loss": 0.7183,
      "step": 150700
    },
    {
      "epoch": 296.27,
      "learning_rate": 3.148330058939096e-05,
      "loss": 0.7091,
      "step": 150800
    },
    {
      "epoch": 296.46,
      "learning_rate": 3.1471021611001966e-05,
      "loss": 0.6846,
      "step": 150900
    },
    {
      "epoch": 296.66,
      "learning_rate": 3.145874263261297e-05,
      "loss": 0.7184,
      "step": 151000
    },
    {
      "epoch": 296.86,
      "learning_rate": 3.1446463654223966e-05,
      "loss": 0.7124,
      "step": 151100
    },
    {
      "epoch": 297.05,
      "learning_rate": 3.143418467583497e-05,
      "loss": 0.7166,
      "step": 151200
    },
    {
      "epoch": 297.25,
      "learning_rate": 3.142190569744597e-05,
      "loss": 0.7117,
      "step": 151300
    },
    {
      "epoch": 297.45,
      "learning_rate": 3.140962671905698e-05,
      "loss": 0.702,
      "step": 151400
    },
    {
      "epoch": 297.64,
      "learning_rate": 3.139734774066798e-05,
      "loss": 0.7099,
      "step": 151500
    },
    {
      "epoch": 297.84,
      "learning_rate": 3.138506876227898e-05,
      "loss": 0.6917,
      "step": 151600
    },
    {
      "epoch": 298.04,
      "learning_rate": 3.1372789783889984e-05,
      "loss": 0.6838,
      "step": 151700
    },
    {
      "epoch": 298.23,
      "learning_rate": 3.1360510805500984e-05,
      "loss": 0.6956,
      "step": 151800
    },
    {
      "epoch": 298.43,
      "learning_rate": 3.134823182711198e-05,
      "loss": 0.6987,
      "step": 151900
    },
    {
      "epoch": 298.62,
      "learning_rate": 3.133595284872299e-05,
      "loss": 0.699,
      "step": 152000
    },
    {
      "epoch": 298.82,
      "learning_rate": 3.132367387033399e-05,
      "loss": 0.7004,
      "step": 152100
    },
    {
      "epoch": 299.02,
      "learning_rate": 3.131139489194499e-05,
      "loss": 0.6875,
      "step": 152200
    },
    {
      "epoch": 299.21,
      "learning_rate": 3.1299115913555995e-05,
      "loss": 0.7074,
      "step": 152300
    },
    {
      "epoch": 299.41,
      "learning_rate": 3.1286836935166995e-05,
      "loss": 0.6923,
      "step": 152400
    },
    {
      "epoch": 299.61,
      "learning_rate": 3.1274557956778e-05,
      "loss": 0.6804,
      "step": 152500
    },
    {
      "epoch": 299.8,
      "learning_rate": 3.1262278978389e-05,
      "loss": 0.6921,
      "step": 152600
    },
    {
      "epoch": 300.0,
      "learning_rate": 3.125e-05,
      "loss": 0.6909,
      "step": 152700
    },
    {
      "epoch": 300.2,
      "learning_rate": 3.123772102161101e-05,
      "loss": 0.6874,
      "step": 152800
    },
    {
      "epoch": 300.39,
      "learning_rate": 3.1225442043222e-05,
      "loss": 0.7065,
      "step": 152900
    },
    {
      "epoch": 300.59,
      "learning_rate": 3.1213163064833006e-05,
      "loss": 0.6993,
      "step": 153000
    },
    {
      "epoch": 300.79,
      "learning_rate": 3.120088408644401e-05,
      "loss": 0.6957,
      "step": 153100
    },
    {
      "epoch": 300.98,
      "learning_rate": 3.118860510805501e-05,
      "loss": 0.6886,
      "step": 153200
    },
    {
      "epoch": 301.18,
      "learning_rate": 3.117632612966601e-05,
      "loss": 0.6986,
      "step": 153300
    },
    {
      "epoch": 301.38,
      "learning_rate": 3.116404715127701e-05,
      "loss": 0.6947,
      "step": 153400
    },
    {
      "epoch": 301.57,
      "learning_rate": 3.115176817288802e-05,
      "loss": 0.678,
      "step": 153500
    },
    {
      "epoch": 301.77,
      "learning_rate": 3.1139489194499025e-05,
      "loss": 0.7015,
      "step": 153600
    },
    {
      "epoch": 301.96,
      "learning_rate": 3.112721021611002e-05,
      "loss": 0.7066,
      "step": 153700
    },
    {
      "epoch": 302.16,
      "learning_rate": 3.1114931237721024e-05,
      "loss": 0.7069,
      "step": 153800
    },
    {
      "epoch": 302.36,
      "learning_rate": 3.110265225933203e-05,
      "loss": 0.6857,
      "step": 153900
    },
    {
      "epoch": 302.55,
      "learning_rate": 3.109037328094302e-05,
      "loss": 0.6996,
      "step": 154000
    },
    {
      "epoch": 302.75,
      "learning_rate": 3.107809430255403e-05,
      "loss": 0.6916,
      "step": 154100
    },
    {
      "epoch": 302.95,
      "learning_rate": 3.106581532416503e-05,
      "loss": 0.6907,
      "step": 154200
    },
    {
      "epoch": 303.14,
      "learning_rate": 3.1053536345776036e-05,
      "loss": 0.7072,
      "step": 154300
    },
    {
      "epoch": 303.34,
      "learning_rate": 3.1041257367387035e-05,
      "loss": 0.7008,
      "step": 154400
    },
    {
      "epoch": 303.54,
      "learning_rate": 3.1028978388998035e-05,
      "loss": 0.6837,
      "step": 154500
    },
    {
      "epoch": 303.73,
      "learning_rate": 3.101669941060904e-05,
      "loss": 0.7045,
      "step": 154600
    },
    {
      "epoch": 303.93,
      "learning_rate": 3.100442043222004e-05,
      "loss": 0.7219,
      "step": 154700
    },
    {
      "epoch": 304.13,
      "learning_rate": 3.099214145383104e-05,
      "loss": 0.6751,
      "step": 154800
    },
    {
      "epoch": 304.32,
      "learning_rate": 3.097986247544205e-05,
      "loss": 0.7173,
      "step": 154900
    },
    {
      "epoch": 304.52,
      "learning_rate": 3.096758349705305e-05,
      "loss": 0.6958,
      "step": 155000
    },
    {
      "epoch": 304.72,
      "learning_rate": 3.0955304518664046e-05,
      "loss": 0.682,
      "step": 155100
    },
    {
      "epoch": 304.91,
      "learning_rate": 3.094302554027505e-05,
      "loss": 0.671,
      "step": 155200
    },
    {
      "epoch": 305.11,
      "learning_rate": 3.093074656188605e-05,
      "loss": 0.6866,
      "step": 155300
    },
    {
      "epoch": 305.3,
      "learning_rate": 3.091846758349706e-05,
      "loss": 0.704,
      "step": 155400
    },
    {
      "epoch": 305.5,
      "learning_rate": 3.090618860510806e-05,
      "loss": 0.6969,
      "step": 155500
    },
    {
      "epoch": 305.7,
      "learning_rate": 3.089390962671906e-05,
      "loss": 0.7018,
      "step": 155600
    },
    {
      "epoch": 305.89,
      "learning_rate": 3.0881630648330064e-05,
      "loss": 0.701,
      "step": 155700
    },
    {
      "epoch": 306.09,
      "learning_rate": 3.086935166994106e-05,
      "loss": 0.6894,
      "step": 155800
    },
    {
      "epoch": 306.29,
      "learning_rate": 3.0857072691552064e-05,
      "loss": 0.7051,
      "step": 155900
    },
    {
      "epoch": 306.48,
      "learning_rate": 3.084479371316307e-05,
      "loss": 0.6821,
      "step": 156000
    },
    {
      "epoch": 306.68,
      "learning_rate": 3.083251473477407e-05,
      "loss": 0.7027,
      "step": 156100
    },
    {
      "epoch": 306.88,
      "learning_rate": 3.082023575638507e-05,
      "loss": 0.7086,
      "step": 156200
    },
    {
      "epoch": 307.07,
      "learning_rate": 3.080795677799607e-05,
      "loss": 0.7012,
      "step": 156300
    },
    {
      "epoch": 307.27,
      "learning_rate": 3.0795677799607076e-05,
      "loss": 0.6964,
      "step": 156400
    },
    {
      "epoch": 307.47,
      "learning_rate": 3.0783398821218075e-05,
      "loss": 0.7029,
      "step": 156500
    },
    {
      "epoch": 307.66,
      "learning_rate": 3.0771119842829075e-05,
      "loss": 0.6933,
      "step": 156600
    },
    {
      "epoch": 307.86,
      "learning_rate": 3.075884086444008e-05,
      "loss": 0.6998,
      "step": 156700
    },
    {
      "epoch": 308.06,
      "learning_rate": 3.074656188605108e-05,
      "loss": 0.708,
      "step": 156800
    },
    {
      "epoch": 308.25,
      "learning_rate": 3.073428290766208e-05,
      "loss": 0.6953,
      "step": 156900
    },
    {
      "epoch": 308.45,
      "learning_rate": 3.072200392927309e-05,
      "loss": 0.6945,
      "step": 157000
    },
    {
      "epoch": 308.64,
      "learning_rate": 3.0709724950884087e-05,
      "loss": 0.6878,
      "step": 157100
    },
    {
      "epoch": 308.84,
      "learning_rate": 3.069744597249509e-05,
      "loss": 0.6821,
      "step": 157200
    },
    {
      "epoch": 309.04,
      "learning_rate": 3.068516699410609e-05,
      "loss": 0.6904,
      "step": 157300
    },
    {
      "epoch": 309.23,
      "learning_rate": 3.067288801571709e-05,
      "loss": 0.6907,
      "step": 157400
    },
    {
      "epoch": 309.43,
      "learning_rate": 3.06606090373281e-05,
      "loss": 0.6793,
      "step": 157500
    },
    {
      "epoch": 309.63,
      "learning_rate": 3.06483300589391e-05,
      "loss": 0.7024,
      "step": 157600
    },
    {
      "epoch": 309.82,
      "learning_rate": 3.06360510805501e-05,
      "loss": 0.7005,
      "step": 157700
    },
    {
      "epoch": 310.02,
      "learning_rate": 3.0623772102161104e-05,
      "loss": 0.6921,
      "step": 157800
    },
    {
      "epoch": 310.22,
      "learning_rate": 3.0611493123772104e-05,
      "loss": 0.697,
      "step": 157900
    },
    {
      "epoch": 310.41,
      "learning_rate": 3.0599214145383104e-05,
      "loss": 0.6815,
      "step": 158000
    },
    {
      "epoch": 310.61,
      "learning_rate": 3.058693516699411e-05,
      "loss": 0.682,
      "step": 158100
    },
    {
      "epoch": 310.81,
      "learning_rate": 3.057465618860511e-05,
      "loss": 0.6818,
      "step": 158200
    },
    {
      "epoch": 311.0,
      "learning_rate": 3.056237721021611e-05,
      "loss": 0.6968,
      "step": 158300
    },
    {
      "epoch": 311.2,
      "learning_rate": 3.055009823182711e-05,
      "loss": 0.6857,
      "step": 158400
    },
    {
      "epoch": 311.39,
      "learning_rate": 3.0537819253438115e-05,
      "loss": 0.6964,
      "step": 158500
    },
    {
      "epoch": 311.59,
      "learning_rate": 3.052554027504912e-05,
      "loss": 0.705,
      "step": 158600
    },
    {
      "epoch": 311.79,
      "learning_rate": 3.0513261296660118e-05,
      "loss": 0.6977,
      "step": 158700
    },
    {
      "epoch": 311.98,
      "learning_rate": 3.050098231827112e-05,
      "loss": 0.6914,
      "step": 158800
    },
    {
      "epoch": 312.18,
      "learning_rate": 3.0488703339882124e-05,
      "loss": 0.7084,
      "step": 158900
    },
    {
      "epoch": 312.38,
      "learning_rate": 3.0476424361493127e-05,
      "loss": 0.6902,
      "step": 159000
    },
    {
      "epoch": 312.57,
      "learning_rate": 3.0464145383104127e-05,
      "loss": 0.7021,
      "step": 159100
    },
    {
      "epoch": 312.77,
      "learning_rate": 3.045186640471513e-05,
      "loss": 0.6853,
      "step": 159200
    },
    {
      "epoch": 312.97,
      "learning_rate": 3.0439587426326133e-05,
      "loss": 0.6959,
      "step": 159300
    },
    {
      "epoch": 313.16,
      "learning_rate": 3.042730844793713e-05,
      "loss": 0.6987,
      "step": 159400
    },
    {
      "epoch": 313.36,
      "learning_rate": 3.0415029469548136e-05,
      "loss": 0.6774,
      "step": 159500
    },
    {
      "epoch": 313.56,
      "learning_rate": 3.040275049115914e-05,
      "loss": 0.7059,
      "step": 159600
    },
    {
      "epoch": 313.75,
      "learning_rate": 3.039047151277014e-05,
      "loss": 0.7095,
      "step": 159700
    },
    {
      "epoch": 313.95,
      "learning_rate": 3.0378192534381138e-05,
      "loss": 0.6938,
      "step": 159800
    },
    {
      "epoch": 314.15,
      "learning_rate": 3.036591355599214e-05,
      "loss": 0.6565,
      "step": 159900
    },
    {
      "epoch": 314.34,
      "learning_rate": 3.0353634577603147e-05,
      "loss": 0.6959,
      "step": 160000
    },
    {
      "epoch": 314.54,
      "learning_rate": 3.034135559921415e-05,
      "loss": 0.6912,
      "step": 160100
    },
    {
      "epoch": 314.73,
      "learning_rate": 3.0329076620825147e-05,
      "loss": 0.6875,
      "step": 160200
    },
    {
      "epoch": 314.93,
      "learning_rate": 3.031679764243615e-05,
      "loss": 0.6972,
      "step": 160300
    },
    {
      "epoch": 315.13,
      "learning_rate": 3.0304518664047156e-05,
      "loss": 0.683,
      "step": 160400
    },
    {
      "epoch": 315.32,
      "learning_rate": 3.0292239685658152e-05,
      "loss": 0.686,
      "step": 160500
    },
    {
      "epoch": 315.52,
      "learning_rate": 3.0279960707269155e-05,
      "loss": 0.6996,
      "step": 160600
    },
    {
      "epoch": 315.72,
      "learning_rate": 3.026768172888016e-05,
      "loss": 0.6882,
      "step": 160700
    },
    {
      "epoch": 315.91,
      "learning_rate": 3.025540275049116e-05,
      "loss": 0.6844,
      "step": 160800
    },
    {
      "epoch": 316.11,
      "learning_rate": 3.024312377210216e-05,
      "loss": 0.684,
      "step": 160900
    },
    {
      "epoch": 316.31,
      "learning_rate": 3.0230844793713164e-05,
      "loss": 0.7031,
      "step": 161000
    },
    {
      "epoch": 316.5,
      "learning_rate": 3.0218565815324167e-05,
      "loss": 0.6985,
      "step": 161100
    },
    {
      "epoch": 316.7,
      "learning_rate": 3.0206286836935167e-05,
      "loss": 0.697,
      "step": 161200
    },
    {
      "epoch": 316.9,
      "learning_rate": 3.019400785854617e-05,
      "loss": 0.6946,
      "step": 161300
    },
    {
      "epoch": 317.09,
      "learning_rate": 3.0181728880157173e-05,
      "loss": 0.6793,
      "step": 161400
    },
    {
      "epoch": 317.29,
      "learning_rate": 3.0169449901768176e-05,
      "loss": 0.6912,
      "step": 161500
    },
    {
      "epoch": 317.49,
      "learning_rate": 3.0157170923379176e-05,
      "loss": 0.7001,
      "step": 161600
    },
    {
      "epoch": 317.68,
      "learning_rate": 3.014489194499018e-05,
      "loss": 0.6998,
      "step": 161700
    },
    {
      "epoch": 317.88,
      "learning_rate": 3.013261296660118e-05,
      "loss": 0.6818,
      "step": 161800
    },
    {
      "epoch": 318.07,
      "learning_rate": 3.0120333988212185e-05,
      "loss": 0.6808,
      "step": 161900
    },
    {
      "epoch": 318.27,
      "learning_rate": 3.0108055009823184e-05,
      "loss": 0.6941,
      "step": 162000
    },
    {
      "epoch": 318.47,
      "learning_rate": 3.0095776031434187e-05,
      "loss": 0.7052,
      "step": 162100
    },
    {
      "epoch": 318.66,
      "learning_rate": 3.008349705304519e-05,
      "loss": 0.6853,
      "step": 162200
    },
    {
      "epoch": 318.86,
      "learning_rate": 3.0071218074656187e-05,
      "loss": 0.6848,
      "step": 162300
    },
    {
      "epoch": 319.06,
      "learning_rate": 3.005893909626719e-05,
      "loss": 0.6728,
      "step": 162400
    },
    {
      "epoch": 319.25,
      "learning_rate": 3.0046660117878196e-05,
      "loss": 0.677,
      "step": 162500
    },
    {
      "epoch": 319.45,
      "learning_rate": 3.00343811394892e-05,
      "loss": 0.6766,
      "step": 162600
    },
    {
      "epoch": 319.65,
      "learning_rate": 3.0022102161100195e-05,
      "loss": 0.6987,
      "step": 162700
    },
    {
      "epoch": 319.84,
      "learning_rate": 3.00098231827112e-05,
      "loss": 0.6899,
      "step": 162800
    },
    {
      "epoch": 320.04,
      "learning_rate": 2.9997544204322205e-05,
      "loss": 0.6806,
      "step": 162900
    },
    {
      "epoch": 320.24,
      "learning_rate": 2.99852652259332e-05,
      "loss": 0.6937,
      "step": 163000
    },
    {
      "epoch": 320.43,
      "learning_rate": 2.9972986247544204e-05,
      "loss": 0.6753,
      "step": 163100
    },
    {
      "epoch": 320.63,
      "learning_rate": 2.9960707269155207e-05,
      "loss": 0.6959,
      "step": 163200
    },
    {
      "epoch": 320.83,
      "learning_rate": 2.994842829076621e-05,
      "loss": 0.6778,
      "step": 163300
    },
    {
      "epoch": 321.02,
      "learning_rate": 2.993614931237721e-05,
      "loss": 0.6855,
      "step": 163400
    },
    {
      "epoch": 321.22,
      "learning_rate": 2.9923870333988213e-05,
      "loss": 0.7138,
      "step": 163500
    },
    {
      "epoch": 321.41,
      "learning_rate": 2.9911591355599216e-05,
      "loss": 0.694,
      "step": 163600
    },
    {
      "epoch": 321.61,
      "learning_rate": 2.989931237721022e-05,
      "loss": 0.677,
      "step": 163700
    },
    {
      "epoch": 321.81,
      "learning_rate": 2.988703339882122e-05,
      "loss": 0.6736,
      "step": 163800
    },
    {
      "epoch": 322.0,
      "learning_rate": 2.987475442043222e-05,
      "loss": 0.6716,
      "step": 163900
    },
    {
      "epoch": 322.2,
      "learning_rate": 2.9862475442043225e-05,
      "loss": 0.6896,
      "step": 164000
    },
    {
      "epoch": 322.4,
      "learning_rate": 2.9850196463654224e-05,
      "loss": 0.6762,
      "step": 164100
    },
    {
      "epoch": 322.59,
      "learning_rate": 2.9837917485265227e-05,
      "loss": 0.6797,
      "step": 164200
    },
    {
      "epoch": 322.79,
      "learning_rate": 2.982563850687623e-05,
      "loss": 0.6804,
      "step": 164300
    },
    {
      "epoch": 322.99,
      "learning_rate": 2.9813359528487233e-05,
      "loss": 0.6897,
      "step": 164400
    },
    {
      "epoch": 323.18,
      "learning_rate": 2.9801080550098233e-05,
      "loss": 0.6849,
      "step": 164500
    },
    {
      "epoch": 323.38,
      "learning_rate": 2.9788801571709236e-05,
      "loss": 0.6892,
      "step": 164600
    },
    {
      "epoch": 323.58,
      "learning_rate": 2.977652259332024e-05,
      "loss": 0.6952,
      "step": 164700
    },
    {
      "epoch": 323.77,
      "learning_rate": 2.9764243614931235e-05,
      "loss": 0.7054,
      "step": 164800
    },
    {
      "epoch": 323.97,
      "learning_rate": 2.975196463654224e-05,
      "loss": 0.7014,
      "step": 164900
    },
    {
      "epoch": 324.17,
      "learning_rate": 2.9739685658153245e-05,
      "loss": 0.6831,
      "step": 165000
    },
    {
      "epoch": 324.36,
      "learning_rate": 2.9727406679764248e-05,
      "loss": 0.6833,
      "step": 165100
    },
    {
      "epoch": 324.56,
      "learning_rate": 2.9715127701375244e-05,
      "loss": 0.6924,
      "step": 165200
    },
    {
      "epoch": 324.75,
      "learning_rate": 2.9702848722986247e-05,
      "loss": 0.7026,
      "step": 165300
    },
    {
      "epoch": 324.95,
      "learning_rate": 2.9690569744597253e-05,
      "loss": 0.6871,
      "step": 165400
    },
    {
      "epoch": 325.15,
      "learning_rate": 2.9678290766208256e-05,
      "loss": 0.7019,
      "step": 165500
    },
    {
      "epoch": 325.34,
      "learning_rate": 2.9666011787819253e-05,
      "loss": 0.6892,
      "step": 165600
    },
    {
      "epoch": 325.54,
      "learning_rate": 2.9653732809430256e-05,
      "loss": 0.6976,
      "step": 165700
    },
    {
      "epoch": 325.74,
      "learning_rate": 2.964145383104126e-05,
      "loss": 0.7011,
      "step": 165800
    },
    {
      "epoch": 325.93,
      "learning_rate": 2.962917485265226e-05,
      "loss": 0.6859,
      "step": 165900
    },
    {
      "epoch": 326.13,
      "learning_rate": 2.961689587426326e-05,
      "loss": 0.6766,
      "step": 166000
    },
    {
      "epoch": 326.33,
      "learning_rate": 2.9604616895874264e-05,
      "loss": 0.6796,
      "step": 166100
    },
    {
      "epoch": 326.52,
      "learning_rate": 2.9592337917485267e-05,
      "loss": 0.6955,
      "step": 166200
    },
    {
      "epoch": 326.72,
      "learning_rate": 2.9580058939096267e-05,
      "loss": 0.6793,
      "step": 166300
    },
    {
      "epoch": 326.92,
      "learning_rate": 2.956777996070727e-05,
      "loss": 0.679,
      "step": 166400
    },
    {
      "epoch": 327.11,
      "learning_rate": 2.9555500982318273e-05,
      "loss": 0.6774,
      "step": 166500
    },
    {
      "epoch": 327.31,
      "learning_rate": 2.9543222003929273e-05,
      "loss": 0.6833,
      "step": 166600
    },
    {
      "epoch": 327.5,
      "learning_rate": 2.9530943025540276e-05,
      "loss": 0.6819,
      "step": 166700
    },
    {
      "epoch": 327.7,
      "learning_rate": 2.951866404715128e-05,
      "loss": 0.685,
      "step": 166800
    },
    {
      "epoch": 327.9,
      "learning_rate": 2.9506385068762282e-05,
      "loss": 0.6822,
      "step": 166900
    },
    {
      "epoch": 328.09,
      "learning_rate": 2.949410609037328e-05,
      "loss": 0.6853,
      "step": 167000
    },
    {
      "epoch": 328.29,
      "learning_rate": 2.9481827111984285e-05,
      "loss": 0.6903,
      "step": 167100
    },
    {
      "epoch": 328.49,
      "learning_rate": 2.9469548133595288e-05,
      "loss": 0.6616,
      "step": 167200
    },
    {
      "epoch": 328.68,
      "learning_rate": 2.945726915520629e-05,
      "loss": 0.6853,
      "step": 167300
    },
    {
      "epoch": 328.88,
      "learning_rate": 2.944499017681729e-05,
      "loss": 0.6744,
      "step": 167400
    },
    {
      "epoch": 329.08,
      "learning_rate": 2.9432711198428293e-05,
      "loss": 0.6852,
      "step": 167500
    },
    {
      "epoch": 329.27,
      "learning_rate": 2.9420432220039296e-05,
      "loss": 0.6896,
      "step": 167600
    },
    {
      "epoch": 329.47,
      "learning_rate": 2.9408153241650293e-05,
      "loss": 0.6867,
      "step": 167700
    },
    {
      "epoch": 329.67,
      "learning_rate": 2.9395874263261296e-05,
      "loss": 0.6942,
      "step": 167800
    },
    {
      "epoch": 329.86,
      "learning_rate": 2.9383595284872302e-05,
      "loss": 0.6745,
      "step": 167900
    },
    {
      "epoch": 330.06,
      "learning_rate": 2.9371316306483305e-05,
      "loss": 0.6946,
      "step": 168000
    },
    {
      "epoch": 330.26,
      "learning_rate": 2.93590373280943e-05,
      "loss": 0.6978,
      "step": 168100
    },
    {
      "epoch": 330.45,
      "learning_rate": 2.9346758349705304e-05,
      "loss": 0.6861,
      "step": 168200
    },
    {
      "epoch": 330.65,
      "learning_rate": 2.9334479371316307e-05,
      "loss": 0.6895,
      "step": 168300
    },
    {
      "epoch": 330.84,
      "learning_rate": 2.9322200392927314e-05,
      "loss": 0.6866,
      "step": 168400
    },
    {
      "epoch": 331.04,
      "learning_rate": 2.930992141453831e-05,
      "loss": 0.6766,
      "step": 168500
    },
    {
      "epoch": 331.24,
      "learning_rate": 2.9297642436149313e-05,
      "loss": 0.6916,
      "step": 168600
    },
    {
      "epoch": 331.43,
      "learning_rate": 2.9285363457760316e-05,
      "loss": 0.6879,
      "step": 168700
    },
    {
      "epoch": 331.63,
      "learning_rate": 2.9273084479371316e-05,
      "loss": 0.6676,
      "step": 168800
    },
    {
      "epoch": 331.83,
      "learning_rate": 2.926080550098232e-05,
      "loss": 0.681,
      "step": 168900
    },
    {
      "epoch": 332.02,
      "learning_rate": 2.9248526522593322e-05,
      "loss": 0.6756,
      "step": 169000
    },
    {
      "epoch": 332.22,
      "learning_rate": 2.9236247544204325e-05,
      "loss": 0.6835,
      "step": 169100
    },
    {
      "epoch": 332.42,
      "learning_rate": 2.9223968565815325e-05,
      "loss": 0.672,
      "step": 169200
    },
    {
      "epoch": 332.61,
      "learning_rate": 2.9211689587426328e-05,
      "loss": 0.6802,
      "step": 169300
    },
    {
      "epoch": 332.81,
      "learning_rate": 2.919941060903733e-05,
      "loss": 0.6954,
      "step": 169400
    },
    {
      "epoch": 333.01,
      "learning_rate": 2.918713163064833e-05,
      "loss": 0.6895,
      "step": 169500
    },
    {
      "epoch": 333.2,
      "learning_rate": 2.9174852652259333e-05,
      "loss": 0.6735,
      "step": 169600
    },
    {
      "epoch": 333.4,
      "learning_rate": 2.9162573673870336e-05,
      "loss": 0.6911,
      "step": 169700
    },
    {
      "epoch": 333.6,
      "learning_rate": 2.915029469548134e-05,
      "loss": 0.6761,
      "step": 169800
    },
    {
      "epoch": 333.79,
      "learning_rate": 2.913801571709234e-05,
      "loss": 0.6811,
      "step": 169900
    },
    {
      "epoch": 333.99,
      "learning_rate": 2.9125736738703342e-05,
      "loss": 0.687,
      "step": 170000
    },
    {
      "epoch": 334.18,
      "learning_rate": 2.9113457760314345e-05,
      "loss": 0.6744,
      "step": 170100
    },
    {
      "epoch": 334.38,
      "learning_rate": 2.9101178781925348e-05,
      "loss": 0.6835,
      "step": 170200
    },
    {
      "epoch": 334.58,
      "learning_rate": 2.9088899803536344e-05,
      "loss": 0.6695,
      "step": 170300
    },
    {
      "epoch": 334.77,
      "learning_rate": 2.907662082514735e-05,
      "loss": 0.6755,
      "step": 170400
    },
    {
      "epoch": 334.97,
      "learning_rate": 2.9064341846758354e-05,
      "loss": 0.7028,
      "step": 170500
    },
    {
      "epoch": 335.17,
      "learning_rate": 2.905206286836935e-05,
      "loss": 0.6753,
      "step": 170600
    },
    {
      "epoch": 335.36,
      "learning_rate": 2.9039783889980353e-05,
      "loss": 0.6789,
      "step": 170700
    },
    {
      "epoch": 335.56,
      "learning_rate": 2.9027504911591356e-05,
      "loss": 0.6726,
      "step": 170800
    },
    {
      "epoch": 335.76,
      "learning_rate": 2.9015225933202363e-05,
      "loss": 0.6979,
      "step": 170900
    },
    {
      "epoch": 335.95,
      "learning_rate": 2.900294695481336e-05,
      "loss": 0.6816,
      "step": 171000
    },
    {
      "epoch": 336.15,
      "learning_rate": 2.8990667976424362e-05,
      "loss": 0.6886,
      "step": 171100
    },
    {
      "epoch": 336.35,
      "learning_rate": 2.8978388998035365e-05,
      "loss": 0.6895,
      "step": 171200
    },
    {
      "epoch": 336.54,
      "learning_rate": 2.8966110019646364e-05,
      "loss": 0.6744,
      "step": 171300
    },
    {
      "epoch": 336.74,
      "learning_rate": 2.8953831041257367e-05,
      "loss": 0.6902,
      "step": 171400
    },
    {
      "epoch": 336.94,
      "learning_rate": 2.894155206286837e-05,
      "loss": 0.692,
      "step": 171500
    },
    {
      "epoch": 337.13,
      "learning_rate": 2.8929273084479374e-05,
      "loss": 0.6838,
      "step": 171600
    },
    {
      "epoch": 337.33,
      "learning_rate": 2.8916994106090373e-05,
      "loss": 0.6964,
      "step": 171700
    },
    {
      "epoch": 337.52,
      "learning_rate": 2.8904715127701376e-05,
      "loss": 0.6923,
      "step": 171800
    },
    {
      "epoch": 337.72,
      "learning_rate": 2.889243614931238e-05,
      "loss": 0.6792,
      "step": 171900
    },
    {
      "epoch": 337.92,
      "learning_rate": 2.8880157170923382e-05,
      "loss": 0.6809,
      "step": 172000
    },
    {
      "epoch": 338.11,
      "learning_rate": 2.8867878192534382e-05,
      "loss": 0.6819,
      "step": 172100
    },
    {
      "epoch": 338.31,
      "learning_rate": 2.8855599214145385e-05,
      "loss": 0.6916,
      "step": 172200
    },
    {
      "epoch": 338.51,
      "learning_rate": 2.8843320235756388e-05,
      "loss": 0.6775,
      "step": 172300
    },
    {
      "epoch": 338.7,
      "learning_rate": 2.8831041257367388e-05,
      "loss": 0.6848,
      "step": 172400
    },
    {
      "epoch": 338.9,
      "learning_rate": 2.881876227897839e-05,
      "loss": 0.6972,
      "step": 172500
    },
    {
      "epoch": 339.1,
      "learning_rate": 2.8806483300589394e-05,
      "loss": 0.6839,
      "step": 172600
    },
    {
      "epoch": 339.29,
      "learning_rate": 2.8794204322200397e-05,
      "loss": 0.6711,
      "step": 172700
    },
    {
      "epoch": 339.49,
      "learning_rate": 2.8781925343811393e-05,
      "loss": 0.7063,
      "step": 172800
    },
    {
      "epoch": 339.69,
      "learning_rate": 2.87696463654224e-05,
      "loss": 0.6926,
      "step": 172900
    },
    {
      "epoch": 339.88,
      "learning_rate": 2.8757367387033402e-05,
      "loss": 0.6917,
      "step": 173000
    },
    {
      "epoch": 340.08,
      "learning_rate": 2.87450884086444e-05,
      "loss": 0.6573,
      "step": 173100
    },
    {
      "epoch": 340.28,
      "learning_rate": 2.8732809430255402e-05,
      "loss": 0.6705,
      "step": 173200
    },
    {
      "epoch": 340.47,
      "learning_rate": 2.8720530451866408e-05,
      "loss": 0.6721,
      "step": 173300
    },
    {
      "epoch": 340.67,
      "learning_rate": 2.870825147347741e-05,
      "loss": 0.6827,
      "step": 173400
    },
    {
      "epoch": 340.86,
      "learning_rate": 2.8695972495088407e-05,
      "loss": 0.6874,
      "step": 173500
    },
    {
      "epoch": 341.06,
      "learning_rate": 2.868369351669941e-05,
      "loss": 0.6781,
      "step": 173600
    },
    {
      "epoch": 341.26,
      "learning_rate": 2.8671414538310413e-05,
      "loss": 0.6888,
      "step": 173700
    },
    {
      "epoch": 341.45,
      "learning_rate": 2.865913555992142e-05,
      "loss": 0.682,
      "step": 173800
    },
    {
      "epoch": 341.65,
      "learning_rate": 2.8646856581532416e-05,
      "loss": 0.6709,
      "step": 173900
    },
    {
      "epoch": 341.85,
      "learning_rate": 2.863457760314342e-05,
      "loss": 0.668,
      "step": 174000
    },
    {
      "epoch": 342.04,
      "learning_rate": 2.8622298624754422e-05,
      "loss": 0.6711,
      "step": 174100
    },
    {
      "epoch": 342.24,
      "learning_rate": 2.8610019646365422e-05,
      "loss": 0.6731,
      "step": 174200
    },
    {
      "epoch": 342.44,
      "learning_rate": 2.8597740667976425e-05,
      "loss": 0.6782,
      "step": 174300
    },
    {
      "epoch": 342.63,
      "learning_rate": 2.8585461689587428e-05,
      "loss": 0.6766,
      "step": 174400
    },
    {
      "epoch": 342.83,
      "learning_rate": 2.857318271119843e-05,
      "loss": 0.6763,
      "step": 174500
    },
    {
      "epoch": 343.03,
      "learning_rate": 2.856090373280943e-05,
      "loss": 0.6722,
      "step": 174600
    },
    {
      "epoch": 343.22,
      "learning_rate": 2.8548624754420434e-05,
      "loss": 0.6714,
      "step": 174700
    },
    {
      "epoch": 343.42,
      "learning_rate": 2.8536345776031437e-05,
      "loss": 0.6778,
      "step": 174800
    },
    {
      "epoch": 343.61,
      "learning_rate": 2.852406679764244e-05,
      "loss": 0.6867,
      "step": 174900
    },
    {
      "epoch": 343.81,
      "learning_rate": 2.851178781925344e-05,
      "loss": 0.6877,
      "step": 175000
    },
    {
      "epoch": 344.01,
      "learning_rate": 2.8499508840864442e-05,
      "loss": 0.6892,
      "step": 175100
    },
    {
      "epoch": 344.2,
      "learning_rate": 2.8487229862475445e-05,
      "loss": 0.6772,
      "step": 175200
    },
    {
      "epoch": 344.4,
      "learning_rate": 2.847495088408644e-05,
      "loss": 0.6715,
      "step": 175300
    },
    {
      "epoch": 344.6,
      "learning_rate": 2.8462671905697448e-05,
      "loss": 0.687,
      "step": 175400
    },
    {
      "epoch": 344.79,
      "learning_rate": 2.845039292730845e-05,
      "loss": 0.669,
      "step": 175500
    },
    {
      "epoch": 344.99,
      "learning_rate": 2.8438113948919454e-05,
      "loss": 0.6803,
      "step": 175600
    },
    {
      "epoch": 345.19,
      "learning_rate": 2.842583497053045e-05,
      "loss": 0.6873,
      "step": 175700
    },
    {
      "epoch": 345.38,
      "learning_rate": 2.8413555992141457e-05,
      "loss": 0.6831,
      "step": 175800
    },
    {
      "epoch": 345.58,
      "learning_rate": 2.840127701375246e-05,
      "loss": 0.6788,
      "step": 175900
    },
    {
      "epoch": 345.78,
      "learning_rate": 2.8388998035363456e-05,
      "loss": 0.6809,
      "step": 176000
    },
    {
      "epoch": 345.97,
      "learning_rate": 2.837671905697446e-05,
      "loss": 0.6826,
      "step": 176100
    },
    {
      "epoch": 346.17,
      "learning_rate": 2.8364440078585462e-05,
      "loss": 0.6824,
      "step": 176200
    },
    {
      "epoch": 346.37,
      "learning_rate": 2.835216110019647e-05,
      "loss": 0.7044,
      "step": 176300
    },
    {
      "epoch": 346.56,
      "learning_rate": 2.8339882121807465e-05,
      "loss": 0.6673,
      "step": 176400
    },
    {
      "epoch": 346.76,
      "learning_rate": 2.8327603143418468e-05,
      "loss": 0.6873,
      "step": 176500
    },
    {
      "epoch": 346.95,
      "learning_rate": 2.831532416502947e-05,
      "loss": 0.6767,
      "step": 176600
    },
    {
      "epoch": 347.15,
      "learning_rate": 2.8303045186640474e-05,
      "loss": 0.6834,
      "step": 176700
    },
    {
      "epoch": 347.35,
      "learning_rate": 2.8290766208251474e-05,
      "loss": 0.6804,
      "step": 176800
    },
    {
      "epoch": 347.54,
      "learning_rate": 2.8278487229862477e-05,
      "loss": 0.6764,
      "step": 176900
    },
    {
      "epoch": 347.74,
      "learning_rate": 2.826620825147348e-05,
      "loss": 0.6779,
      "step": 177000
    },
    {
      "epoch": 347.94,
      "learning_rate": 2.825392927308448e-05,
      "loss": 0.6834,
      "step": 177100
    },
    {
      "epoch": 348.13,
      "learning_rate": 2.8241650294695482e-05,
      "loss": 0.6719,
      "step": 177200
    },
    {
      "epoch": 348.33,
      "learning_rate": 2.8229371316306485e-05,
      "loss": 0.6976,
      "step": 177300
    },
    {
      "epoch": 348.53,
      "learning_rate": 2.821709233791749e-05,
      "loss": 0.6754,
      "step": 177400
    },
    {
      "epoch": 348.72,
      "learning_rate": 2.8204813359528488e-05,
      "loss": 0.6624,
      "step": 177500
    },
    {
      "epoch": 348.92,
      "learning_rate": 2.819253438113949e-05,
      "loss": 0.6929,
      "step": 177600
    },
    {
      "epoch": 349.12,
      "learning_rate": 2.8180255402750494e-05,
      "loss": 0.6887,
      "step": 177700
    },
    {
      "epoch": 349.31,
      "learning_rate": 2.816797642436149e-05,
      "loss": 0.6925,
      "step": 177800
    },
    {
      "epoch": 349.51,
      "learning_rate": 2.8155697445972497e-05,
      "loss": 0.6804,
      "step": 177900
    },
    {
      "epoch": 349.71,
      "learning_rate": 2.81434184675835e-05,
      "loss": 0.6833,
      "step": 178000
    },
    {
      "epoch": 349.9,
      "learning_rate": 2.8131139489194503e-05,
      "loss": 0.6786,
      "step": 178100
    },
    {
      "epoch": 350.1,
      "learning_rate": 2.81188605108055e-05,
      "loss": 0.6739,
      "step": 178200
    },
    {
      "epoch": 350.29,
      "learning_rate": 2.8106581532416505e-05,
      "loss": 0.6829,
      "step": 178300
    },
    {
      "epoch": 350.49,
      "learning_rate": 2.809430255402751e-05,
      "loss": 0.6896,
      "step": 178400
    },
    {
      "epoch": 350.69,
      "learning_rate": 2.808202357563851e-05,
      "loss": 0.683,
      "step": 178500
    },
    {
      "epoch": 350.88,
      "learning_rate": 2.8069744597249508e-05,
      "loss": 0.6809,
      "step": 178600
    },
    {
      "epoch": 351.08,
      "learning_rate": 2.805746561886051e-05,
      "loss": 0.6789,
      "step": 178700
    },
    {
      "epoch": 351.28,
      "learning_rate": 2.8045186640471517e-05,
      "loss": 0.6625,
      "step": 178800
    },
    {
      "epoch": 351.47,
      "learning_rate": 2.8032907662082513e-05,
      "loss": 0.6798,
      "step": 178900
    },
    {
      "epoch": 351.67,
      "learning_rate": 2.8020628683693517e-05,
      "loss": 0.6809,
      "step": 179000
    },
    {
      "epoch": 351.87,
      "learning_rate": 2.800834970530452e-05,
      "loss": 0.6885,
      "step": 179100
    },
    {
      "epoch": 352.06,
      "learning_rate": 2.7996070726915523e-05,
      "loss": 0.6735,
      "step": 179200
    },
    {
      "epoch": 352.26,
      "learning_rate": 2.7983791748526522e-05,
      "loss": 0.671,
      "step": 179300
    },
    {
      "epoch": 352.46,
      "learning_rate": 2.7971512770137525e-05,
      "loss": 0.6897,
      "step": 179400
    },
    {
      "epoch": 352.65,
      "learning_rate": 2.7959233791748528e-05,
      "loss": 0.673,
      "step": 179500
    },
    {
      "epoch": 352.85,
      "learning_rate": 2.7946954813359528e-05,
      "loss": 0.6774,
      "step": 179600
    },
    {
      "epoch": 353.05,
      "learning_rate": 2.793467583497053e-05,
      "loss": 0.671,
      "step": 179700
    },
    {
      "epoch": 353.24,
      "learning_rate": 2.7922396856581534e-05,
      "loss": 0.6687,
      "step": 179800
    },
    {
      "epoch": 353.44,
      "learning_rate": 2.7910117878192537e-05,
      "loss": 0.6709,
      "step": 179900
    },
    {
      "epoch": 353.63,
      "learning_rate": 2.7897838899803537e-05,
      "loss": 0.6635,
      "step": 180000
    },
    {
      "epoch": 353.83,
      "learning_rate": 2.788555992141454e-05,
      "loss": 0.6827,
      "step": 180100
    },
    {
      "epoch": 354.03,
      "learning_rate": 2.7873280943025543e-05,
      "loss": 0.6954,
      "step": 180200
    },
    {
      "epoch": 354.22,
      "learning_rate": 2.7861001964636546e-05,
      "loss": 0.6689,
      "step": 180300
    },
    {
      "epoch": 354.42,
      "learning_rate": 2.7848722986247545e-05,
      "loss": 0.6693,
      "step": 180400
    },
    {
      "epoch": 354.62,
      "learning_rate": 2.783644400785855e-05,
      "loss": 0.6857,
      "step": 180500
    },
    {
      "epoch": 354.81,
      "learning_rate": 2.782416502946955e-05,
      "loss": 0.6638,
      "step": 180600
    },
    {
      "epoch": 355.01,
      "learning_rate": 2.7811886051080548e-05,
      "loss": 0.6747,
      "step": 180700
    },
    {
      "epoch": 355.21,
      "learning_rate": 2.7799607072691554e-05,
      "loss": 0.6673,
      "step": 180800
    },
    {
      "epoch": 355.4,
      "learning_rate": 2.7787328094302557e-05,
      "loss": 0.6693,
      "step": 180900
    },
    {
      "epoch": 355.6,
      "learning_rate": 2.777504911591356e-05,
      "loss": 0.6731,
      "step": 181000
    },
    {
      "epoch": 355.8,
      "learning_rate": 2.7762770137524556e-05,
      "loss": 0.6802,
      "step": 181100
    },
    {
      "epoch": 355.99,
      "learning_rate": 2.775049115913556e-05,
      "loss": 0.6717,
      "step": 181200
    },
    {
      "epoch": 356.19,
      "learning_rate": 2.7738212180746566e-05,
      "loss": 0.6884,
      "step": 181300
    },
    {
      "epoch": 356.39,
      "learning_rate": 2.7725933202357562e-05,
      "loss": 0.6662,
      "step": 181400
    },
    {
      "epoch": 356.58,
      "learning_rate": 2.7713654223968565e-05,
      "loss": 0.6883,
      "step": 181500
    },
    {
      "epoch": 356.78,
      "learning_rate": 2.7701375245579568e-05,
      "loss": 0.6659,
      "step": 181600
    },
    {
      "epoch": 356.97,
      "learning_rate": 2.768909626719057e-05,
      "loss": 0.6795,
      "step": 181700
    },
    {
      "epoch": 357.17,
      "learning_rate": 2.767681728880157e-05,
      "loss": 0.6817,
      "step": 181800
    },
    {
      "epoch": 357.37,
      "learning_rate": 2.7664538310412574e-05,
      "loss": 0.6751,
      "step": 181900
    },
    {
      "epoch": 357.56,
      "learning_rate": 2.7652259332023577e-05,
      "loss": 0.668,
      "step": 182000
    },
    {
      "epoch": 357.76,
      "learning_rate": 2.763998035363458e-05,
      "loss": 0.6824,
      "step": 182100
    },
    {
      "epoch": 357.96,
      "learning_rate": 2.762770137524558e-05,
      "loss": 0.6768,
      "step": 182200
    },
    {
      "epoch": 358.15,
      "learning_rate": 2.7615422396856583e-05,
      "loss": 0.6829,
      "step": 182300
    },
    {
      "epoch": 358.35,
      "learning_rate": 2.7603143418467586e-05,
      "loss": 0.6775,
      "step": 182400
    },
    {
      "epoch": 358.55,
      "learning_rate": 2.7590864440078585e-05,
      "loss": 0.6791,
      "step": 182500
    },
    {
      "epoch": 358.74,
      "learning_rate": 2.757858546168959e-05,
      "loss": 0.657,
      "step": 182600
    },
    {
      "epoch": 358.94,
      "learning_rate": 2.756630648330059e-05,
      "loss": 0.682,
      "step": 182700
    },
    {
      "epoch": 359.14,
      "learning_rate": 2.7554027504911594e-05,
      "loss": 0.67,
      "step": 182800
    },
    {
      "epoch": 359.33,
      "learning_rate": 2.7541748526522594e-05,
      "loss": 0.6816,
      "step": 182900
    },
    {
      "epoch": 359.53,
      "learning_rate": 2.7529469548133597e-05,
      "loss": 0.6787,
      "step": 183000
    },
    {
      "epoch": 359.72,
      "learning_rate": 2.75171905697446e-05,
      "loss": 0.6714,
      "step": 183100
    },
    {
      "epoch": 359.92,
      "learning_rate": 2.7504911591355603e-05,
      "loss": 0.6829,
      "step": 183200
    },
    {
      "epoch": 360.12,
      "learning_rate": 2.7492632612966603e-05,
      "loss": 0.6806,
      "step": 183300
    },
    {
      "epoch": 360.31,
      "learning_rate": 2.7480353634577606e-05,
      "loss": 0.6724,
      "step": 183400
    },
    {
      "epoch": 360.51,
      "learning_rate": 2.746807465618861e-05,
      "loss": 0.6734,
      "step": 183500
    },
    {
      "epoch": 360.71,
      "learning_rate": 2.7455795677799605e-05,
      "loss": 0.6593,
      "step": 183600
    },
    {
      "epoch": 360.9,
      "learning_rate": 2.7443516699410608e-05,
      "loss": 0.6895,
      "step": 183700
    },
    {
      "epoch": 361.1,
      "learning_rate": 2.7431237721021615e-05,
      "loss": 0.6934,
      "step": 183800
    },
    {
      "epoch": 361.3,
      "learning_rate": 2.7418958742632618e-05,
      "loss": 0.6773,
      "step": 183900
    },
    {
      "epoch": 361.49,
      "learning_rate": 2.7406679764243614e-05,
      "loss": 0.6698,
      "step": 184000
    },
    {
      "epoch": 361.69,
      "learning_rate": 2.7394400785854617e-05,
      "loss": 0.6866,
      "step": 184100
    },
    {
      "epoch": 361.89,
      "learning_rate": 2.7382121807465623e-05,
      "loss": 0.668,
      "step": 184200
    },
    {
      "epoch": 362.08,
      "learning_rate": 2.736984282907662e-05,
      "loss": 0.6782,
      "step": 184300
    },
    {
      "epoch": 362.28,
      "learning_rate": 2.7357563850687623e-05,
      "loss": 0.6757,
      "step": 184400
    },
    {
      "epoch": 362.48,
      "learning_rate": 2.7345284872298626e-05,
      "loss": 0.6758,
      "step": 184500
    },
    {
      "epoch": 362.67,
      "learning_rate": 2.733300589390963e-05,
      "loss": 0.6633,
      "step": 184600
    },
    {
      "epoch": 362.87,
      "learning_rate": 2.7320726915520628e-05,
      "loss": 0.6767,
      "step": 184700
    },
    {
      "epoch": 363.06,
      "learning_rate": 2.730844793713163e-05,
      "loss": 0.6759,
      "step": 184800
    },
    {
      "epoch": 363.26,
      "learning_rate": 2.7296168958742634e-05,
      "loss": 0.6834,
      "step": 184900
    },
    {
      "epoch": 363.46,
      "learning_rate": 2.7283889980353637e-05,
      "loss": 0.6606,
      "step": 185000
    },
    {
      "epoch": 363.65,
      "learning_rate": 2.7271611001964637e-05,
      "loss": 0.6684,
      "step": 185100
    },
    {
      "epoch": 363.85,
      "learning_rate": 2.725933202357564e-05,
      "loss": 0.6797,
      "step": 185200
    },
    {
      "epoch": 364.05,
      "learning_rate": 2.7247053045186643e-05,
      "loss": 0.6657,
      "step": 185300
    },
    {
      "epoch": 364.24,
      "learning_rate": 2.7234774066797643e-05,
      "loss": 0.661,
      "step": 185400
    },
    {
      "epoch": 364.44,
      "learning_rate": 2.7222495088408646e-05,
      "loss": 0.6748,
      "step": 185500
    },
    {
      "epoch": 364.64,
      "learning_rate": 2.721021611001965e-05,
      "loss": 0.6737,
      "step": 185600
    },
    {
      "epoch": 364.83,
      "learning_rate": 2.7197937131630652e-05,
      "loss": 0.6864,
      "step": 185700
    },
    {
      "epoch": 365.03,
      "learning_rate": 2.718565815324165e-05,
      "loss": 0.6795,
      "step": 185800
    },
    {
      "epoch": 365.23,
      "learning_rate": 2.7173379174852654e-05,
      "loss": 0.6741,
      "step": 185900
    },
    {
      "epoch": 365.42,
      "learning_rate": 2.7161100196463658e-05,
      "loss": 0.6706,
      "step": 186000
    },
    {
      "epoch": 365.62,
      "learning_rate": 2.7148821218074654e-05,
      "loss": 0.6814,
      "step": 186100
    },
    {
      "epoch": 365.82,
      "learning_rate": 2.7136542239685657e-05,
      "loss": 0.6778,
      "step": 186200
    },
    {
      "epoch": 366.01,
      "learning_rate": 2.7124263261296663e-05,
      "loss": 0.6585,
      "step": 186300
    },
    {
      "epoch": 366.21,
      "learning_rate": 2.7111984282907666e-05,
      "loss": 0.6703,
      "step": 186400
    },
    {
      "epoch": 366.4,
      "learning_rate": 2.7099705304518663e-05,
      "loss": 0.66,
      "step": 186500
    },
    {
      "epoch": 366.6,
      "learning_rate": 2.7087426326129666e-05,
      "loss": 0.685,
      "step": 186600
    },
    {
      "epoch": 366.8,
      "learning_rate": 2.7075147347740672e-05,
      "loss": 0.6735,
      "step": 186700
    },
    {
      "epoch": 366.99,
      "learning_rate": 2.7062868369351675e-05,
      "loss": 0.6971,
      "step": 186800
    },
    {
      "epoch": 367.19,
      "learning_rate": 2.705058939096267e-05,
      "loss": 0.6533,
      "step": 186900
    },
    {
      "epoch": 367.39,
      "learning_rate": 2.7038310412573674e-05,
      "loss": 0.6775,
      "step": 187000
    },
    {
      "epoch": 367.58,
      "learning_rate": 2.7026031434184677e-05,
      "loss": 0.6648,
      "step": 187100
    },
    {
      "epoch": 367.78,
      "learning_rate": 2.7013752455795677e-05,
      "loss": 0.6737,
      "step": 187200
    },
    {
      "epoch": 367.98,
      "learning_rate": 2.700147347740668e-05,
      "loss": 0.662,
      "step": 187300
    },
    {
      "epoch": 368.17,
      "learning_rate": 2.6989194499017683e-05,
      "loss": 0.6602,
      "step": 187400
    },
    {
      "epoch": 368.37,
      "learning_rate": 2.6976915520628686e-05,
      "loss": 0.6867,
      "step": 187500
    },
    {
      "epoch": 368.57,
      "learning_rate": 2.6964636542239686e-05,
      "loss": 0.673,
      "step": 187600
    },
    {
      "epoch": 368.76,
      "learning_rate": 2.695235756385069e-05,
      "loss": 0.6888,
      "step": 187700
    },
    {
      "epoch": 368.96,
      "learning_rate": 2.6940078585461692e-05,
      "loss": 0.6726,
      "step": 187800
    },
    {
      "epoch": 369.16,
      "learning_rate": 2.692779960707269e-05,
      "loss": 0.6696,
      "step": 187900
    },
    {
      "epoch": 369.35,
      "learning_rate": 2.6915520628683694e-05,
      "loss": 0.6722,
      "step": 188000
    },
    {
      "epoch": 369.55,
      "learning_rate": 2.6903241650294697e-05,
      "loss": 0.6778,
      "step": 188100
    },
    {
      "epoch": 369.74,
      "learning_rate": 2.68909626719057e-05,
      "loss": 0.6704,
      "step": 188200
    },
    {
      "epoch": 369.94,
      "learning_rate": 2.68786836935167e-05,
      "loss": 0.6559,
      "step": 188300
    },
    {
      "epoch": 370.14,
      "learning_rate": 2.6866404715127703e-05,
      "loss": 0.6727,
      "step": 188400
    },
    {
      "epoch": 370.33,
      "learning_rate": 2.6854125736738706e-05,
      "loss": 0.6655,
      "step": 188500
    },
    {
      "epoch": 370.53,
      "learning_rate": 2.684184675834971e-05,
      "loss": 0.6533,
      "step": 188600
    },
    {
      "epoch": 370.73,
      "learning_rate": 2.6829567779960705e-05,
      "loss": 0.6654,
      "step": 188700
    },
    {
      "epoch": 370.92,
      "learning_rate": 2.6817288801571712e-05,
      "loss": 0.6884,
      "step": 188800
    },
    {
      "epoch": 371.12,
      "learning_rate": 2.6805009823182715e-05,
      "loss": 0.644,
      "step": 188900
    },
    {
      "epoch": 371.32,
      "learning_rate": 2.679273084479371e-05,
      "loss": 0.6725,
      "step": 189000
    },
    {
      "epoch": 371.51,
      "learning_rate": 2.6780451866404714e-05,
      "loss": 0.661,
      "step": 189100
    },
    {
      "epoch": 371.71,
      "learning_rate": 2.676817288801572e-05,
      "loss": 0.6725,
      "step": 189200
    },
    {
      "epoch": 371.91,
      "learning_rate": 2.6755893909626724e-05,
      "loss": 0.6736,
      "step": 189300
    },
    {
      "epoch": 372.1,
      "learning_rate": 2.674361493123772e-05,
      "loss": 0.6666,
      "step": 189400
    },
    {
      "epoch": 372.3,
      "learning_rate": 2.6731335952848723e-05,
      "loss": 0.6765,
      "step": 189500
    },
    {
      "epoch": 372.5,
      "learning_rate": 2.6719056974459726e-05,
      "loss": 0.6742,
      "step": 189600
    },
    {
      "epoch": 372.69,
      "learning_rate": 2.6706777996070732e-05,
      "loss": 0.6759,
      "step": 189700
    },
    {
      "epoch": 372.89,
      "learning_rate": 2.669449901768173e-05,
      "loss": 0.6774,
      "step": 189800
    },
    {
      "epoch": 373.08,
      "learning_rate": 2.668222003929273e-05,
      "loss": 0.6629,
      "step": 189900
    },
    {
      "epoch": 373.28,
      "learning_rate": 2.6669941060903735e-05,
      "loss": 0.6639,
      "step": 190000
    },
    {
      "epoch": 373.48,
      "learning_rate": 2.6657662082514734e-05,
      "loss": 0.665,
      "step": 190100
    },
    {
      "epoch": 373.67,
      "learning_rate": 2.6645383104125737e-05,
      "loss": 0.6685,
      "step": 190200
    },
    {
      "epoch": 373.87,
      "learning_rate": 2.663310412573674e-05,
      "loss": 0.6903,
      "step": 190300
    },
    {
      "epoch": 374.07,
      "learning_rate": 2.6620825147347743e-05,
      "loss": 0.6588,
      "step": 190400
    },
    {
      "epoch": 374.26,
      "learning_rate": 2.6608546168958743e-05,
      "loss": 0.6589,
      "step": 190500
    },
    {
      "epoch": 374.46,
      "learning_rate": 2.6596267190569746e-05,
      "loss": 0.6648,
      "step": 190600
    },
    {
      "epoch": 374.66,
      "learning_rate": 2.658398821218075e-05,
      "loss": 0.6481,
      "step": 190700
    },
    {
      "epoch": 374.85,
      "learning_rate": 2.657170923379175e-05,
      "loss": 0.6731,
      "step": 190800
    },
    {
      "epoch": 375.05,
      "learning_rate": 2.6559430255402752e-05,
      "loss": 0.6679,
      "step": 190900
    },
    {
      "epoch": 375.25,
      "learning_rate": 2.6547151277013755e-05,
      "loss": 0.6723,
      "step": 191000
    },
    {
      "epoch": 375.44,
      "learning_rate": 2.6534872298624758e-05,
      "loss": 0.6685,
      "step": 191100
    },
    {
      "epoch": 375.64,
      "learning_rate": 2.6522593320235754e-05,
      "loss": 0.6706,
      "step": 191200
    },
    {
      "epoch": 375.83,
      "learning_rate": 2.651031434184676e-05,
      "loss": 0.6717,
      "step": 191300
    },
    {
      "epoch": 376.03,
      "learning_rate": 2.6498035363457764e-05,
      "loss": 0.683,
      "step": 191400
    },
    {
      "epoch": 376.23,
      "learning_rate": 2.6485756385068767e-05,
      "loss": 0.6758,
      "step": 191500
    },
    {
      "epoch": 376.42,
      "learning_rate": 2.6473477406679763e-05,
      "loss": 0.6674,
      "step": 191600
    },
    {
      "epoch": 376.62,
      "learning_rate": 2.646119842829077e-05,
      "loss": 0.6634,
      "step": 191700
    },
    {
      "epoch": 376.82,
      "learning_rate": 2.6448919449901772e-05,
      "loss": 0.6718,
      "step": 191800
    },
    {
      "epoch": 377.01,
      "learning_rate": 2.643664047151277e-05,
      "loss": 0.6744,
      "step": 191900
    },
    {
      "epoch": 377.21,
      "learning_rate": 2.642436149312377e-05,
      "loss": 0.6675,
      "step": 192000
    },
    {
      "epoch": 377.41,
      "learning_rate": 2.6412082514734775e-05,
      "loss": 0.6653,
      "step": 192100
    },
    {
      "epoch": 377.6,
      "learning_rate": 2.639980353634578e-05,
      "loss": 0.6732,
      "step": 192200
    },
    {
      "epoch": 377.8,
      "learning_rate": 2.6387524557956777e-05,
      "loss": 0.6603,
      "step": 192300
    },
    {
      "epoch": 378.0,
      "learning_rate": 2.637524557956778e-05,
      "loss": 0.6587,
      "step": 192400
    },
    {
      "epoch": 378.19,
      "learning_rate": 2.6362966601178783e-05,
      "loss": 0.6705,
      "step": 192500
    },
    {
      "epoch": 378.39,
      "learning_rate": 2.6350687622789783e-05,
      "loss": 0.6655,
      "step": 192600
    },
    {
      "epoch": 378.59,
      "learning_rate": 2.6338408644400786e-05,
      "loss": 0.6605,
      "step": 192700
    },
    {
      "epoch": 378.78,
      "learning_rate": 2.632612966601179e-05,
      "loss": 0.6776,
      "step": 192800
    },
    {
      "epoch": 378.98,
      "learning_rate": 2.6313850687622792e-05,
      "loss": 0.671,
      "step": 192900
    },
    {
      "epoch": 379.17,
      "learning_rate": 2.6301571709233792e-05,
      "loss": 0.6491,
      "step": 193000
    },
    {
      "epoch": 379.37,
      "learning_rate": 2.6289292730844795e-05,
      "loss": 0.6615,
      "step": 193100
    },
    {
      "epoch": 379.57,
      "learning_rate": 2.6277013752455798e-05,
      "loss": 0.6686,
      "step": 193200
    },
    {
      "epoch": 379.76,
      "learning_rate": 2.62647347740668e-05,
      "loss": 0.6685,
      "step": 193300
    },
    {
      "epoch": 379.96,
      "learning_rate": 2.62524557956778e-05,
      "loss": 0.6694,
      "step": 193400
    },
    {
      "epoch": 380.16,
      "learning_rate": 2.6240176817288804e-05,
      "loss": 0.668,
      "step": 193500
    },
    {
      "epoch": 380.35,
      "learning_rate": 2.6227897838899807e-05,
      "loss": 0.6606,
      "step": 193600
    },
    {
      "epoch": 380.55,
      "learning_rate": 2.6215618860510803e-05,
      "loss": 0.6549,
      "step": 193700
    },
    {
      "epoch": 380.75,
      "learning_rate": 2.620333988212181e-05,
      "loss": 0.6773,
      "step": 193800
    },
    {
      "epoch": 380.94,
      "learning_rate": 2.6191060903732812e-05,
      "loss": 0.654,
      "step": 193900
    },
    {
      "epoch": 381.14,
      "learning_rate": 2.6178781925343815e-05,
      "loss": 0.6616,
      "step": 194000
    },
    {
      "epoch": 381.34,
      "learning_rate": 2.616650294695481e-05,
      "loss": 0.6565,
      "step": 194100
    },
    {
      "epoch": 381.53,
      "learning_rate": 2.6154223968565818e-05,
      "loss": 0.6605,
      "step": 194200
    },
    {
      "epoch": 381.73,
      "learning_rate": 2.614194499017682e-05,
      "loss": 0.6694,
      "step": 194300
    },
    {
      "epoch": 381.93,
      "learning_rate": 2.6129666011787817e-05,
      "loss": 0.6826,
      "step": 194400
    },
    {
      "epoch": 382.12,
      "learning_rate": 2.611738703339882e-05,
      "loss": 0.6773,
      "step": 194500
    },
    {
      "epoch": 382.32,
      "learning_rate": 2.6105108055009823e-05,
      "loss": 0.6747,
      "step": 194600
    },
    {
      "epoch": 382.51,
      "learning_rate": 2.609282907662083e-05,
      "loss": 0.6614,
      "step": 194700
    },
    {
      "epoch": 382.71,
      "learning_rate": 2.6080550098231826e-05,
      "loss": 0.6837,
      "step": 194800
    },
    {
      "epoch": 382.91,
      "learning_rate": 2.606827111984283e-05,
      "loss": 0.666,
      "step": 194900
    },
    {
      "epoch": 383.1,
      "learning_rate": 2.6055992141453832e-05,
      "loss": 0.6518,
      "step": 195000
    },
    {
      "epoch": 383.3,
      "learning_rate": 2.604371316306484e-05,
      "loss": 0.6579,
      "step": 195100
    },
    {
      "epoch": 383.5,
      "learning_rate": 2.6031434184675835e-05,
      "loss": 0.6665,
      "step": 195200
    },
    {
      "epoch": 383.69,
      "learning_rate": 2.6019155206286838e-05,
      "loss": 0.6803,
      "step": 195300
    },
    {
      "epoch": 383.89,
      "learning_rate": 2.600687622789784e-05,
      "loss": 0.6556,
      "step": 195400
    },
    {
      "epoch": 384.09,
      "learning_rate": 2.599459724950884e-05,
      "loss": 0.6796,
      "step": 195500
    },
    {
      "epoch": 384.28,
      "learning_rate": 2.5982318271119843e-05,
      "loss": 0.6665,
      "step": 195600
    },
    {
      "epoch": 384.48,
      "learning_rate": 2.5970039292730846e-05,
      "loss": 0.6776,
      "step": 195700
    },
    {
      "epoch": 384.68,
      "learning_rate": 2.595776031434185e-05,
      "loss": 0.6634,
      "step": 195800
    },
    {
      "epoch": 384.87,
      "learning_rate": 2.594548133595285e-05,
      "loss": 0.6679,
      "step": 195900
    },
    {
      "epoch": 385.07,
      "learning_rate": 2.5933202357563852e-05,
      "loss": 0.6621,
      "step": 196000
    },
    {
      "epoch": 385.27,
      "learning_rate": 2.5920923379174855e-05,
      "loss": 0.6749,
      "step": 196100
    },
    {
      "epoch": 385.46,
      "learning_rate": 2.590864440078585e-05,
      "loss": 0.6462,
      "step": 196200
    },
    {
      "epoch": 385.66,
      "learning_rate": 2.5896365422396858e-05,
      "loss": 0.6725,
      "step": 196300
    },
    {
      "epoch": 385.85,
      "learning_rate": 2.588408644400786e-05,
      "loss": 0.6731,
      "step": 196400
    },
    {
      "epoch": 386.05,
      "learning_rate": 2.5871807465618864e-05,
      "loss": 0.6701,
      "step": 196500
    },
    {
      "epoch": 386.25,
      "learning_rate": 2.585952848722986e-05,
      "loss": 0.6712,
      "step": 196600
    },
    {
      "epoch": 386.44,
      "learning_rate": 2.5847249508840867e-05,
      "loss": 0.6753,
      "step": 196700
    },
    {
      "epoch": 386.64,
      "learning_rate": 2.583497053045187e-05,
      "loss": 0.6583,
      "step": 196800
    },
    {
      "epoch": 386.84,
      "learning_rate": 2.5822691552062873e-05,
      "loss": 0.647,
      "step": 196900
    },
    {
      "epoch": 387.03,
      "learning_rate": 2.581041257367387e-05,
      "loss": 0.6508,
      "step": 197000
    },
    {
      "epoch": 387.23,
      "learning_rate": 2.5798133595284872e-05,
      "loss": 0.6618,
      "step": 197100
    },
    {
      "epoch": 387.43,
      "learning_rate": 2.578585461689588e-05,
      "loss": 0.6676,
      "step": 197200
    },
    {
      "epoch": 387.62,
      "learning_rate": 2.5773575638506875e-05,
      "loss": 0.6763,
      "step": 197300
    },
    {
      "epoch": 387.82,
      "learning_rate": 2.5761296660117878e-05,
      "loss": 0.65,
      "step": 197400
    },
    {
      "epoch": 388.02,
      "learning_rate": 2.574901768172888e-05,
      "loss": 0.6772,
      "step": 197500
    },
    {
      "epoch": 388.21,
      "learning_rate": 2.5736738703339887e-05,
      "loss": 0.6689,
      "step": 197600
    },
    {
      "epoch": 388.41,
      "learning_rate": 2.5724459724950883e-05,
      "loss": 0.6552,
      "step": 197700
    },
    {
      "epoch": 388.61,
      "learning_rate": 2.5712180746561886e-05,
      "loss": 0.6585,
      "step": 197800
    },
    {
      "epoch": 388.8,
      "learning_rate": 2.569990176817289e-05,
      "loss": 0.6799,
      "step": 197900
    },
    {
      "epoch": 389.0,
      "learning_rate": 2.5687622789783892e-05,
      "loss": 0.6435,
      "step": 198000
    },
    {
      "epoch": 389.19,
      "learning_rate": 2.5675343811394892e-05,
      "loss": 0.6695,
      "step": 198100
    },
    {
      "epoch": 389.39,
      "learning_rate": 2.5663064833005895e-05,
      "loss": 0.6561,
      "step": 198200
    },
    {
      "epoch": 389.59,
      "learning_rate": 2.5650785854616898e-05,
      "loss": 0.6493,
      "step": 198300
    },
    {
      "epoch": 389.78,
      "learning_rate": 2.5638506876227898e-05,
      "loss": 0.6501,
      "step": 198400
    },
    {
      "epoch": 389.98,
      "learning_rate": 2.56262278978389e-05,
      "loss": 0.6712,
      "step": 198500
    },
    {
      "epoch": 390.18,
      "learning_rate": 2.5613948919449904e-05,
      "loss": 0.6721,
      "step": 198600
    },
    {
      "epoch": 390.37,
      "learning_rate": 2.5601669941060907e-05,
      "loss": 0.6617,
      "step": 198700
    },
    {
      "epoch": 390.57,
      "learning_rate": 2.5589390962671907e-05,
      "loss": 0.6641,
      "step": 198800
    },
    {
      "epoch": 390.77,
      "learning_rate": 2.557711198428291e-05,
      "loss": 0.6778,
      "step": 198900
    },
    {
      "epoch": 390.96,
      "learning_rate": 2.5564833005893913e-05,
      "loss": 0.6463,
      "step": 199000
    },
    {
      "epoch": 391.16,
      "learning_rate": 2.555255402750491e-05,
      "loss": 0.6519,
      "step": 199100
    },
    {
      "epoch": 391.36,
      "learning_rate": 2.5540275049115915e-05,
      "loss": 0.6532,
      "step": 199200
    },
    {
      "epoch": 391.55,
      "learning_rate": 2.552799607072692e-05,
      "loss": 0.6775,
      "step": 199300
    },
    {
      "epoch": 391.75,
      "learning_rate": 2.551571709233792e-05,
      "loss": 0.6616,
      "step": 199400
    },
    {
      "epoch": 391.94,
      "learning_rate": 2.5503438113948918e-05,
      "loss": 0.6697,
      "step": 199500
    },
    {
      "epoch": 392.14,
      "learning_rate": 2.549115913555992e-05,
      "loss": 0.6658,
      "step": 199600
    },
    {
      "epoch": 392.34,
      "learning_rate": 2.5478880157170927e-05,
      "loss": 0.6513,
      "step": 199700
    },
    {
      "epoch": 392.53,
      "learning_rate": 2.546660117878193e-05,
      "loss": 0.649,
      "step": 199800
    },
    {
      "epoch": 392.73,
      "learning_rate": 2.5454322200392926e-05,
      "loss": 0.6712,
      "step": 199900
    },
    {
      "epoch": 392.93,
      "learning_rate": 2.544204322200393e-05,
      "loss": 0.6761,
      "step": 200000
    },
    {
      "epoch": 393.12,
      "learning_rate": 2.5429764243614936e-05,
      "loss": 0.6775,
      "step": 200100
    },
    {
      "epoch": 393.32,
      "learning_rate": 2.5417485265225932e-05,
      "loss": 0.6685,
      "step": 200200
    },
    {
      "epoch": 393.52,
      "learning_rate": 2.5405206286836935e-05,
      "loss": 0.6732,
      "step": 200300
    },
    {
      "epoch": 393.71,
      "learning_rate": 2.5392927308447938e-05,
      "loss": 0.6668,
      "step": 200400
    },
    {
      "epoch": 393.91,
      "learning_rate": 2.538064833005894e-05,
      "loss": 0.6635,
      "step": 200500
    },
    {
      "epoch": 394.11,
      "learning_rate": 2.536836935166994e-05,
      "loss": 0.6602,
      "step": 200600
    },
    {
      "epoch": 394.3,
      "learning_rate": 2.5356090373280944e-05,
      "loss": 0.6616,
      "step": 200700
    },
    {
      "epoch": 394.5,
      "learning_rate": 2.5343811394891947e-05,
      "loss": 0.6841,
      "step": 200800
    },
    {
      "epoch": 394.7,
      "learning_rate": 2.5331532416502946e-05,
      "loss": 0.6627,
      "step": 200900
    },
    {
      "epoch": 394.89,
      "learning_rate": 2.531925343811395e-05,
      "loss": 0.6613,
      "step": 201000
    },
    {
      "epoch": 395.09,
      "learning_rate": 2.5306974459724953e-05,
      "loss": 0.662,
      "step": 201100
    },
    {
      "epoch": 395.28,
      "learning_rate": 2.5294695481335956e-05,
      "loss": 0.6537,
      "step": 201200
    },
    {
      "epoch": 395.48,
      "learning_rate": 2.5282416502946955e-05,
      "loss": 0.6839,
      "step": 201300
    },
    {
      "epoch": 395.68,
      "learning_rate": 2.5270137524557958e-05,
      "loss": 0.666,
      "step": 201400
    },
    {
      "epoch": 395.87,
      "learning_rate": 2.525785854616896e-05,
      "loss": 0.6721,
      "step": 201500
    },
    {
      "epoch": 396.07,
      "learning_rate": 2.5245579567779964e-05,
      "loss": 0.6599,
      "step": 201600
    },
    {
      "epoch": 396.27,
      "learning_rate": 2.5233300589390964e-05,
      "loss": 0.6538,
      "step": 201700
    },
    {
      "epoch": 396.46,
      "learning_rate": 2.5221021611001967e-05,
      "loss": 0.6574,
      "step": 201800
    },
    {
      "epoch": 396.66,
      "learning_rate": 2.520874263261297e-05,
      "loss": 0.6755,
      "step": 201900
    },
    {
      "epoch": 396.86,
      "learning_rate": 2.5196463654223966e-05,
      "loss": 0.6744,
      "step": 202000
    },
    {
      "epoch": 397.05,
      "learning_rate": 2.518418467583497e-05,
      "loss": 0.6562,
      "step": 202100
    },
    {
      "epoch": 397.25,
      "learning_rate": 2.5171905697445976e-05,
      "loss": 0.663,
      "step": 202200
    },
    {
      "epoch": 397.45,
      "learning_rate": 2.515962671905698e-05,
      "loss": 0.6526,
      "step": 202300
    },
    {
      "epoch": 397.64,
      "learning_rate": 2.5147347740667975e-05,
      "loss": 0.6625,
      "step": 202400
    },
    {
      "epoch": 397.84,
      "learning_rate": 2.5135068762278978e-05,
      "loss": 0.6741,
      "step": 202500
    },
    {
      "epoch": 398.04,
      "learning_rate": 2.5122789783889984e-05,
      "loss": 0.6571,
      "step": 202600
    },
    {
      "epoch": 398.23,
      "learning_rate": 2.511051080550098e-05,
      "loss": 0.6668,
      "step": 202700
    },
    {
      "epoch": 398.43,
      "learning_rate": 2.5098231827111984e-05,
      "loss": 0.6624,
      "step": 202800
    },
    {
      "epoch": 398.62,
      "learning_rate": 2.5085952848722987e-05,
      "loss": 0.6565,
      "step": 202900
    },
    {
      "epoch": 398.82,
      "learning_rate": 2.507367387033399e-05,
      "loss": 0.6588,
      "step": 203000
    },
    {
      "epoch": 399.02,
      "learning_rate": 2.506139489194499e-05,
      "loss": 0.6637,
      "step": 203100
    },
    {
      "epoch": 399.21,
      "learning_rate": 2.5049115913555992e-05,
      "loss": 0.6509,
      "step": 203200
    },
    {
      "epoch": 399.41,
      "learning_rate": 2.5036836935166995e-05,
      "loss": 0.6596,
      "step": 203300
    },
    {
      "epoch": 399.61,
      "learning_rate": 2.5024557956778e-05,
      "loss": 0.662,
      "step": 203400
    },
    {
      "epoch": 399.8,
      "learning_rate": 2.5012278978388998e-05,
      "loss": 0.6706,
      "step": 203500
    },
    {
      "epoch": 400.0,
      "learning_rate": 2.5e-05,
      "loss": 0.679,
      "step": 203600
    },
    {
      "epoch": 400.2,
      "learning_rate": 2.4987721021611e-05,
      "loss": 0.6753,
      "step": 203700
    },
    {
      "epoch": 400.39,
      "learning_rate": 2.4975442043222004e-05,
      "loss": 0.6498,
      "step": 203800
    },
    {
      "epoch": 400.59,
      "learning_rate": 2.4963163064833007e-05,
      "loss": 0.656,
      "step": 203900
    },
    {
      "epoch": 400.79,
      "learning_rate": 2.495088408644401e-05,
      "loss": 0.6619,
      "step": 204000
    },
    {
      "epoch": 400.98,
      "learning_rate": 2.493860510805501e-05,
      "loss": 0.6523,
      "step": 204100
    },
    {
      "epoch": 401.18,
      "learning_rate": 2.4926326129666013e-05,
      "loss": 0.6479,
      "step": 204200
    },
    {
      "epoch": 401.38,
      "learning_rate": 2.4914047151277016e-05,
      "loss": 0.6532,
      "step": 204300
    },
    {
      "epoch": 401.57,
      "learning_rate": 2.490176817288802e-05,
      "loss": 0.6587,
      "step": 204400
    },
    {
      "epoch": 401.77,
      "learning_rate": 2.488948919449902e-05,
      "loss": 0.6535,
      "step": 204500
    },
    {
      "epoch": 401.96,
      "learning_rate": 2.4877210216110018e-05,
      "loss": 0.6619,
      "step": 204600
    },
    {
      "epoch": 402.16,
      "learning_rate": 2.4864931237721024e-05,
      "loss": 0.6573,
      "step": 204700
    },
    {
      "epoch": 402.36,
      "learning_rate": 2.4852652259332024e-05,
      "loss": 0.6505,
      "step": 204800
    },
    {
      "epoch": 402.55,
      "learning_rate": 2.4840373280943027e-05,
      "loss": 0.6643,
      "step": 204900
    },
    {
      "epoch": 402.75,
      "learning_rate": 2.4828094302554027e-05,
      "loss": 0.6505,
      "step": 205000
    },
    {
      "epoch": 402.95,
      "learning_rate": 2.4815815324165033e-05,
      "loss": 0.6791,
      "step": 205100
    },
    {
      "epoch": 403.14,
      "learning_rate": 2.4803536345776033e-05,
      "loss": 0.6592,
      "step": 205200
    },
    {
      "epoch": 403.34,
      "learning_rate": 2.4791257367387036e-05,
      "loss": 0.6697,
      "step": 205300
    },
    {
      "epoch": 403.54,
      "learning_rate": 2.4778978388998035e-05,
      "loss": 0.6549,
      "step": 205400
    },
    {
      "epoch": 403.73,
      "learning_rate": 2.476669941060904e-05,
      "loss": 0.64,
      "step": 205500
    },
    {
      "epoch": 403.93,
      "learning_rate": 2.475442043222004e-05,
      "loss": 0.6613,
      "step": 205600
    },
    {
      "epoch": 404.13,
      "learning_rate": 2.474214145383104e-05,
      "loss": 0.6697,
      "step": 205700
    },
    {
      "epoch": 404.32,
      "learning_rate": 2.4729862475442044e-05,
      "loss": 0.6756,
      "step": 205800
    },
    {
      "epoch": 404.52,
      "learning_rate": 2.4717583497053047e-05,
      "loss": 0.6455,
      "step": 205900
    },
    {
      "epoch": 404.72,
      "learning_rate": 2.470530451866405e-05,
      "loss": 0.6571,
      "step": 206000
    },
    {
      "epoch": 404.91,
      "learning_rate": 2.469302554027505e-05,
      "loss": 0.6394,
      "step": 206100
    },
    {
      "epoch": 405.11,
      "learning_rate": 2.4680746561886053e-05,
      "loss": 0.6521,
      "step": 206200
    },
    {
      "epoch": 405.3,
      "learning_rate": 2.4668467583497053e-05,
      "loss": 0.6601,
      "step": 206300
    },
    {
      "epoch": 405.5,
      "learning_rate": 2.4656188605108056e-05,
      "loss": 0.6677,
      "step": 206400
    },
    {
      "epoch": 405.7,
      "learning_rate": 2.464390962671906e-05,
      "loss": 0.658,
      "step": 206500
    },
    {
      "epoch": 405.89,
      "learning_rate": 2.4631630648330058e-05,
      "loss": 0.6612,
      "step": 206600
    },
    {
      "epoch": 406.09,
      "learning_rate": 2.461935166994106e-05,
      "loss": 0.6709,
      "step": 206700
    },
    {
      "epoch": 406.29,
      "learning_rate": 2.4607072691552064e-05,
      "loss": 0.6474,
      "step": 206800
    },
    {
      "epoch": 406.48,
      "learning_rate": 2.4594793713163067e-05,
      "loss": 0.6599,
      "step": 206900
    },
    {
      "epoch": 406.68,
      "learning_rate": 2.4582514734774067e-05,
      "loss": 0.6581,
      "step": 207000
    },
    {
      "epoch": 406.88,
      "learning_rate": 2.457023575638507e-05,
      "loss": 0.6374,
      "step": 207100
    },
    {
      "epoch": 407.07,
      "learning_rate": 2.4557956777996073e-05,
      "loss": 0.6701,
      "step": 207200
    },
    {
      "epoch": 407.27,
      "learning_rate": 2.4545677799607076e-05,
      "loss": 0.6651,
      "step": 207300
    },
    {
      "epoch": 407.47,
      "learning_rate": 2.4533398821218076e-05,
      "loss": 0.6404,
      "step": 207400
    },
    {
      "epoch": 407.66,
      "learning_rate": 2.4521119842829075e-05,
      "loss": 0.6612,
      "step": 207500
    },
    {
      "epoch": 407.86,
      "learning_rate": 2.4508840864440082e-05,
      "loss": 0.6613,
      "step": 207600
    },
    {
      "epoch": 408.06,
      "learning_rate": 2.449656188605108e-05,
      "loss": 0.6618,
      "step": 207700
    },
    {
      "epoch": 408.25,
      "learning_rate": 2.4484282907662084e-05,
      "loss": 0.6651,
      "step": 207800
    },
    {
      "epoch": 408.45,
      "learning_rate": 2.4472003929273084e-05,
      "loss": 0.654,
      "step": 207900
    },
    {
      "epoch": 408.64,
      "learning_rate": 2.4459724950884087e-05,
      "loss": 0.6673,
      "step": 208000
    },
    {
      "epoch": 408.84,
      "learning_rate": 2.444744597249509e-05,
      "loss": 0.6559,
      "step": 208100
    },
    {
      "epoch": 409.04,
      "learning_rate": 2.4435166994106093e-05,
      "loss": 0.6553,
      "step": 208200
    },
    {
      "epoch": 409.23,
      "learning_rate": 2.4422888015717093e-05,
      "loss": 0.6472,
      "step": 208300
    },
    {
      "epoch": 409.43,
      "learning_rate": 2.4410609037328096e-05,
      "loss": 0.6645,
      "step": 208400
    },
    {
      "epoch": 409.63,
      "learning_rate": 2.43983300589391e-05,
      "loss": 0.668,
      "step": 208500
    },
    {
      "epoch": 409.82,
      "learning_rate": 2.43860510805501e-05,
      "loss": 0.6579,
      "step": 208600
    },
    {
      "epoch": 410.02,
      "learning_rate": 2.43737721021611e-05,
      "loss": 0.6559,
      "step": 208700
    },
    {
      "epoch": 410.22,
      "learning_rate": 2.43614931237721e-05,
      "loss": 0.669,
      "step": 208800
    },
    {
      "epoch": 410.41,
      "learning_rate": 2.4349214145383108e-05,
      "loss": 0.6476,
      "step": 208900
    },
    {
      "epoch": 410.61,
      "learning_rate": 2.4336935166994107e-05,
      "loss": 0.6528,
      "step": 209000
    },
    {
      "epoch": 410.81,
      "learning_rate": 2.432465618860511e-05,
      "loss": 0.6666,
      "step": 209100
    },
    {
      "epoch": 411.0,
      "learning_rate": 2.431237721021611e-05,
      "loss": 0.6642,
      "step": 209200
    },
    {
      "epoch": 411.2,
      "learning_rate": 2.4300098231827113e-05,
      "loss": 0.6613,
      "step": 209300
    },
    {
      "epoch": 411.39,
      "learning_rate": 2.4287819253438116e-05,
      "loss": 0.6507,
      "step": 209400
    },
    {
      "epoch": 411.59,
      "learning_rate": 2.4275540275049116e-05,
      "loss": 0.6668,
      "step": 209500
    },
    {
      "epoch": 411.79,
      "learning_rate": 2.426326129666012e-05,
      "loss": 0.6693,
      "step": 209600
    },
    {
      "epoch": 411.98,
      "learning_rate": 2.4250982318271122e-05,
      "loss": 0.6639,
      "step": 209700
    },
    {
      "epoch": 412.18,
      "learning_rate": 2.4238703339882125e-05,
      "loss": 0.6621,
      "step": 209800
    },
    {
      "epoch": 412.38,
      "learning_rate": 2.4226424361493124e-05,
      "loss": 0.6663,
      "step": 209900
    },
    {
      "epoch": 412.57,
      "learning_rate": 2.4214145383104127e-05,
      "loss": 0.6518,
      "step": 210000
    }
  ],
  "max_steps": 407200,
  "num_train_epochs": 800,
  "total_flos": 1.0514172727753728e+16,
  "trial_name": null,
  "trial_params": null
}
